<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Thoughts from the Café</title>
    <link href="http://stappit.github.io/atom.xml" rel="self" />
    <link href="http://stappit.github.io" />
    <id>http://stappit.github.io/atom.xml</id>
    <author>
        <name>Brian</name>
        <email>ha@hahaha.com</email>
    </author>
    <updated>2018-08-29T00:00:00Z</updated>
    <entry>
    <title>BDA3 Chapter 2 Exercise 9</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_09.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_09.html</id>
    <published>2018-08-29T00:00:00Z</published>
    <updated>2018-08-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 9</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 29, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/beta.html">beta</a>, <a href="/tags/prior%20sensitivity.html">prior sensitivity</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 9, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dnorm}{normal} \DeclareMathOperator{\dgamma}{gamma} \DeclareMathOperator{\invlogit}{invlogit} \DeclareMathOperator{\logit}{logit} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>The data show 650 people in support of the death penalty and 350 against. We explore the effect of different priors on the posterior.</p>
<p>First let’s find the prior with a mean of 0.6 and standard deviation 0.3. The mean of the <span class="math inline">\(\dbeta(\alpha, \beta)\)</span> distribution is</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{3}{5}
=
\frac{\alpha}{\alpha + \beta}
\]</span></p>
<p>which implies that <span class="math inline">\(\alpha = 1.5 \beta\)</span>. The variance is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \frac{9}{100}
  &amp;=
  \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta  + 1)}
  \\
  &amp;=
  \frac{3}{2} \frac{\beta^2}{\frac{25}{4}\beta^2 \frac{5\beta + 2}{2}}
  \\
  &amp;=
  \frac{3}{2}\frac{4}{25}\frac{2}{5\beta + 2}
  \\
  &amp;=
  \frac{12}{25(5\beta + 2)}
  \\
  &amp;\Leftrightarrow
  \\
  5\beta + 2
  &amp;=
  \frac{12}{25}\frac{100}{9}
  \\
  &amp;=
  4,
\end{align}
\]</span></p>
<p>which implies that <span class="math inline">\(\beta = \frac{2}{5}\)</span>. Thus <span class="math inline">\(\alpha = \frac{3}{5}\)</span>. Since both parameters are below 1, we see maxima near 0 and 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">α &lt;-<span class="st"> </span><span class="dv">3</span> <span class="op">/</span><span class="st"> </span><span class="dv">5</span>
β &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">5</span>

<span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.001</span>), <span class="dt">y =</span> <span class="kw">dbeta</span>(x, α, β)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(x, y) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">fill =</span> <span class="st">&#39;skyblue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;x&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;beta(x | α, β)&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Beta prior with mean 0.3 and standard deviation 0.6&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;α = {α}, β = {β}&#39;</span>)
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_09_files/figure-markdown/prior-1.png" />
</figure>
<p>The beta distribution is self-conjugate so the posterior is <span class="math inline">\(\dbeta(0.6 + 650, 0.4 + 350)\)</span>.</p>
<p>Let’s plot the posterior with priors of different strength. We can increase the strength of the prior whilst keeping the mean constant by multiplying <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> by the same constant c. We will use <span class="math inline">\(c \in \{ 1, 10, 100, 1000\}\)</span>. In the plot below, we have restricted the x-axis to focus on the differences in the shape of the posteriors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">support &lt;-<span class="st"> </span><span class="dv">650</span>
against &lt;-<span class="st"> </span><span class="dv">350</span>

<span class="kw">expand.grid</span>(<span class="dt">magnitude =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">x =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.001</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">c =</span> <span class="dv">10</span><span class="op">^</span>magnitude,
    <span class="dt">a_prior =</span> α <span class="op">*</span><span class="st"> </span>c,
    <span class="dt">b_prior =</span> β <span class="op">*</span><span class="st"> </span>c,
    <span class="dt">y =</span> <span class="kw">dbeta</span>(x, support <span class="op">+</span><span class="st"> </span>a_prior, against <span class="op">+</span><span class="st"> </span>b_prior),
    <span class="dt">prior_magnitude =</span> <span class="kw">factor</span>(<span class="kw">as.character</span>(<span class="dv">10</span><span class="op">^</span>magnitude))
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(x, y, <span class="dt">colour =</span> prior_magnitude) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="fl">0.55</span>, <span class="fl">0.75</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;x&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;beta(x | support + a, against + b)&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Beta posterior with different priors&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="kw">paste</span>(
      <span class="st">&#39;a = {α} * 10^magnitude, b = {β} * 10^magnitude&#39;</span>,
      <span class="st">&#39;support = 650, against = 350&#39;</span>,
      <span class="dt">sep =</span> <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>
    )),
    <span class="dt">colour =</span> <span class="st">&#39;Magnitude of the prior&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_09_files/figure-markdown/posterior-1.png" />
</figure>
<p>Magnitudes 1 and 10 give very similar results close to the maximum likelihood estimate of 65%. The higher magnitudes pull the mean towards the prior mean of 60%.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 8</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_08.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_08.html</id>
    <published>2018-08-27T00:00:00Z</published>
    <updated>2018-08-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 8</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 27, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/normal.html">normal</a>, <a href="/tags/posterior%20predictive.html">posterior predictive</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 8, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dnorm}{normal} \DeclareMathOperator{\dgamma}{gamma} \DeclareMathOperator{\invlogit}{invlogit} \DeclareMathOperator{\logit}{logit} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>With prior <span class="math inline">\(\theta \sim \dnorm(180, 40)\)</span>, sampling distribution <span class="math inline">\(y \mid \theta \sim \dnorm(\theta, 20)\)</span>, and <span class="math inline">\(n\)</span> sampled students with average weight <span class="math inline">\(\bar y = 150\)</span>, it follows from 2.11 that the posterior mean is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mu
  :=
  \mathbb E(\theta \mid \bar y) 
  &amp;=
  \frac{\frac{180}{1600} + \frac{150n}{400}}{\frac{1}{1600} + \frac{n}{400}} 
  \\
  &amp;=
  \frac{60(3 + 10n)}{1600} \cdot \frac{1600}{1 + 4n}
  \\
  &amp;=
  \frac{60(3 + 10n)}{1 + 4n}
  \\
  1 / \sigma^2 
  :=
  1 / \mathbb V (\theta \mid \bar y)
  &amp;=
  \frac{1}{1600} + \frac{n}{400}
  \\
  &amp;=
  \frac{1 + 4n}{1600}
  .
\end{align}
\]</span></p>
<p>So <span class="math inline">\(\theta \mid \bar y ~ \dnorm \left( \frac{60(3 + 10n)}{1 + 4n}, \frac{40}{\sqrt{1 + 4n}} \right)\)</span>.</p>
<p>It follows from the calculations shown in the book that the posterior predictive distribution is <span class="math inline">\(\tilde y \mid y \sim \dnorm(\mu, \sigma + 20)\)</span>.</p>
<p>We can obtain 95% posterior intervals as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="cf">function</span>(n) <span class="dv">60</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">10</span> <span class="op">*</span><span class="st"> </span>n) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>n)
sigma &lt;-<span class="st"> </span><span class="cf">function</span>(n) <span class="dv">40</span> <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>n)

percentiles &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>)

theta_posterior_interval &lt;-<span class="st"> </span><span class="kw">qnorm</span>(percentiles, <span class="kw">mu</span>(<span class="dv">10</span>), <span class="kw">sigma</span>(<span class="dv">10</span>))
y_posterior_interval &lt;-<span class="st"> </span><span class="kw">qnorm</span>(percentiles, <span class="kw">mu</span>(<span class="dv">10</span>), <span class="kw">sigma</span>(<span class="dv">10</span>) <span class="op">+</span><span class="st"> </span><span class="dv">20</span>)</code></pre></div>
<p>With a sample of size of 10, we get θ ϵ [140.5, 161] and <span class="math inline">\(\tilde y\)</span> ϵ [107.6, 193.9].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">theta_posterior_interval &lt;-<span class="st"> </span><span class="kw">qnorm</span>(percentiles, <span class="kw">mu</span>(<span class="dv">100</span>), <span class="kw">sigma</span>(<span class="dv">100</span>))
y_posterior_interval &lt;-<span class="st"> </span><span class="kw">qnorm</span>(percentiles, <span class="kw">mu</span>(<span class="dv">100</span>), <span class="kw">sigma</span>(<span class="dv">100</span>) <span class="op">+</span><span class="st"> </span><span class="dv">20</span>)</code></pre></div>
<p>With a sample of size of 100, we get θ ϵ [146.8, 153.4] and <span class="math inline">\(\tilde y\)</span> ϵ [113.9, 186.3].</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 7</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_07.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_07.html</id>
    <published>2018-08-26T00:00:00Z</published>
    <updated>2018-08-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 7</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 26, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/binomial.html">binomial</a>, <a href="/tags/natural%20parameter.html">natural parameter</a>, <a href="/tags/exponential%20family.html">exponential family</a>, <a href="/tags/improper%20prior.html">improper prior</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 7, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dgamma}{gamma} \DeclareMathOperator{\invlogit}{invlogit} \DeclareMathOperator{\logit}{logit} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>We show that a uniform prior on the natural parameter of a binomial model implies an improper prior under a different parameterisation.</p>
<p>The binomial likelihood can be written as a member of the exponential family as</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \dbinomial(y \mid \theta)
  &amp;=
  \binom{n}{y} \theta^y (1 - \theta)^{n - y}
  \\
  &amp;=
  \binom{n}{y} \cdot (1 - \theta)^n \cdot \exp \left(y \log \left(\frac{\theta}{1 - \theta}\right)\right)
  \\
  &amp;=
  f(y) \cdot g(\theta) \cdot \exp (\phi(\theta) \cdot u(y))
  ,
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\phi(\theta) := \log \frac{\theta}{1 - \theta}\)</span>, <span class="math inline">\(u(y) := y\)</span>, <span class="math inline">\(g(\theta) := (1 - \theta)^n\)</span>. Suppose the natural parameter <span class="math inline">\(\phi \sim \dbeta(1, 1)\)</span> is uniformly distributed. Then the distribution of <span class="math inline">\(\theta\)</span> is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\theta) 
  &amp;\propto
  p(\phi) \cdot \vert \invlogit^\prime (\phi) \vert^{-1}
  \\
  &amp;=
  \left \vert \frac{1}{1 + \exp(-\phi)}^\prime \right\vert^{-1}
  \\
  &amp;=
  \left \vert \frac{1}{\left(1 + \exp(-\phi)\right)^2} \cdot \exp(-\phi) \right\vert^{-1}
  \\
  &amp;=
  \frac{1 + 2 \exp(-\phi) + \exp(-2\phi)}{\exp(-\phi)}
  \\
  &amp;=
  \exp(\phi) + 2 + \exp(-\phi)
  \\
  &amp;=
  \frac{\theta}{1 - \theta} + 2 + \frac{1 - \theta}{\theta}
  \\
  &amp;=
  \frac{\theta^2 + 2\theta(1 - \theta) + (1 - \theta)^2}{\theta(1 - \theta)}
  \\
  &amp;=
  \frac{1}{\theta(1 - \theta)}
  \\
  &amp;=
  \theta^{-1}(1 - \theta)^{-1}
  \qquad \square
\end{align}
\]</span></p>
<p>This is an improper distribution on <span class="math inline">\(\theta\)</span> because</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \int_0^1 \frac{1}{\theta(1 - \theta)}
  &amp;\ge
  \int_0^1 \frac{1}{\theta}
  \\
  &amp;=
  \log\theta \vert_0^1
  \\
  &amp;=
  \infty.
\end{align}
\]</span></p>
<p>When <span class="math inline">\(y = 0\)</span>, then the posterior distribution is <span class="math inline">\(p(\theta \mid y = 0) \propto (1 - \theta)^{n - 1}\theta^{-1}\)</span>. When <span class="math inline">\(y = n\)</span>, then the posterior distribution is <span class="math inline">\(p(\theta \mid y = n) \propto \theta^{n-1}(1 - \theta)^{-1}\)</span>. These two cases are equivalent by the change of variable <span class="math inline">\(\theta \mapsto 1 - \theta\)</span>.</p>
<p>We show that the distribution is improper for <span class="math inline">\(y = 0\)</span> by induction. The case <span class="math inline">\(n = 0\)</span> is shown above (for the prior). Assume the distribution is improper for any integer <span class="math inline">\(k &lt; n\)</span>. Then using integration by parts yields</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
\int_0^1 \theta^{- 1}(1 - \theta)^{n - 1} d\theta
&amp;=
\int_0^1 \theta^{- 1}(1 - \theta)^{n - 2} \cdot (1 - \theta)d\theta
\\
&amp;=
\left[(1 - \theta)^{n-2}(1 - \frac{\theta}{2}) \right]_0^1
+
\int_0^1 \frac{(1 - \theta)^{n - 2}}{\theta}
+
(n-2)(1 - \theta)^{n-3}
-
\frac{(1 - \theta)^{n-2}}{2}
-
(n - 2)\theta\frac{(1 - \theta)^{n-3}}{2}
d\theta
\\
&amp;=
c
+
\int_0^1 \frac{(1 - \theta)^{n - 2}}{\theta} d\theta,
\end{align}
\]</span></p>
<p>where <span class="math inline">\(c &lt; \infty\)</span>. By the induction hypothesis, the integral on the last line is <span class="math inline">\(\infty\)</span>. Therefore, the distribution is also improper for <span class="math inline">\(n\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 6</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_06.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_06.html</id>
    <published>2018-08-25T00:00:00Z</published>
    <updated>2018-08-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 6</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 25, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/poisson.html">poisson</a>, <a href="/tags/gamma.html">gamma</a>, <a href="/tags/negative%20binomial.html">negative binomial</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 6, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dgamma}{gamma} \DeclareMathOperator{\dpois}{Poisson} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Considering the negative binomial variable <span class="math inline">\(y\)</span> as a gamma-Poisson variable, we derive expressions for the mean and variance.</p>
<p>From equation 1.6, <span class="math inline">\(\mathbb E (y) = \mathbb E (\mathbb E(y \mid \theta))\)</span>. Since <span class="math inline">\(y \mid \theta \sim \dpois(10n\theta)\)</span>, it follows that <span class="math inline">\(\mathbb E (y \mid \theta) = 10n\theta\)</span>. The rate <span class="math inline">\(\theta \sim \dgamma(\alpha, \beta)\)</span> so <span class="math inline">\(\mathbb E(\theta) = \frac{\alpha}{\beta}\)</span>. Thus, <span class="math inline">\(\mathbb E(y) = 10n\mathbb E(\theta) = 10n \frac{\alpha}{\beta}\)</span>.</p>
<p>We also have <span class="math inline">\(\mathbb V(\theta) = \frac{\alpha}{\beta^2}\)</span> since <span class="math inline">\(\theta \sim \dgamma(\alpha, \beta)\)</span>, and <span class="math inline">\(\mathbb V(y \mid \theta) = 10n\theta\)</span> since <span class="math inline">\(y \mid \theta \sim \dpois(10n\theta)\)</span>. Thus,</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb V (y) 
  &amp;= 
  \mathbb E(\mathbb V(y \mid \theta)) + \mathbb V (\mathbb E (y \mid \theta)) 
  \\
  &amp;=
  \mathbb E(10n\theta) + \mathbb V (10n\theta)
  \\
  &amp;=
  10n\frac{\alpha}{\beta} + (10n)^2\frac{\alpha}{\beta^2}
  \qquad \square
\end{align}
\]</span></p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 5</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_05.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_05.html</id>
    <published>2018-08-24T00:00:00Z</published>
    <updated>2018-08-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 5</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 24, 2018  by Brian </br>
     Tags: <a href="/tags/bayes.html">bayes</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a>, <a href="/tags/beta.html">beta</a>, <a href="/tags/binomial.html">binomial</a>, <a href="/tags/beta-binomial.html">beta-binomial</a>, <a href="/tags/variance.html">variance</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 5, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Let’s derive the prior predictive distribution of a beta-binomial model with a uniform prior. See <a href="https://math.stackexchange.com/questions/122296/how-to-evaluate-this-integral-relating-to-binomial">stackexchange</a> and <a href="https://en.wikipedia.org/wiki/Beta_function">wikipedia</a> for useful results for solving the integral below.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(y = k)
  &amp;=
  \int_0^1 p(y = k \mid \theta) p(\theta) d\theta
  \\
  &amp;=
  \binom{n}{k} \cdot \int_0^1 \theta^k (1 - \theta)^{n - k} d\theta
  \\
  &amp;=
  \binom{n}{k} \cdot \frac{1}{\binom{n}{k} \cdot (n + 1)}
  \\
  &amp;=
  \frac{1}{n + 1}
\end{align}
\]</span></p>
<p>Now let’s show that the posterior mean of <span class="math inline">\(\theta\)</span> lies between the prior mean and observed frequency. The posterior is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\theta \mid y)
  &amp;\propto
  p(y \mid \theta) \cdot p(\theta)
  \\
  &amp;\propto
  \theta^y (1 - \theta)^{n - y}\cdot \theta^{\alpha - 1} (1 - \theta)^{\beta - 1}
  \\
  &amp;=
  \theta^{y + \alpha - 1} (1 - \theta)^{n + \beta - y - 1}.
\end{align}
\]</span></p>
<p>So <span class="math inline">\(p(\theta \mid y) \sim \dbeta(y + \alpha, n - y + \beta)\)</span>, which has mean <span class="math inline">\(\frac{y + \alpha}{n + \alpha + \beta}\)</span>. Suppose <span class="math inline">\(\frac{y}{n} \le \frac{\alpha}{\alpha + \beta}\)</span>. Then</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \frac{y}{n}
  &amp;\le
  \frac{y + \alpha}{n + \alpha + \beta}
  \\
  \Leftrightarrow
  y(n + \alpha + \beta)
  &amp;\le
  n(y + \alpha)
  \\
  \Leftrightarrow
  y(\alpha + \beta)
  &amp;\le
  n\alpha
  \\
  \Leftrightarrow
  \frac{y}{n} 
  &amp;\le 
  \frac{\alpha}{\alpha + \beta}
\end{align}
\]</span></p>
<p>A similar argument shows that <span class="math inline">\(\frac{y + \alpha}{n + \alpha + \beta} \le \frac{\alpha}{\alpha + \beta}\)</span>.</p>
<p>If <span class="math inline">\(\frac{y}{n} \ge \frac{\alpha}{\alpha + \beta}\)</span>, then the analogous argument shows that <span class="math inline">\(\frac{\alpha}{\alpha + \beta} \le \frac{y + \alpha}{n + \alpha + \beta} \le \frac{y}{n}. \square\)</span></p>
<p>The prior variance is <span class="math inline">\(\mathbb V (\theta) = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}\)</span>. For a uniform prior this is <span class="math inline">\(\frac{1}{4 \cdot 3} = \frac{1}{12}\)</span>. The posterior variance with a uniform prior is <span class="math inline">\(\frac{y + 1}{n + 2} \cdot \frac{n - y + 1}{n + 2} \cdot \frac{1}{n + 3}\)</span>. For <span class="math inline">\(p \in [0, 1]\)</span>, the function <span class="math inline">\(p \mapsto p(1 - p)\)</span> is maximised when <span class="math inline">\(p = 0.5\)</span>. Thus for fixed <span class="math inline">\(n\)</span>, the posterior variance is maximised when <span class="math inline">\(y = \frac{n}{2}\)</span>. This means that the posterior variance is at most <span class="math inline">\(\frac{1}{4} \cdot \frac{1}{n + 3} \le \frac{1}{4n + 12} \le \frac{1}{12}. \square\)</span></p>
<p>Intuitively, the posterior variance should be larger than the prior variance when the observed data is different from what would be expected from the prior distribution. (This can’t happen with a uniform prior because every value is equally likely). Indeed, with prior <span class="math inline">\(\theta \sim \dbeta(1, 9)\)</span> and observed data <span class="math inline">\(y = 9, n = 10\)</span>, we have <span class="math inline">\(\mathbb V(\theta) = \frac{9}{1100}\)</span> and <span class="math inline">\(\mathbb V(\theta \mid y) = \frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{21} = \frac{1}{84}\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 4</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_04.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_04.html</id>
    <published>2018-08-23T00:00:00Z</published>
    <updated>2018-08-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 4</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 23, 2018  by Brian </br>
     Tags: <a href="/tags/binomial.html">binomial</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a>, <a href="/tags/normal%20approximation.html">normal approximation</a>, <a href="/tags/multi-modal.html">multi-modal</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 4, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Consider 1000 rolls of an unfair die, where the probability of a 6 is either 1/4, 1/6, or 1/12. Let’s draw the distribution and the normal approximation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">1000</span>
p6 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">6</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">12</span>)

ex4 &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(
    <span class="dt">y =</span> <span class="kw">seq</span>(<span class="dv">0</span>, N),
    <span class="dt">theta =</span> p6
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">mu =</span> N <span class="op">*</span><span class="st"> </span>theta,
    <span class="dt">sigma =</span> <span class="kw">sqrt</span>(N <span class="op">*</span><span class="st"> </span>theta <span class="op">*</span><span class="st"> </span>(<span class="dv">10</span> <span class="op">-</span><span class="st"> </span>theta)),
    <span class="dt">binomial =</span> <span class="kw">dbinom</span>(y, N, theta),
    <span class="dt">normal_approx =</span> <span class="kw">dnorm</span>(y, mu, sigma),
    <span class="dt">theta =</span> scales<span class="op">::</span><span class="kw">percent</span>(<span class="kw">signif</span>(theta))
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>mu, <span class="op">-</span>sigma) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(distribution, probability, binomial, normal_approx) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(theta, probability) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prior_probability =</span> <span class="fl">0.25</span> <span class="op">*</span><span class="st"> `</span><span class="dt">8.3%</span><span class="st">`</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> `</span><span class="dt">16.7%</span><span class="st">`</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.25</span> <span class="op">*</span><span class="st"> `</span><span class="dt">25.0%</span><span class="st">`</span>)</code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
y
</th>
<th style="text-align:left;">
distribution
</th>
<th style="text-align:right;">
16.7%
</th>
<th style="text-align:right;">
25.0%
</th>
<th style="text-align:right;">
8.3%
</th>
<th style="text-align:right;">
prior_probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0.0e+00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.00e+00
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
normal_approx
</td>
<td style="text-align:right;">
2.1e-06
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0002078
</td>
<td style="text-align:right;">
5.30e-05
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0.0e+00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.00e+00
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
normal_approx
</td>
<td style="text-align:right;">
2.3e-06
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0002297
</td>
<td style="text-align:right;">
5.86e-05
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0.0e+00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
0.00e+00
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
normal_approx
</td>
<td style="text-align:right;">
2.5e-06
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0002536
</td>
<td style="text-align:right;">
6.47e-05
</td>
</tr>
</tbody>
</table>
<figure>
<img src="chapter_02_exercise_04_files/figure-markdown/ex4_plot-1.png" />
</figure>
<p>The normal approximation underestimates the maxima and overestimates the values between the maxima. From the percentiles in the table below, we see that the normal approximation is best near the median but becomes gradually worse towards towards both extremes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">percentiles &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.95</span>)

ex4 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(distribution) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(y) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">cdf =</span> <span class="kw">cumsum</span>(prior_probability),
    <span class="dt">percentile =</span> <span class="kw">case_when</span>(
      cdf <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span> <span class="op">~</span><span class="st"> &#39;05%&#39;</span>,
      cdf <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.25</span> <span class="op">~</span><span class="st"> &#39;25%&#39;</span>,
      cdf <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.50</span> <span class="op">~</span><span class="st"> &#39;50%&#39;</span>,
      cdf <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.75</span> <span class="op">~</span><span class="st"> &#39;75%&#39;</span>,
      cdf <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.95</span> <span class="op">~</span><span class="st"> &#39;95%&#39;</span>
    )
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(cdf <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.95</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(distribution, percentile) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="kw">which.max</span>(cdf)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(distribution, percentile, y) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(distribution, y) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(percentile) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">kable</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">kable_styling</span>()</code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
percentile
</th>
<th style="text-align:right;">
binomial
</th>
<th style="text-align:right;">
normal_approx
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
05%
</td>
<td style="text-align:right;">
75
</td>
<td style="text-align:right;">
58
</td>
</tr>
<tr>
<td style="text-align:left;">
25%
</td>
<td style="text-align:right;">
119
</td>
<td style="text-align:right;">
110
</td>
</tr>
<tr>
<td style="text-align:left;">
50%
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
164
</td>
</tr>
<tr>
<td style="text-align:left;">
75%
</td>
<td style="text-align:right;">
206
</td>
<td style="text-align:right;">
214
</td>
</tr>
<tr>
<td style="text-align:left;">
95%
</td>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
291
</td>
</tr>
</tbody>
</table>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 3</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_03.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_03.html</id>
    <published>2018-08-22T00:00:00Z</published>
    <updated>2018-08-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 3</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 22, 2018  by Brian </br>
     Tags: <a href="/tags/binomial.html">binomial</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a>, <a href="/tags/normal%20approximation.html">normal approximation</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 3, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>For 1000 rolls of a fair die, The mean number of sixs is 1000/6 = 166.667, the variance is 138.889, and the standard deviation is 11.7851.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">1000</span>
p &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">6</span>
mu &lt;-<span class="st"> </span>N <span class="op">*</span><span class="st"> </span>p
sigma &lt;-<span class="st"> </span><span class="kw">sqrt</span>(N <span class="op">*</span><span class="st"> </span>p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p))

ex3 &lt;-<span class="st"> </span><span class="kw">tibble</span>(
    <span class="dt">y =</span> <span class="kw">seq</span>(<span class="dv">0</span>, N),
    <span class="dt">binomial =</span> <span class="kw">dbinom</span>(y, N, p),
    <span class="dt">normal_approx =</span> <span class="kw">dnorm</span>(y, mu, sigma)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(metric, probability, <span class="op">-</span>y) </code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
y
</th>
<th style="text-align:left;">
metric
</th>
<th style="text-align:right;">
probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
binomial
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<figure>
<img src="chapter_02_exercise_03_files/figure-markdown/ex3_plot-1.png" />
</figure>
<p>The two curves are visually indistinguishable. The percentiles are listed in the table below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">percentiles &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.95</span>)

<span class="kw">tibble</span>(
    <span class="dt">percentile =</span> scales<span class="op">::</span><span class="kw">percent</span>(percentiles),
    <span class="dt">binom =</span> <span class="kw">qbinom</span>(percentiles, N, p),
    <span class="dt">norm =</span> <span class="kw">qnorm</span>(percentiles, mu, sigma)
) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">kable</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">kable_styling</span>()</code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
percentile
</th>
<th style="text-align:right;">
binom
</th>
<th style="text-align:right;">
norm
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
5%
</td>
<td style="text-align:right;">
147
</td>
<td style="text-align:right;">
147.2819
</td>
</tr>
<tr>
<td style="text-align:left;">
25%
</td>
<td style="text-align:right;">
159
</td>
<td style="text-align:right;">
158.7177
</td>
</tr>
<tr>
<td style="text-align:left;">
50%
</td>
<td style="text-align:right;">
167
</td>
<td style="text-align:right;">
166.6667
</td>
</tr>
<tr>
<td style="text-align:left;">
75%
</td>
<td style="text-align:right;">
175
</td>
<td style="text-align:right;">
174.6156
</td>
</tr>
<tr>
<td style="text-align:left;">
95%
</td>
<td style="text-align:right;">
186
</td>
<td style="text-align:right;">
186.0515
</td>
</tr>
</tbody>
</table>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 2</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_02.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_02.html</id>
    <published>2018-08-21T00:00:00Z</published>
    <updated>2018-08-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 2</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 21, 2018  by Brian </br>
     Tags: <a href="/tags/stan.html">stan</a>, <a href="/tags/binomial.html">binomial</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 2, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>We are given the following information about the two coins.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(C_1) &amp;= 0.5 &amp; p(H \mid C_1) &amp;= \dbern(H \mid 0.6) 
  \\
  p(C_2) &amp;= 0.5 &amp; p(H \mid C_2) &amp;= \dbern(H \mid 0.4)
\end{align}
\]</span></p>
<p>The posterior probability of each coin given two tails is:</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(C_1 \mid TT )
  &amp;\propto
  p(TT \mid C_1) \cdot p(C_1)
  \\
  &amp;=
  \left(\frac{2}{5}\right)^2 \frac{1}{2}
  \\
  &amp;=
  \frac{2}{25}
\end{align}
\]</span> <span class="math display">\[
\begin{align}
  p(C_2 \mid TT )
  &amp;\propto
  p(TT \mid C_2) \cdot p(C_2)
  \\
  &amp;=
  \left(\frac{3}{5}\right)^2 \frac{1}{2}
  \\
  &amp;=
  \frac{9}{50}
\end{align}
\]</span></p>
<p>Both of the previous probabilities are normalised by the same constant. Since <span class="math inline">\(p(C_1 \mid TT) + p(C_2 \mid TT) = 1\)</span>, the normalising constant is <span class="math inline">\(\frac{2}{25} + \frac{9}{50} = \frac{13}{50}\)</span>. Thus</p>
<p class="mathjaxWide"><span class="math display">\[
p(C_1 \mid TT) = \frac{4}{13}
\qquad
\text{and}
\qquad
p(C_2 \mid TT) = \frac{9}{13}.
\]</span></p>
<p>Let <span class="math inline">\(y\)</span> be the number of additional spins until the next head. Conditional on a coin, <span class="math inline">\(y\)</span> is <a href="https://en.wikipedia.org/wiki/Geometric_distribution">geometrically</a> distributed. So the expected number of spins before the next head is:</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb E(y \mid TT)
  &amp;=
  \frac{4}{13}\mathbb E(y \mid C_1)
  +
  \frac{9}{13}\mathbb E(y \mid C_1)
  \\
  &amp;=
  \frac{4}{13}\frac{5}{3}
  +
  \frac{9}{13}\frac{5}{2}
  \\
  &amp;=
  \frac{20}{39}
  +
  \frac{45}{26}
  \\
  &amp;=
  \frac{175}{78},
\end{align}
\]</span></p>
<p>which is 2.24359.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 1</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_01.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_01.html</id>
    <published>2018-08-20T00:00:00Z</published>
    <updated>2018-08-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 1</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August 20, 2018  by Brian </br>
     Tags: <a href="/tags/stan.html">stan</a>, <a href="/tags/beta.html">beta</a>, <a href="/tags/binomial.html">binomial</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/bda.html">bda</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 1, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Let <span class="math inline">\(H\)</span> be the number of heads in 10 tosses of the coin. With a <span class="math inline">\(\dbeta(4, 4)\)</span> prior on the probability <span class="math inline">\(\theta\)</span> of a head, the posterior after finding out <span class="math inline">\(H \le 2\)</span> is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\theta \mid H \le 2)
  &amp;\propto
  p(H \le 2 \mid \theta) \cdot p(\theta)
  \\
  &amp;=
  \dbeta(\theta \mid 4, 4) \sum_{h = 0}^2 \dbinomial(h \mid \theta, 10)
  \\
  &amp;=
  \theta^3 (1 - \theta)^3 \sum_{h = 0}^2 \binom{10}{h} \theta^h (1 - \theta)^{10 - h}.
\end{align}
\]</span></p>
<p>We can plot this unnormalised posterior density from the following dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ex1 &lt;-<span class="st"> </span><span class="kw">tibble</span>(
         <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.01</span>), 
         <span class="dt">prior =</span> theta<span class="op">^</span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span><span class="dv">3</span>,
         <span class="dt">posterior =</span> prior <span class="op">*</span><span class="st"> </span>(
           <span class="kw">choose</span>(<span class="dv">10</span>, <span class="dv">0</span>) <span class="op">*</span><span class="st"> </span>theta<span class="op">^</span><span class="dv">0</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span><span class="dv">10</span> <span class="op">+</span>
<span class="st">           </span><span class="kw">choose</span>(<span class="dv">10</span>, <span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>theta<span class="op">^</span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span><span class="dv">9</span> <span class="op">+</span>
<span class="st">           </span><span class="kw">choose</span>(<span class="dv">10</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>theta<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span><span class="dv">8</span> 
         )
       )</code></pre></div>
<figure>
<img src="chapter_02_exercise_01_files/figure-markdown/ex1_plot-1.png" />
</figure>
<p>With the help of <a href="http://mc-stan.org/">Stan</a>, we can obtain the normalised posterior density. We include the information that there are at most 2 heads observed by using the (log) cumulative density function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span>rstan<span class="op">::</span><span class="kw">stan_model</span>(<span class="st">&#39;src/ex_02_01.stan&#39;</span>)</code></pre></div>
<pre><code>S4 class stanmodel &#39;ex_02_01&#39; coded as follows:
transformed data {
  int tosses = 10;
  int max_heads = 2;
}

parameters {
  real&lt;lower = 0, upper = 1&gt; theta;
}

model {
  theta ~ beta(4, 4); // prior 
  target += binomial_lcdf(max_heads | tosses, theta); // likelihood
} </code></pre>
<p>The following posterior has the same shape as our exact unnormalised density above. The difference is that we now have a normalised probability distribution without having to work out the maths ourselves.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f1 &lt;-<span class="st"> </span><span class="kw">sampling</span>(m1, <span class="dt">iter =</span> <span class="dv">40000</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">chains =</span> <span class="dv">1</span>)</code></pre></div>
<figure>
<img src="chapter_02_exercise_01_files/figure-markdown/ex1_stan_plot-1.png" />
</figure>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Understanding the hazard function</title>
    <link href="http://stappit.github.io/posts/survival_models/hazard.html" />
    <id>http://stappit.github.io/posts/survival_models/hazard.html</id>
    <published>2018-08-05T00:00:00Z</published>
    <updated>2018-08-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">Understanding the hazard function</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on August  5, 2018  by Brian </br>
     Tags: <a href="/tags/hazard.html">hazard</a>, <a href="/tags/censoring.html">censoring</a>, <a href="/tags/survival.html">survival</a>, <a href="/tags/exponential.html">exponential</a>, <a href="/tags/poisson.html">poisson</a> </br>
     Category: <a href="/categories/survival_models.html">survival_models</a> 
    </p>
  </div>
</div>

<p>Suppose you have fit a distribution to your censored survival times as in the <a href="./censoring.html">previous post</a> and now want to quantify the intuition of an event being imminent. For example, being able to characterise precisely when your customers are about to churn can help identify problem areas to improve on. This notion is called the <em>hazard</em>. We’ll take a look at some of its main properties and how it related to survival analysis.</p>
<!--more-->
<h2 id="definition">Definition</h2>
<p>Start with a small <span class="math inline">\(\delta\)</span>-interval around t and and consider the average probability density of an event ocurring in that interval given that it occurs after t: <span class="math inline">\(\frac{\mathbb P(t \le T &lt; t + \delta \mid t \le T)}{\delta}\)</span>, where <span class="math inline">\(\mathbb P\)</span> is the probability function. To get rid of the arbitrary choice of <span class="math inline">\(\delta\)</span>, we take the limit as <span class="math inline">\(\delta\)</span> goes to zero.</p>
<p class="mathjaxWide"><span class="math display">\[
h(t)
:=
\lim_{\delta \rightarrow 0} \frac{\mathbb P(t \le T &lt; t + \delta \mid t \le T)}{\delta}
.
\]</span></p>
<p>This is well-defined whenever the CDF is differentiable. Although it is defined in terms of probabilities, we will show below that the hazard is not itself a probability density function.</p>
<h2 id="identities">Identities</h2>
<p>There are a number of useful properties of the hazard function that make it convenient to work with in survival analysis.</p>
<h3 id="equivalent-definition">Equivalent definition</h3>
<p>The above definition helps us understand the intuition behind the hazard function but there’s an equivalent formulation that can be easier to work with. Using</p>
<ul>
<li>the definition of conditional probabilities,</li>
<li>the definition of a derivative, and</li>
<li>that <span class="math inline">\(F&#39;(t) = f(t)\)</span> where <span class="math inline">\(F\)</span> is the CDF and <span class="math inline">\(f\)</span> the probability function,</li>
</ul>
<p>we can show that</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  h(t)
  &amp;=
  \lim_{\delta \rightarrow 0} \frac{\mathbb P(t \le T &lt; t + \delta \mid t \le T)}{\delta}
  \\
  &amp;=\lim_{\delta \rightarrow 0} \frac{\mathbb P(t \le T &lt; t + \delta)}{\mathbb P(t \le T)\delta}
  \\
  &amp;=\lim_{\delta \rightarrow 0} \frac{F(t + \delta) - F(t)}{S(t)\delta}
  \\
  &amp;=\lim_{\delta \rightarrow 0} \frac{F(t + \delta) - F(t)}{\delta} \frac{1}{S(t)}
  \\
  &amp;= F&#39;(t) \frac{1}{S(t)}
  \\
  &amp;= \frac{f(t)}{S(t)}.
\end{align}
\]</span></p>
<p>We will show below how to use this to simplify the likelihood in the case of censored observations for measuring time to an event of interest.</p>
<h3 id="relation-with-the-survival-function">Relation with the survival function</h3>
<p>Using the identity above, we can rewrite the hazard as a derivative of the survival function:</p>
<p class="mathjaxWide"><span class="math display">\[
h(t)
=
\frac{f(t)}{S(t)}
=
-\frac{d}{dt} \log S(t)
.
\]</span></p>
<p>It then follows from the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_calculus">first fundamental theorem of calculus</a> that</p>
<p class="mathjaxWide"><span class="math display">\[
S(t) = e^{-\int_0^t h(s) ds}.
\]</span></p>
<p>In other words, the hazard function completely determines the survival function (and therefore also the mass/density function).</p>
<p>Since the integral of the hazard appears in the above equation, we can give it a definition for easier reference. We define the <em>cumulative hazard</em> as</p>
<p class="mathjaxWide"><span class="math display">\[
H(t) 
:=
\int_0^t h(s) ds
.
\]</span></p>
<p>Since <span class="math inline">\(\lim_{t \rightarrow \infty} S(t) = 0\)</span>, it follows that <span class="math inline">\(\lim_{t \rightarrow \infty} H(t) = -\lim \log S(t) = \infty\)</span>. In particular, this means that the hazard function is NOT a probability density function!</p>
<h3 id="example">Example</h3>
<p>The exponential distribution has constant hazard. To see this, suppose <span class="math inline">\(h(t) = \lambda\)</span>. Then <span class="math inline">\(S(t) = \exp(-\int_0^t \lambda ds) = \exp(-\lambda t)\)</span> so that <span class="math inline">\(f(t) = -S&#39;(t) = \lambda \exp(-\lambda t)\)</span>, which is the probability function for the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">exponential distribution</a>.</p>
<h2 id="hazard-in-censored-survival-analysis">Hazard in censored survival analysis</h2>
<p>In <a href="./censoring.html">the previous post</a>, we motivated the following likelihood in the case of censored survival times:</p>
<p class="mathjaxWide"><span class="math display">\[
L(\theta) 
:= 
\prod_{i = 1}^N \delta_i f(t_i \mid \theta)
\times
\prod_{i = 1}^N (1 - \delta_i) S(t_i \mid \theta)
\]</span></p>
<p>where <span class="math inline">\(\delta_i\)</span> is 1 if the event is observed and 0 if it is censored, and <span class="math inline">\(\theta\)</span> is the vector of parameters of the distribution of survival times. Since <span class="math inline">\(f(t) = h(t) S(t)\)</span>, we can rewrite this as</p>
<p class="mathjaxWide"><span class="math display">\[
L(\theta) 
:= 
\prod_{i = 1}^N h(t_i \mid \theta)^{\delta_i}S(t_i \mid \theta).
\]</span></p>
<h3 id="example-1">Example</h3>
<p>Assuming that survival times follow an exponential distribution, the hazard <span class="math inline">\(h(t) = \lambda\)</span> is constant, and the likelihood is</p>
<p class="mathjaxWide"><span class="math display">\[
  L(\lambda)
  = 
  \prod_{i = 1}^N \lambda^{\delta_i} e^{-\lambda t_i}
  =
  \lambda^D e^{-\lambda T}
\]</span></p>
<p>where <span class="math inline">\(D := \sum_1^N \delta_i\)</span> is the total number of events observed and <span class="math inline">\(T := \sum_1^N t_i\)</span> is the total observation time. This expression has an interesting interpretation as a <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson</a> likelihood. To see this, first note that <span class="math inline">\(T\)</span> and <span class="math inline">\(D\)</span> can be considered constant in our likelihood because they don’t depend on our only parameter <span class="math inline">\(\lambda\)</span>. We can consider <span class="math inline">\(D\)</span> as a Poisson variable with rate <span class="math inline">\(\lambda\)</span> and exposure <span class="math inline">\(T\)</span>:</p>
<p class="mathjaxWide"><span class="math display">\[
D \mid \lambda \sim \text{Poisson}(\lambda T),
\]</span></p>
<p>which gives probability of observing <span class="math inline">\(D\)</span> events as</p>
<p class="mathjaxWide"><span class="math display">\[
\text{Poisson}(D \mid \lambda T)
=
(\lambda T)^D e^{-\lambda T}
=
T^D L(\lambda)
.
\]</span></p>
<p>However, likelihoods are equivalent up to a multiplicative constant. Since <span class="math inline">\(T^D\)</span> is constant we can treat our likelihood, <span class="math inline">\(L\)</span>, as Poisson.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>

</feed>
