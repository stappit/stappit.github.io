<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Thoughts from the Café</title>
    <link href="http://stappit.github.io/atom.xml" rel="self" />
    <link href="http://stappit.github.io" />
    <id>http://stappit.github.io/atom.xml</id>
    <author>
        <name>Brian</name>
        <email>ha@hahaha.com</email>
    </author>
    <updated>2018-09-09T00:00:00Z</updated>
    <entry>
    <title>BDA3 Chapter 2 Exercise 22</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_22.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_22.html</id>
    <published>2018-09-09T00:00:00Z</published>
    <updated>2018-09-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 22</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  9, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/basketball.html">basketball</a>, <a href="/tags/prior%20choice.html">prior choice</a>, <a href="/tags/weakly%0Ainformative%20prior.html">weakly
informative prior</a>, <a href="/tags/noninformative%20prior.html">noninformative prior</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 22, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{Binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dpois}{Poisson} \DeclareMathOperator{\dnorm}{Normal} \DeclareMathOperator{\dcauchy}{Cauchy} \DeclareMathOperator{\dexponential}{Exp} \DeclareMathOperator{\dgamma}{Gamma} \DeclareMathOperator{\dinvgamma}{InvGamma} \DeclareMathOperator{\invlogit}{InvLogit} \DeclareMathOperator{\logit}{Logit} \DeclareMathOperator{\dbeta}{Beta}\)</span></p>
</div>
<p>Suppose you have a random sample of 100 college students in a basketball study. Each student takes 100 free-throws to establish a baseline success probability, <span class="math inline">\(\phi_0\)</span>. The students then take 50 practice free-throws per day for a month. After this month is up, each takes 100 shots for a final measurement of success probability, <span class="math inline">\(\phi_1\)</span>. We wish to estimate the increase in success probability, <span class="math inline">\(\theta := \phi_1 - \phi_0\)</span>.</p>
<p>We could use the uniform distribution on the range of theoretically possible values <span class="math inline">\([-1, 1]\)</span> as a ‘non-informative’ prior, i.e. every level of increase is equally likely.</p>
<figure>
<img src="chapter_02_exercise_22_files/figure-markdown/noninformative_prior-1..svg" />
</figure>
<p>To construct an informative prior, I had to do a bit of background reading as I have next to zero basketball knowledge. After some google-fu, it seems the <a href="https://www.basketball-reference.com/leaders/ft_pct_career.html">best of the best</a> have a free-throw success rate of around 80-90%, and the <a href="https://abcnews.go.com/Sports/free-throws-easy-consequences-failing/story?id=40769445">worst of the best</a> around 50-60%. This latter estimate probably lies on the upper extreme for random college students. From watching some <a href="https://www.youtube.com/watch?v=LFF6_5hyokU">free throw videos</a>, I would guess that I would have a success rate of about 10% (baseline).</p>
<p>Let’s model the baseline average as beta distributed around a mean of 10% and upper extreme below 40%.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu0 &lt;-<span class="st"> </span><span class="fl">0.10</span>
n0 &lt;-<span class="st"> </span><span class="dv">15</span>

alpha0 &lt;-<span class="st"> </span>mu0 <span class="op">*</span><span class="st"> </span>n0
beta0 &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mu0) <span class="op">*</span><span class="st"> </span>n0

<span class="kw">tibble</span>(
    <span class="dt">p =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.01</span>),
    <span class="dt">density =</span> <span class="kw">dbeta</span>(p, alpha0, beta0)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(p, density) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">fill =</span> <span class="st">&#39;skyblue&#39;</span>, <span class="dt">colour =</span> <span class="st">&#39;white&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Average baseline success probability&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Density&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Baseline success probability simulation&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;Beta({alpha0}, {beta0})&#39;</span>)
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_22_files/figure-markdown/baseline_simulation-1..svg" />
</figure>
<p>With this assumption, there is a 0.286% chance of an average above 40%.</p>
<p>For the final estimate, the improvement could be quite significant given that random students are likely untrained (the better you get, the harder it is to improve). An average 15%% improvement seems plausible to me.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu1 &lt;-<span class="st"> </span>mu0 <span class="op">+</span><span class="st"> </span><span class="fl">0.15</span>
n1 &lt;-<span class="st"> </span><span class="dv">20</span>

alpha1 &lt;-<span class="st"> </span>mu1 <span class="op">*</span><span class="st"> </span>n1
beta1 &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mu1) <span class="op">*</span><span class="st"> </span>n1

<span class="kw">tibble</span>(
    <span class="dt">p =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.01</span>),
    <span class="dt">density =</span> <span class="kw">dbeta</span>(p, alpha1, beta1)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(p, density) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">fill =</span> <span class="st">&#39;skyblue&#39;</span>, <span class="dt">colour =</span> <span class="st">&#39;white&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Average final success probability&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Density&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Final success probability simulation&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;Beta({alpha1}, {beta1})&#39;</span>)
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_22_files/figure-markdown/final_simulation-1..svg" />
</figure>
<p>With the above assumptions, the distribution of the average increase is shown below. The bulk of the mass is above 0, which makes sense as most should improve through practice. There is also some chance of a decrease, with -25%% being fairly extreme.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">increase &lt;-<span class="st"> </span><span class="kw">tibble</span>(
    <span class="dt">phi0 =</span> <span class="kw">rbeta</span>(<span class="dv">10000</span>, alpha0, beta0),
    <span class="dt">phi1 =</span> <span class="kw">rbeta</span>(<span class="dv">10000</span>, alpha1, beta1),
    <span class="dt">theta =</span> phi1 <span class="op">-</span><span class="st"> </span>phi0
  ) 

increase <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">aes</span>(theta) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&#39;skyblue&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">colour =</span> <span class="st">&#39;dark orange&#39;</span>, <span class="dt">linetype =</span> <span class="st">&#39;dashed&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.2</span>), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Average increase in success probability (percentage points)&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Count&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Average increase in success probability simulation&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;Beta({alpha1}, {beta1}) - Beta({alpha0}, {beta0})&#39;</span>)
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_22_files/figure-markdown/increase_simulation-1..svg" />
</figure>
<p>We could approximate this as a beta distribution on <span class="math inline">\([-1, 1]\)</span> to ensure the prior is bounded. In this case, we can probably get away with using a normal distribution since the probability of exceeding the bounds is negligible.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span>mu1 <span class="op">-</span><span class="st"> </span>mu0
sigma &lt;-<span class="st"> </span><span class="kw">sd</span>(increase<span class="op">$</span>theta)

<span class="kw">tibble</span>(
    <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.01</span>),
    <span class="dt">density =</span> <span class="kw">dnorm</span>(theta, mu, sigma)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(theta, density) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">fill =</span> <span class="st">&#39;skyblue&#39;</span>, <span class="dt">colour =</span> <span class="st">&#39;white&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">colour =</span> <span class="st">&#39;dark orange&#39;</span>, <span class="dt">linetype =</span> <span class="st">&#39;dashed&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.25</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Average increase in success probability (percentage points)&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Density&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Strongly informative prior&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;Normal(μ = {signif(mu, digits = 2)}, σ = {signif(sigma, digits = 2)})&#39;</span>)
  ) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<figure>
<img src="chapter_02_exercise_22_files/figure-markdown/informative_prior-1..svg" />
</figure>
<p>The probability that this normal distribution exceeds 1 is 0.000000000104%. A subjective prior for the average increase in success probability would thus be a <span class="math inline">\(\dnorm(0.15, 0.12)\)</span> prior.</p>
<p>Finally, let’s construct a weakly informative prior. We’ll again use the beta distribution scaled to the interval <span class="math inline">\([-1, 1]\)</span>, with a mean of 0 so that an increase can be entirely attributed to the data and not to the prior. Since the best of the pros have a success probability around 90%, we’d expect the increase of 100 random students to be below this value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha &lt;-<span class="st"> </span><span class="dv">5</span>
beta &lt;-<span class="st"> </span><span class="dv">5</span>

<span class="kw">tibble</span>(
    <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.01</span>),
    <span class="dt">density =</span> <span class="kw">dbeta</span>(<span class="fl">0.5</span> <span class="op">+</span><span class="st"> </span>theta <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, alpha, beta)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(theta, density) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">fill =</span> <span class="st">&#39;skyblue&#39;</span>, <span class="dt">colour =</span> <span class="st">&#39;white&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">colour =</span> <span class="st">&#39;dark orange&#39;</span>, <span class="dt">linetype =</span> <span class="st">&#39;dashed&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.25</span>), <span class="dt">labels =</span> percent) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Average increase in success probability (percentage points)&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Density&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Weakly informative prior&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;Beta({alpha}, {beta})&#39;</span>)
  ) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<figure>
<img src="chapter_02_exercise_22_files/figure-markdown/weakly_informative_prior-1..svg" />
</figure>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 21</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_21.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_21.html</id>
    <published>2018-09-09T00:00:00Z</published>
    <updated>2018-09-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 21</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  9, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/poisson.html">poisson</a>, <a href="/tags/gamma.html">gamma</a>, <a href="/tags/exposure.html">exposure</a>, <a href="/tags/election.html">election</a>, <a href="/tags/usa.html">usa</a>, <a href="/tags/obama.html">obama</a>, <a href="/tags/pew%20research%20center.html">pew research center</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 21, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{Binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dpois}{Poisson} \DeclareMathOperator{\dnorm}{Normal} \DeclareMathOperator{\dcauchy}{Cauchy} \DeclareMathOperator{\dexponential}{Exp} \DeclareMathOperator{\dgamma}{Gamma} \DeclareMathOperator{\dinvgamma}{InvGamma} \DeclareMathOperator{\invlogit}{InvLogit} \DeclareMathOperator{\logit}{Logit} \DeclareMathOperator{\dbeta}{Beta}\)</span></p>
</div>
<p>I wasn’t able to find any of the data for this question on the book’s website (as indicated in the book). However, the data are available on the <a href="http://www.people-press.org/2008/11/02/november-2008-election-weekend-survey/">Pew Research Center website</a>. I am unsure if the Pew version is the same as the version intended in the book.</p>
<h2 id="data-inspection">Data inspection</h2>
<h3 id="loading">Loading</h3>
<p>Unzipping the download into my local <code>data</code> directory gives three files of interest:</p>
<ul>
<li><p><code>ElectWkd08c.sav</code></p>
<p>The dataset in SPSS format.</p></li>
<li><p><code>ElecWknd08.que.doc</code></p>
<p>A description of the survey questions and their column names in the dataset.</p></li>
<li><p><code>readme.txt</code></p>
<p>A description of the columns in the dataset derived from the survey questions.</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(foreign)

df0 &lt;-<span class="st"> </span><span class="kw">read.spss</span>(<span class="dt">file =</span> <span class="st">&#39;data/ElectWkd08c.sav&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>()

df0 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nrow</span>()</code></pre></div>
<pre><code>[1] 3402</code></pre>
<p>There are many columns.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">colnames</span>()</code></pre></div>
<pre><code>  [1] &quot;psraid&quot;    &quot;attempt&quot;   &quot;fcall&quot;     &quot;refusal&quot;   &quot;int_date&quot; 
  [6] &quot;area&quot;      &quot;scregion&quot;  &quot;sfips&quot;     &quot;sstate&quot;    &quot;cdist&quot;    
 [11] &quot;msa&quot;       &quot;usr&quot;       &quot;usr1&quot;      &quot;sampzip&quot;   &quot;pdsgen&quot;   
 [16] &quot;pdsrace&quot;   &quot;zfips&quot;     &quot;zstate&quot;    &quot;zcregion&quot;  &quot;zdensity3&quot;
 [21] &quot;sdensity3&quot; &quot;file&quot;      &quot;sample&quot;    &quot;sex&quot;       &quot;qs1&quot;      
 [26] &quot;thought&quot;   &quot;q1&quot;        &quot;voter&quot;     &quot;regist&quot;    &quot;regicert&quot; 
 [31] &quot;planreg&quot;   &quot;precinct&quot;  &quot;q2&quot;        &quot;oftvote&quot;   &quot;where&quot;    
 [36] &quot;horse&quot;     &quot;q3&quot;        &quot;q3_1&quot;      &quot;q3_2&quot;      &quot;q3_3&quot;     
 [41] &quot;q3a&quot;       &quot;q3a_1&quot;     &quot;q3a_2&quot;     &quot;q3a_3&quot;     &quot;q3summ&quot;   
 [46] &quot;q3summ2&quot;   &quot;q3tot&quot;     &quot;q3atot&quot;    &quot;q3horse&quot;   &quot;q3b&quot;      
 [51] &quot;q3bfilt&quot;   &quot;q5&quot;        &quot;q6&quot;        &quot;swing&quot;     &quot;plan1&quot;    
 [56] &quot;plan2&quot;     &quot;plan3&quot;     &quot;q7&quot;        &quot;q8&quot;        &quot;q9&quot;       
 [61] &quot;q10a&quot;      &quot;q10b&quot;      &quot;q10c&quot;      &quot;q10d&quot;      &quot;q10e&quot;     
 [66] &quot;q10f&quot;      &quot;q10g&quot;      &quot;q10de&quot;     &quot;q11&quot;       &quot;q12&quot;      
 [71] &quot;q13&quot;       &quot;q14&quot;       &quot;q15&quot;       &quot;q15_1&quot;     &quot;q15_2&quot;    
 [76] &quot;q15_3&quot;     &quot;Q15tot&quot;    &quot;q16&quot;       &quot;q16a&quot;      &quot;q17&quot;      
 [81] &quot;age&quot;       &quot;recage&quot;    &quot;educ&quot;      &quot;receduc&quot;   &quot;hisp1&quot;    
 [86] &quot;race_1&quot;    &quot;race_2&quot;    &quot;race_3&quot;    &quot;race_4&quot;    &quot;racecmb&quot;  
 [91] &quot;racethn&quot;   &quot;marital&quot;   &quot;parent&quot;    &quot;relig&quot;     &quot;religos&quot;  
 [96] &quot;chr&quot;       &quot;born&quot;      &quot;attend&quot;    &quot;income&quot;    &quot;party&quot;    
[101] &quot;partyln&quot;   &quot;ideo&quot;      &quot;class&quot;     &quot;employ&quot;    &quot;pvote04a&quot; 
[106] &quot;pvote04b&quot;  &quot;primary&quot;   &quot;first1&quot;    &quot;first2&quot;    &quot;scale10&quot;  
[111] &quot;labor&quot;     &quot;ql1&quot;       &quot;ql2&quot;       &quot;qc1&quot;       &quot;qc2&quot;      
[116] &quot;zipcode&quot;   &quot;money10&quot;   &quot;website&quot;   &quot;isex&quot;      &quot;ihisp1&quot;   
[121] &quot;irace_1&quot;   &quot;irace_2&quot;   &quot;irace_3&quot;   &quot;irace_4&quot;   &quot;iraceth&quot;  
[126] &quot;iracecmb&quot;  &quot;regfinal&quot;  &quot;ballot&quot;    &quot;mccain&quot;    &quot;obama&quot;    
[131] &quot;sameday&quot;   &quot;battle&quot;    &quot;phoneuse&quot;  &quot;filter_$&quot;  &quot;lvs&quot;      
[136] &quot;lvswt67&quot;   &quot;llweight&quot;  &quot;coweight&quot;  &quot;wt_weth&quot;   &quot;wt_thfr&quot;  
[141] &quot;wt_frsa&quot;   &quot;wt_wefr&quot;   &quot;weight&quot;    &quot;unlvwt67&quot; </code></pre>
<h3 id="state">State</h3>
<p>For each state, we want to know how many label themselves as <code>Very liberal</code> and how many report supporting Obama. The state is given by the <code>sstate</code> column and doesn’t include Hawaii or Alaska.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(sstate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(<span class="kw">reorder</span>(sstate, n), n) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;State&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Respondents&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Responses by state&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;There are {df0 %&gt;% distinct(sstate) %&gt;% nrow()} states in the dataset&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;Source: http://www.people-press.org/2008/11/02/november-2008-election-weekend-survey/&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/state_count-1..svg" />
</figure>
<h3 id="ideology">Ideology</h3>
<p>Consulting the documentation, we see that liberality is given by the <code>ideo</code> column.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(ideo) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Ideology&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Respondents&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Responses by ideology&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;There are {df0 %&gt;% distinct(ideo) %&gt;% nrow()} ideologies in the dataset&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;Source: http://www.people-press.org/2008/11/02/november-2008-election-weekend-survey/&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/ideo_count-1..svg" />
</figure>
<h3 id="obama-voters">Obama voters</h3>
<p>The data indicating vote is not so obvious. There is</p>
<ul>
<li>current voting preference in question 3, of which there are different versions for different states;</li>
<li>there are various columns derived from the survey responses to question 3, such as <code>q3horse</code>;</li>
<li>there is question 6 which asks for voting intention in November; and</li>
<li>there is a column called <code>obama</code> for which I couldn’t find any documentation.</li>
</ul>
<p>Despite the lack of documentation, I’ll run with <code>obama</code> since the responses seem to align better with the purpose of the exercise.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(obama) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Vote&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Respondents&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Responses by vote&#39;</span>,
    <span class="dt">subtitle =</span> <span class="kw">str_glue</span>(<span class="st">&#39;There are {df0 %&gt;% distinct(obama) %&gt;% nrow()} voting intentions in the dataset&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;Source data: http://www.people-press.org/2008/11/02/november-2008-election-weekend-survey/&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/vote_count-1..svg" />
</figure>
<h3 id="data-augmentation">Data augmentation</h3>
<p>In order to display two-letter abbreviations of the states, we use the data provided by the <code>state</code> package and join it to the Pew dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mapping &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">name =</span> <span class="kw">as_factor</span>(state.name, <span class="dt">levels =</span> <span class="kw">levels</span>(df<span class="op">$</span>sstate)), 
  <span class="dt">abbreviation =</span> state.abb
)

df &lt;-<span class="st"> </span>df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(mapping, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&#39;sstate&#39;</span> =<span class="st"> &#39;name&#39;</span>))</code></pre></div>
<p>Here’s a sample from the mapping table.</p>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
name
</th>
<th style="text-align:left;">
abbreviation
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Alabama
</td>
<td style="text-align:left;">
AL
</td>
</tr>
<tr>
<td style="text-align:left;">
Alaska
</td>
<td style="text-align:left;">
AK
</td>
</tr>
<tr>
<td style="text-align:left;">
Arizona
</td>
<td style="text-align:left;">
AZ
</td>
</tr>
<tr>
<td style="text-align:left;">
Arkansas
</td>
<td style="text-align:left;">
AR
</td>
</tr>
<tr>
<td style="text-align:left;">
California
</td>
<td style="text-align:left;">
CA
</td>
</tr>
<tr>
<td style="text-align:left;">
Colorado
</td>
<td style="text-align:left;">
CO
</td>
</tr>
</tbody>
</table>
<h2 id="ideology-vs.obama-voter">Ideology vs. Obama voter</h2>
<h3 id="raw-proportions">Raw proportions</h3>
<p>Let’s take a look at how the proportion of liberals relates to the proportion of Obama voters. There seems to be a positive relation, although the data are fairly noisy. Plotting the full range of values on the y-axis makes the noise more prominent. We only show the resticted range in order to show the individual state names.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qa &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(sstate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">respondents =</span> <span class="kw">n</span>(),
    <span class="dt">liberals =</span> <span class="kw">sum</span>(ideo <span class="op">==</span><span class="st"> &#39;Very liberal&#39;</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),
    <span class="dt">liberal_proportion =</span> liberals <span class="op">/</span><span class="st"> </span>respondents,
    <span class="dt">obama_voters =</span> <span class="kw">sum</span>(obama <span class="op">==</span><span class="st"> &#39;Obama voter&#39;</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),
    <span class="dt">obama_vote_share =</span> obama_voters <span class="op">/</span><span class="st"> </span>respondents  
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(mapping, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&#39;sstate&#39;</span> =<span class="st"> &#39;name&#39;</span>))

qa <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">y =</span> liberal_proportion, <span class="dt">x =</span> obama_vote_share) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> abbreviation, <span class="dt">alpha =</span> <span class="kw">log</span>(respondents)), <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">hjust =</span> <span class="op">-</span><span class="fl">0.1</span>, <span class="dt">vjust =</span> <span class="op">-</span><span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">y =</span> <span class="st">&#39;Observed proportion of liberals&#39;</span>,
    <span class="dt">x =</span> <span class="st">&#39;Obama vote share&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Obama vote share vs liberal proportion for each state&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;The y-axis is truncated so that the labels are readable&#39;</span>,
    <span class="dt">caption =</span> <span class="st">&#39;Source data: http://www.people-press.org/2008/11/02/november-2008-election-weekend-survey/&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/state_liberal_vs_obama-1..svg" />
</figure>
<h3 id="posterior-inference">Posterior inference</h3>
<p>We’ll base our prior on the data (for convenience) and don’t take survey non-response issues into account. The pooled mean proportion of liberals will be our prior mean.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="kw">sum</span>(df<span class="op">$</span>ideo <span class="op">==</span><span class="st"> &#39;Very liberal&#39;</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>) <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(df)
<span class="kw">percent</span>(mu)</code></pre></div>
<pre><code>[1] &quot;3.5%&quot;</code></pre>
<p>After trying various possibilities for the standard deviation <code>sigma</code>, the value below results in a prior that puts most of the density between 0% and 18%.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sigma &lt;-<span class="st"> </span><span class="fl">0.04</span>

shape &lt;-<span class="st"> </span>(mu <span class="op">/</span><span class="st"> </span>sigma)<span class="op">^</span><span class="dv">2</span>
rate &lt;-<span class="st"> </span>shape <span class="op">/</span><span class="st"> </span>mu

<span class="kw">tibble</span>(
    <span class="dt">prop =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="fl">0.0005</span>),
    <span class="dt">density =</span> <span class="kw">dgamma</span>(prop, shape, rate)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(prop, density) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">fill =</span> <span class="st">&#39;skyblue&#39;</span>, <span class="dt">colour =</span> <span class="st">&#39;white&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.3</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Proportion of liberals&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Density&#39;</span>,
    <span class="dt">title =</span> <span class="kw">str_glue</span>(<span class="kw">paste</span>(
      <span class="st">&#39;Gamma(shape = {signif(shape, digits = 2)}, rate = {signif(rate, digits = 2)})&#39;</span>,
      <span class="dt">sep =</span> <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>
    ))
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/prior-1..svg" />
</figure>
<p>Let’s add the posterior means to our dataset and plot the them against proportion of Obama voters. In order to be visually comparable to the plot of observed data, we keep the limits of the axes the same.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qa_posterior &lt;-<span class="st"> </span>qa <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">posterior_shape =</span> shape <span class="op">+</span><span class="st"> </span>liberals,
    <span class="dt">posterior_rate =</span> rate <span class="op">+</span><span class="st"> </span>respondents,
    <span class="dt">posterior_mean =</span> posterior_shape <span class="op">/</span><span class="st"> </span>posterior_rate
  )

qa_posterior <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">y =</span> posterior_mean, <span class="dt">x =</span> obama_vote_share) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> abbreviation, <span class="dt">alpha =</span> <span class="kw">log</span>(respondents)), <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">hjust =</span> <span class="op">-</span><span class="fl">0.1</span>, <span class="dt">vjust =</span> <span class="op">-</span><span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">y =</span> <span class="st">&#39;Posterior mean of proportion of liberals&#39;</span>,
    <span class="dt">x =</span> <span class="st">&#39;Obama vote share&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Obama vote share vs estimate of liberal proportion&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/posterior-1..svg" />
</figure>
<p>The posterior 95% credible intervals are shown below. Arizona and Louisianna seem to have a smaller proportional of liberals compared to the country average. Only Oregon’s credible interval is entirely above the country average.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qa_posterior <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">ci =</span> <span class="kw">map2</span>(
      posterior_shape, 
      posterior_rate, 
      <span class="cf">function</span>(s, r) 
        <span class="kw">tibble</span>(
          <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&#39;lower&#39;</span>, <span class="st">&#39;upper&#39;</span>),
          <span class="dt">value =</span> <span class="kw">qgamma</span>(<span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>), s, r)
        ) 
    )
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(ci) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(type, value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> mu, <span class="dt">linetype =</span> <span class="st">&#39;dotted&#39;</span>, <span class="dt">colour =</span> <span class="st">&#39;orange&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(<span class="kw">reorder</span>(sstate, posterior_mean), posterior_mean) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> lower, <span class="dt">ymax =</span> upper), <span class="dt">fatten =</span> <span class="fl">0.1</span>, <span class="dt">size =</span> <span class="fl">0.4</span>)  <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">y =</span> <span class="st">&#39;Posterior value&#39;</span>,
    <span class="dt">x =</span> <span class="st">&#39;State&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;95% credible intervals for the proportion of liberals per state&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;The pooled observed mean value is shown in orange&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/ci-1..svg" />
</figure>
<p>All of the states in which no liberals were observed had smaller sample sizes (below 50). The largest proportions were also observed in the states with sample sizes below 50. This plot looks fairly similar to the analogous plot for the cancer rate example, albeit with fewer data points.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qa <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(respondents, liberal_proportion) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> abbreviation, <span class="dt">alpha =</span> <span class="kw">log</span>(respondents)), <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">hjust =</span> <span class="op">-</span><span class="fl">0.1</span>, <span class="dt">vjust =</span> <span class="op">-</span><span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Number of respondents&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Observed proportion of liberals&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Observed proportion of liberals per state&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/observed_prop_vs_num_respondents-1..svg" />
</figure>
<p>The posterior estimates result in much less extreme values for the states with few respondents.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qa_posterior <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">aes</span>(respondents, posterior_mean) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> abbreviation, <span class="dt">alpha =</span> <span class="kw">log</span>(respondents)), <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">hjust =</span> <span class="op">-</span><span class="fl">0.1</span>, <span class="dt">vjust =</span> <span class="op">-</span><span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Number of respondents&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Posterior mean of proportion of liberals&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Posterior proportion of liberals by state&#39;</span>
  )</code></pre></div>
<figure>
<img src="chapter_02_exercise_21_files/figure-markdown/posterior_prop_vs_num_respondents-1..svg" />
</figure>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 20</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_20.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_20.html</id>
    <published>2018-09-08T00:00:00Z</published>
    <updated>2018-09-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 20</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  8, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/exponential.html">exponential</a>, <a href="/tags/gamma.html">gamma</a>, <a href="/tags/truncated%0Aobservations.html">truncated
observations</a>, <a href="/tags/posterior%20variance.html">posterior variance</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 20, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{Binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dpois}{Poisson} \DeclareMathOperator{\dnorm}{Normal} \DeclareMathOperator{\dcauchy}{Cauchy} \DeclareMathOperator{\dexponential}{Exp} \DeclareMathOperator{\dgamma}{Gamma} \DeclareMathOperator{\dinvgamma}{InvGamma} \DeclareMathOperator{\invlogit}{InvLogit} \DeclareMathOperator{\logit}{Logit} \DeclareMathOperator{\dbeta}{Beta}\)</span></p>
</div>
<p>Suppose <span class="math inline">\(y \mid \theta \sim \dexponential(\theta)\)</span> with prior <span class="math inline">\(\theta \sim \dgamma(\alpha, \beta)\)</span>. If we observe that <span class="math inline">\(y \ge 100\)</span>, then the posterior is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\theta \mid y \ge 100)
  &amp;\propto
  \theta^{\alpha - 1} e^{-\beta \theta}
  \int_{y = 100}^\infty \theta e^{-\theta y} dy
  \\
  &amp;=
  \theta^{\alpha - 1} e^{-\beta \theta}
  \left[ (-1) e^{-\theta y}  \right]_{100}^\infty
  \\
  &amp;=
  \theta^{\alpha - 1} e^{-\beta \theta}
  e^{-100\theta}
  \\
  &amp;=
  \theta^{\alpha - 1} e^{-(\beta + 100) \theta}
  ,
\end{align}
\]</span></p>
<p>which is a <span class="math inline">\(\dgamma(\alpha, \beta + 100)\)</span> distribution. The posterior mean is <span class="math inline">\(\frac{\alpha}{\beta + 100}\)</span> and the posterior variance is <span class="math inline">\(\frac{\alpha}{(\beta + 100)^2}\)</span>.</p>
<p>If instead we had observed <span class="math inline">\(y = 100\)</span>, the posterior would have been</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\theta \mid y = 100)
  &amp;\propto
  \theta^{\alpha - 1} e^{-\beta \theta}
  \theta e^{-\theta 100} 
  \\
  &amp;=
  \theta^{\alpha} e^{-(\beta + 100) \theta}
  ,
\end{align}
\]</span></p>
<p>which is a <span class="math inline">\(\dgamma(\alpha + 1, \beta + 100)\)</span> distribution. The posterior mean here is <span class="math inline">\(\frac{\alpha + 1}{\beta + 100}\)</span> and the posterior variance is <span class="math inline">\(\frac{\alpha + 1}{(\beta + 100)^2}\)</span>.</p>
<p>Both of these estimates are greater than in the case of observing <span class="math inline">\(y \ge 100\)</span>. This is surprising because knowing that <span class="math inline">\(y = 100\)</span> is more informative than just knowing <span class="math inline">\(y \ge 100\)</span>. The reason there is actually less variance when <span class="math inline">\(y \ge 100\)</span> is that we get to average over all possibilities of <span class="math inline">\(y \ge 100\)</span>, and the case <span class="math inline">\(y = 100\)</span> has the greatest variance of all these possibilities.</p>
<p>We can illustrate this idea more formally using identity (2.8). In the context of this exercise, the identity can be written</p>
<p class="mathjaxWide"><span class="math display">\[
\mathbb V \left(\theta \mid y \ge 100 \right)
\ge
\mathbb E \left( \mathbb V \left(\theta \mid y \right) \mid y \ge 100 \right)
,
\]</span></p>
<p>where all the probabilities are now conditional on <span class="math inline">\(y \ge 100\)</span>. The left hand side is the posterior variance given <span class="math inline">\(y \ge 100\)</span>, which we calculated above to be <span class="math inline">\(\frac{\alpha}{(\beta + 100)^2}\)</span>. The quantity <span class="math inline">\(\mathbb E ( \mathbb V (\theta \mid y = 100) \mid y \ge 100)\)</span> is just <span class="math inline">\(\frac{\alpha + 1}{(\beta + 100)^2}\)</span> as shown above, which is greater than the LHS. However, this quantity is fundamentally different to what the right hand side of the identity expresses. The RHS actually evaluates to</p>
<p class="mathjaxWide"><span class="math display">\[
\int_{100}^\infty \frac{\alpha}{(\beta + \tilde y)^2} p(\tilde y \mid y \ge 100) d\tilde y.
\]</span></p>
<p>That is, it averages over all possible realisations of the variance given <span class="math inline">\(y \ge 100\)</span>. The inequality only guarantees that the posterior variance is <em>on average</em> smaller than the prior variance, so we can’t just plug in one value of interest.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 19</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_19.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_19.html</id>
    <published>2018-09-08T00:00:00Z</published>
    <updated>2018-09-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 19</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  8, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/gamma.html">gamma</a>, <a href="/tags/exponential.html">exponential</a>, <a href="/tags/conjugate%20prior.html">conjugate prior</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 19, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{Binomial}  \DeclareMathOperator{\dbern}{Bernoulli}  \DeclareMathOperator{\dpois}{Poisson}  \DeclareMathOperator{\dnorm}{Normal}  \DeclareMathOperator{\dcauchy}{Cauchy}  \DeclareMathOperator{\dexponential}{Exp}  \DeclareMathOperator{\dgamma}{Gamma}  \DeclareMathOperator{\dinvgamma}{InvGamma}  \DeclareMathOperator{\invlogit}{InvLogit}  \DeclareMathOperator{\logit}{Logit}  \DeclareMathOperator{\dbeta}{Beta}\)</span></p>
</div>
<p>Let’s show that the gamma distribution is conjugate to the exponential distribution. That is, we suppose <span class="math inline">\(y \mid \theta \sim \dexponential(\theta)\)</span> with prior <span class="math inline">\(\theta \sim \dgamma(\alpha, \beta)\)</span>, and show that the posterior is also gamma distributed.</p>
<p>The posterior is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\theta \mid y)
  &amp;\propto
  \theta^n e^{-\theta \sum_1^n y_i} \cdot \theta^{\alpha - 1} e^{-\beta \theta}
  \\
  &amp;=
  \theta^{n + \alpha - 1} e^{-\theta \left(\beta + \sum_1^n y_i \right)}
\end{align}
\]</span></p>
<p>which implies <span class="math inline">\(\theta \mid y \sim \dgamma(\alpha + n, \beta + \sum_1^n y_i)\)</span>.</p>
<p>Suppose now that we wish to do inference on <span class="math inline">\(\phi := \theta^{-1}\)</span>. We will show that <span class="math inline">\(\phi\)</span> has an inverse gamma distribution if <span class="math inline">\(\theta\)</span> has a gamma distribution. Indeed,</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\phi)
  &amp;\propto
  p(\theta) \left\vert {\frac{d\phi}{d\theta}} \right\vert^{-1}
  \\
  &amp;=
  \theta^{\alpha - 1} e^{-\beta \theta} \cdot\theta^2
  \\
  &amp;=
  \phi^{-\alpha - 1} e^{-\frac{\beta}{\phi}}
  ,
\end{align}
\]</span></p>
<p>which corresponds to an <span class="math inline">\(\dinvgamma(\alpha, \beta)\)</span> distribution.</p>
<p>Suppose that the lifetime of a light bulb can be modelled as an exponential distribution with rate <span class="math inline">\(\theta\)</span>. Let’s compare inferences using the two different parameterisations above. For <span class="math inline">\(\theta \sim \dgamma(\alpha, \beta)\)</span>, the prior variance is <span class="math inline">\(\frac{\alpha}{\beta^2}\)</span> and the mean is <span class="math inline">\(\frac{\alpha}{\beta}\)</span>, so the prior coefficient of variation is <span class="math inline">\(\alpha^{-\frac{1}{2}}\)</span>. We are given that the prior coefficient of variation is 0.5, so <span class="math inline">\(\alpha = 4\)</span>. The posterior coefficient of variation is <span class="math inline">\((4 + n)^{-\frac{1}{2}}\)</span>. If we wish this to be at most 0.1, then we would need to test at least <span class="math inline">\(n = 96\)</span> light bulbs.</p>
<p>For <span class="math inline">\(\phi \sim \dinvgamma(\alpha, \beta)\)</span>, the prior variance is</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{\beta^2}{(\alpha - 1)^2 (\alpha - 2)}
\]</span></p>
<p>and the mean is <span class="math inline">\(\frac{\beta}{\alpha - 1}\)</span>, so the prior coefficient of variation is <span class="math inline">\((\alpha - 2)^{-\frac{1}{2}}\)</span>. With a prior coefficient of variation is 0.5, we have <span class="math inline">\(\alpha = 6\)</span>. The posterior coefficient of variation is <span class="math inline">\((6 + n)^{-\frac{1}{2}}\)</span>. If we wish this to be at most 0.1, then we would need to test at least <span class="math inline">\(n = 94\)</span> light bulbs.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 18</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_18.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_18.html</id>
    <published>2018-09-08T00:00:00Z</published>
    <updated>2018-09-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 18</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  8, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/gamma.html">gamma</a>, <a href="/tags/poisson.html">poisson</a>, <a href="/tags/conjugate%20prior.html">conjugate prior</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 18, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial}  \DeclareMathOperator{\dbern}{Bernoulli}  \DeclareMathOperator{\dpois}{Poisson}  \DeclareMathOperator{\dnorm}{normal}  \DeclareMathOperator{\dcauchy}{Cauchy}  \DeclareMathOperator{\dgamma}{gamma}  \DeclareMathOperator{\invlogit}{invlogit}  \DeclareMathOperator{\logit}{logit}  \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Suppose we have <span class="math inline">\(n\)</span> observations from a Poisson likelihood, <span class="math inline">\(y_i \mid \theta \sim \dpois(x_i\theta)\)</span>, with rate <span class="math inline">\(\theta\)</span> and exposure <span class="math inline">\(x_i\)</span>. We show that with a gamma prior, <span class="math inline">\(\theta \sim \dgamma(\alpha, \beta)\)</span>, the posterior also has a gamma distribution.</p>
<p>As shown in the book, the likelihood and prior are</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
p (y \mid \theta)
&amp;\propto
\theta^{\sum_1^n y_i} e^{-\theta \sum_i^n x_i}
\\
p(\theta)
&amp;\propto
\theta^{\alpha - 1} e^{-\beta \theta}
.
\end{align}
\]</span></p>
<p>Thus the posterior is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
p (\theta \mid y)
&amp;\propto
\theta^{\sum_1^n y_i} e^{-\theta \sum_i^n x_i}
\cdot
\theta^{\alpha - 1} e^{-\beta \theta}
\\
&amp;=
\theta^{\alpha - 1 + \sum_1^n y_i}
e^{-\theta \left( \beta + \sum_1^n x_i \right)}
,
\end{align}
\]</span></p>
<p>which shows that <span class="math inline">\(p(\theta \mid y) \sim \dgamma(\alpha + \sum_1^n y_i, \beta + \sum_1^n x_i)\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 17</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_17.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_17.html</id>
    <published>2018-09-08T00:00:00Z</published>
    <updated>2018-09-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 17</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  8, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/chi2.html">chi2</a>, <a href="/tags/highest%20posterior%20interval.html">highest posterior interval</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 17, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial}  \DeclareMathOperator{\dbern}{Bernoulli}  \DeclareMathOperator{\dpois}{Poisson}  \DeclareMathOperator{\dnorm}{normal}  \DeclareMathOperator{\dcauchy}{Cauchy}  \DeclareMathOperator{\dgamma}{gamma}  \DeclareMathOperator{\invlogit}{invlogit}  \DeclareMathOperator{\logit}{logit}  \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>We’ll show that highest posterior invervals are not invariant under parameter transformations.</p>
<p>Suppose <span class="math inline">\(\frac{nv}{\sigma^2} \mid \sigma^2 \sim \chi_n^2\)</span> with (improper) prior <span class="math inline">\(\sigma \propto \sigma^{-1}\)</span>. From equation (2.19), page 52, the prior density for <span class="math inline">\(\sigma^2\)</span> is</p>
<p class="mathjaxWide"><span class="math display">\[
p(\sigma^2) 
=
p(\sigma) (2\sigma)^{-1}
\propto
\frac{1}{\sigma^2}
.
\]</span></p>
<p>Thus the posteriors are</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(\sigma^2 \mid y) 
  &amp;=
  \left( \frac{1}{\sigma} \right)^n e^{\frac{-nv}{2 \sigma^2}}
  \\
  p(\sigma \mid y) 
  &amp;=
  \left( \frac{1}{\sigma} \right)^{n - 1} e^{\frac{-nv}{2 \sigma^2}}
  ,
\end{align}
\]</span></p>
<p>where we have dropped any multiplicative constants that don’t depend on <span class="math inline">\(\sigma\)</span>.</p>
<p>Since the posteriors are continuous everywhere, we can assume that the highest posterior regions are collections of closed intervals. Let <span class="math inline">\(a, b\)</span> be two boundary points on the highest posterior density region of <span class="math inline">\(p(\sigma^2 \mid y)\)</span>. Using continuity and the defining property of highest posterior regions, the density at <span class="math inline">\(a\)</span> is equal to the density at <span class="math inline">\(b\)</span>, i.e.</p>
<p class="mathjaxWide"><span class="math display">\[
\left( \frac{1}{a} \right)^n e^{\frac{-nv}{2 a^2}}
=
\left( \frac{1}{b} \right)^n e^{\frac{-nv}{2 b^2}}
.
\]</span></p>
<p>Assume for contradiction that the highest posterior region for <span class="math inline">\(p(\sigma \mid y)\)</span> is the square root of the region for <span class="math inline">\(p(\sigma^2 \mid y)\)</span>. Then by continuity, <span class="math inline">\(\sqrt{a}, \sqrt{b}\)</span> are endpoints on the highest posterior region for <span class="math inline">\(p(\sigma \mid y)\)</span>. Thus</p>
<p class="mathjaxWide"><span class="math display">\[
\left( \frac{1}{a} \right)^{n - 1} e^{\frac{-nv}{2 a^2}}
=
\left( \frac{1}{b} \right)^{n - 1} e^{\frac{-nv}{2 b^2}}
.
\]</span></p>
<p>The two equalities above are equivalent to <span class="math inline">\(\frac{1}{a} = \frac{1}{b}\)</span>, which implies</p>
<p class="mathjaxWide"><span class="math display">\[
a = b
\qquad
↯
\]</span></p>
<p>This is true of any two boundary points, so the highest posterior region is a point. This contradicts the fact that the highest posterior region contains 95% probability mass. Therefore, the highest posterior regions are not invariant under reparameterisation.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 16</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_16.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_16.html</id>
    <published>2018-09-06T00:00:00Z</published>
    <updated>2018-09-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 16</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  6, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/beta-binomial.html">beta-binomial</a>, <a href="/tags/marginal.html">marginal</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 16, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial}  \DeclareMathOperator{\dbern}{Bernoulli}  \DeclareMathOperator{\dpois}{Poisson}  \DeclareMathOperator{\dnorm}{normal}  \DeclareMathOperator{\dcauchy}{Cauchy}  \DeclareMathOperator{\dgamma}{gamma}  \DeclareMathOperator{\invlogit}{invlogit}  \DeclareMathOperator{\logit}{logit}  \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Suppose <span class="math inline">\(y \mid \theta \sim \dbinomial(n, \theta)\)</span> and <span class="math inline">\(\theta \sim \dbeta(\alpha, \beta)\)</span>. Then</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  p(y)
  &amp;=
  \int_0^1 p(y \mid \theta) p(\theta) d\theta
  \\
  &amp;=
  \int_0^1 \binom{n}{y} \theta^y (1 - \theta)^{n - y} \theta^{\alpha - 1} (1 - \theta)^{\beta - 1} d\theta
  \\
  &amp;=
  \binom{n}{y} \frac{\Gamma (y + \alpha) \Gamma (n - y + \beta)}{\Gamma (n + \alpha + \beta)}
.
\end{align}
\]</span></p>
<p>If this density is constant in <span class="math inline">\(y\)</span> for any <span class="math inline">\(n\)</span>, then</p>
<p class="mathjaxWide"><span class="math display">\[
\binom{n}{y} \Gamma (y + \alpha) \Gamma (n - y + \beta) 
\]</span></p>
<p>is also constant in <span class="math inline">\(y\)</span> for any <span class="math inline">\(n\)</span>. In particular, for <span class="math inline">\(n = 1\)</span>, we can evaulate this at <span class="math inline">\(y = 0\)</span> and <span class="math inline">\(y = n\)</span> to give</p>
<p class="mathjaxWide"><span class="math display">\[
\Gamma (\alpha) \Gamma (1 + \beta) 
=
\Gamma (\beta) \Gamma (1 + \alpha) 
.
\]</span></p>
<p><a href="https://en.wikipedia.org/wiki/Gamma_function">Since</a> <span class="math inline">\(\Gamma (1 + \alpha) = \alpha \Gamma(\alpha)\)</span>, it follows that</p>
<p class="mathjaxWide"><span class="math display">\[
\beta \Gamma (\alpha) \Gamma (\beta)
=
\alpha \Gamma (\alpha) \Gamma (\beta)
.
\]</span></p>
<p>Using the fact that the gamma function is always positive on the reals, we can conclude <span class="math inline">\(\alpha = \beta\)</span>.</p>
<p>Now, for <span class="math inline">\(n = 2\)</span>, we can evaluate at <span class="math inline">\(y = 0\)</span> and <span class="math inline">\(y = 1\)</span> to get</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
\Gamma(\alpha) \Gamma(\alpha + 2)
&amp;=
2 \Gamma(\alpha + 1)^2
\\
\Leftrightarrow
(\alpha + 1) \alpha \Gamma (\alpha)^2
&amp;=
2 \alpha^2 \Gamma (\alpha)^2
\\
\Leftrightarrow
\alpha + 1 
&amp;= 
2\alpha
\\
\Leftrightarrow
\alpha 
&amp;=
1
\end{align}
,
\]</span></p>
<p>where we have used the facts that <span class="math inline">\(\alpha &gt; 0\)</span>, <span class="math inline">\(\Gamma(\alpha + 1) = \alpha \Gamma(\alpha)\)</span>, and that the gamma function is positive on the reals. Therefore, <span class="math inline">\(\alpha = \beta = 1\)</span>. In other words, if the beta-binomial distribution is uniform, then <span class="math inline">\(\alpha = \beta = 1\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 15</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_15.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_15.html</id>
    <published>2018-09-04T00:00:00Z</published>
    <updated>2018-09-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 15</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  4, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/beta.html">beta</a>, <a href="/tags/mean.html">mean</a>, <a href="/tags/variance.html">variance</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 15, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial}  \DeclareMathOperator{\dbern}{Bernoulli}  \DeclareMathOperator{\dpois}{Poisson}  \DeclareMathOperator{\dnorm}{normal}  \DeclareMathOperator{\dcauchy}{Cauchy}  \DeclareMathOperator{\dgamma}{gamma}  \DeclareMathOperator{\invlogit}{invlogit}  \DeclareMathOperator{\logit}{logit}  \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Suppose <span class="math inline">\(Z \sim \dbeta(\alpha, \beta)\)</span>. Then for <span class="math inline">\(m, n \in \mathbb N\)</span> we have</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb E \left[ Z^m (1 - Z)^n \right]
  &amp;=
  \frac{1}{B(\alpha, \beta)} \int_0^1 z^m (1 - z)^n z^{\alpha - 1} (1 - z)^{\beta - 1} dz
  \\
  &amp;=
  \frac{1}{B(\alpha, \beta)} \int_0^1 z^{m + \alpha - 1} (1 - z)^{n + \beta - 1} dz
  \\
  &amp;=
  \frac{1}{B(\alpha, \beta)} \frac{\Gamma (m + \alpha) \Gamma( n + \beta )}{\Gamma (m + n + \alpha + \beta)}
  \\
  &amp;=
  \frac{(\alpha + \beta -1)!}{(\alpha - 1)! (\beta - 1)!} \frac{(m + \alpha - 1)! (n + \beta - 1)!}{(m + n + \alpha + \beta - 1)!}
  ,
\end{align}
\]</span></p>
<p>where <span class="math inline">\(B\)</span> is the <a href="https://en.wikipedia.org/wiki/Gamma_function">beta function</a> and <span class="math inline">\(\Gamma\)</span> is the <a href="https://en.wikipedia.org/wiki/Gamma_function">gamma function</a>.</p>
<p>I’m not sure how the above integral is so useful for this exercise since calculating the mean and variance only require <span class="math inline">\(n = 0\)</span> and <span class="math inline">\(m = 1, 2\)</span>.</p>
<p>The mean of <span class="math inline">\(Z\)</span> is the above expectation when <span class="math inline">\(m = 1\)</span> and <span class="math inline">\(n = 0\)</span>, giving</p>
<p class="mathjaxWide"><span class="math display">\[
\mathbb E (Z)
=
\frac{(\alpha + \beta - 1)!}{(\alpha - 1)! (\beta - 1)!}
\frac{\alpha! (\beta - 1)!}{(\alpha + \beta)!}
=
\frac{\alpha}{\alpha + \beta}
.
\]</span></p>
<p>The second moment is given by <span class="math inline">\(m = 2\)</span> and <span class="math inline">\(n = 0\)</span>, which is</p>
<p class="mathjaxWide"><span class="math display">\[
\mathbb E(Z^2)
=
\frac{(\alpha + \beta - 1)!}{(\alpha - 1)! (\beta - 1)!}
\frac{(\alpha +1)! (\beta - 1)!}{(\alpha + \beta + 1)!}
=
\frac{(\alpha + 1) \alpha}{(\alpha + \beta + 1) (\alpha + \beta)}
.
\]</span></p>
<p>It follows that the variance is</p>
<span class="math display">\[\begin{align}
  \mathbb E (Z^2) - \mathbb E (Z)^2
  &amp;=
  \frac{(\alpha + 1) \alpha}{(\alpha + \beta + 1) (\alpha + \beta)}
  -
  \frac{\alpha^2}{(\alpha + \beta)^2}
  
  \\
  &amp;=
  
  \frac{(\alpha + 1) \alpha (\alpha + \beta)}{(\alpha + \beta + 1) (\alpha + \beta)^2}
  -
  \frac{\alpha^2(\alpha + \beta + 1)}{(\alpha + \beta + 1) (\alpha + \beta)^2}
  
  \\
  &amp;=
  
  \frac{
    \alpha^2 (\alpha + \beta) + \alpha (\alpha + \beta)
    -
    \alpha^2(\alpha + \beta) - \alpha^2
  }{(\alpha + \beta + 1) (\alpha + \beta)^2}
  
  \\
  &amp;=
  
  \frac{
    \alpha (\alpha + \beta)
    -
    \alpha^2
  }{(\alpha + \beta + 1) (\alpha + \beta)^2}
  \\
  &amp;=
  
  \frac{
    \alpha \beta
  }{(\alpha + \beta + 1) (\alpha + \beta)^2}
  .
\end{align}\]</span>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 14</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_14.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_14.html</id>
    <published>2018-09-03T00:00:00Z</published>
    <updated>2018-09-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 14</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  3, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/normal.html">normal</a>, <a href="/tags/conjugate%20prior.html">conjugate prior</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 14, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial}  \DeclareMathOperator{\dbern}{Bernoulli}  \DeclareMathOperator{\dpois}{Poisson}  \DeclareMathOperator{\dnorm}{normal}  \DeclareMathOperator{\dcauchy}{Cauchy}  \DeclareMathOperator{\dgamma}{gamma}  \DeclareMathOperator{\invlogit}{invlogit}  \DeclareMathOperator{\logit}{logit}  \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>Suppose we have a normal prior <span class="math inline">\(\theta \sim \dnorm (\mu_0, \frac{1}{\tau_0})\)</span> and a normal sampling distribution <span class="math inline">\(y \mid \theta \sim \dnorm(\theta, \sigma)\)</span>, where the variance is known. We will show by induction that the posterior is <span class="math inline">\(\theta \mid y_1, \dotsc, y_{n} \sim \dnorm(\mu_{n}, \frac{1}{\tau_{n}})\)</span> where</p>
<p class="mathjaxWide"><span class="math display">\[
  \frac{1}{\tau_{n}^2} = \frac{1}{\tau_0^2} + \frac{n}{\sigma^2}
  \quad
  \text{and}
  \quad
  \mu_n = \frac{\frac{1}{\tau_0^2}\mu_0 + \frac{n}{\sigma^2}\bar y_n}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}
\]</span></p>
<p>for <span class="math inline">\(n = 1, \dotsc, \infty\)</span>.</p>
<h2 id="base-case">Base case</h2>
<p>The case <span class="math inline">\(n = 1\)</span> can be reexpressed as</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \frac{1}{\tau_1^2} = \frac{\sigma^2 + \tau_0^2}{\sigma^2\tau_0^2}
  \quad
  \text{and}
  \quad
  \mu_1 = \frac{\sigma_0^2\mu_0 + \tau_0^2y}{\sigma^2 + \tau_0^2}
  .
\end{align}
\]</span></p>
<p>Now we can combine the fractions in the exponent, expand the brackets, collect the terms as <span class="math inline">\(\theta\)</span>-coefficients, rewrite the coefficients in terms of <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\tau_1\)</span>, then complete the square in terms of <span class="math inline">\(\theta\)</span>:</p>
<span class="math display">\[\begin{align}
  \frac{(y - \theta)^2}{\sigma^2}
  +
  \frac{(\theta - \mu_0)^2}{\tau_0^2}
  
  &amp;=
  \frac{(y^2 + \theta^2 - 2\theta y) \tau_0^2 + (\theta^2 + \mu_0^2 - 2 \theta \mu_0) \sigma^2}{\sigma^2 \tau_0^2}
  
  \\
  &amp;=
  \frac{\theta^2 (\tau_0^2 + \sigma^2) -2 \theta (\sigma^2\mu_0 + \tau_0^2y) + (y^2\tau_0^2 + \mu_0^2\sigma^2)}{\sigma^2\tau_0^2}
  \\
  &amp;=
  \frac{\theta^2 (\tau_0^2 + \sigma^2) -2 \theta \mu_1 (\sigma^2 + \tau_0^2) + \mu_1 (\sigma^2 + \tau_0^2) }{\sigma^2\tau_0^2}
  \\
  &amp;=
  \theta^2\frac{1}{\tau_1^2} -2\theta \mu_1 \frac{1}{\tau_1^2} + \mu_1 \frac{1}{\tau_1^2}
  \\
  &amp;=
  \frac{\theta^2 -2 \mu_1 \theta + \mu_1^2}{\tau_1^2} 
  \\
  &amp;=
  \frac{(\theta - \mu_1)^2}{\tau_1^2} 
  .
\end{align}\]</span>
<h2 id="induction-step">Induction step</h2>
<p>The induction hypothesis is that the variance and mean are given by</p>
<p class="mathjaxWide"><span class="math display">\[
  \frac{1}{\tau_n^2} = \frac{1}{\tau_0^2} + \frac{n}{\sigma^2}
  \quad
  \text{and}
  \quad
  \mu_n = \frac{\frac{1}{\tau_0^2}\mu_0 + \frac{n}{\sigma^2}\bar y}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}}
\]</span></p>
<p>for some <span class="math inline">\(n \ge 1\)</span>.</p>
<p>Starting with the variance, the base step can be reexpressed as</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{1}{\tau_{n+1}^2} 
=
\frac{1}{\tau_n^2} + \frac{1}{\sigma^2}
.
\]</span></p>
<p>Now apply the induction hypothesis to get</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{1}{\tau_{n+1}^2} 
=
\frac{1}{\tau_0^2} + \frac{n}{\sigma^2} + \frac{1}{\sigma^2}
=
\frac{1}{\tau_0^2} + \frac{n+1}{\sigma^2}
.
\]</span></p>
<p>For the mean we apply the same strategy. The base step can be reexpressed as</p>
<p class="mathjaxWide"><span class="math display">\[
\mu_{n+1}
=
\frac{
  \frac{1}{\tau_n^2}\mu_n + \frac{1}{\sigma^2}y_{n+1}
}{
  \frac{1}{\tau_n^2} + \frac{1}{\sigma^2}
}
.
\]</span></p>
<p>Applying the induction hypothesis then gives</p>
<span class="math display">\[\begin{align}
  \mu_{n+1}
  &amp;=
  \frac{
    \frac{1}{\tau_n^2} \left( \frac{\frac{1}{\tau_0^2}\mu_0 + \frac{n}{\sigma^2}\bar y_n}{\frac{1}{\tau_0^2} + \frac{n}{\sigma^2}} \right) + \frac{1}{\sigma^2}y_{n+1}
  }{
    \frac{1}{\tau_0^2} + \frac{n+1}{\sigma^2}}
  
  \\
  &amp;=
  \frac{
    \frac{1}{\tau_0^2}\mu_0 + \frac{n}{\sigma^2}\bar y_n + \frac{1}{\sigma^2}y_{n+1}
  }{
    \frac{1}{\tau_0^2} + \frac{n+1}{\sigma^2}
  }
  
  \\
  &amp;=
  \frac{
    \frac{1}{\tau_0^2}\mu_0 + \frac{n+1}{\sigma^2}\bar y_{n+1}
  }{
    \frac{1}{\tau_0^2} + \frac{n+1}{\sigma^2}
  }
  ,
\end{align}\]</span>
<p>since</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
(n + 1) \bar y_{n + 1}
&amp;:=
\sum_1^{n+1} y_i
\\
&amp;=
y_{n+1} + \sum_1^n y_i
\\
&amp;=
y_{n+1} + n\bar y_n
.
\end{align}
\]</span></p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>BDA3 Chapter 2 Exercise 13</title>
    <link href="http://stappit.github.io/posts/bda3/chapter_02_exercise_13.html" />
    <id>http://stappit.github.io/posts/bda3/chapter_02_exercise_13.html</id>
    <published>2018-09-02T00:00:00Z</published>
    <updated>2018-09-02T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1 class="post-title">BDA3 Chapter 2 Exercise 13</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on September  2, 2018  by Brian </br>
     Tags: <a href="/tags/bda%20chapter%202.html">bda chapter 2</a>, <a href="/tags/solutions.html">solutions</a>, <a href="/tags/bayes.html">bayes</a>, <a href="/tags/poisson.html">poisson</a>, <a href="/tags/gamma.html">gamma</a>, <a href="/tags/jeffrey%20prior.html">jeffrey prior</a>, <a href="/tags/posterior%20predictive.html">posterior predictive</a> </br>
     Category: <a href="/categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 13, chapter 2, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dpois}{Poisson} \DeclareMathOperator{\dnorm}{normal} \DeclareMathOperator{\dcauchy}{Cauchy} \DeclareMathOperator{\dgamma}{gamma} \DeclareMathOperator{\invlogit}{invlogit} \DeclareMathOperator{\logit}{logit} \DeclareMathOperator{\dbeta}{beta}\)</span></p>
</div>
<p>We are given data on airline deaths and asked to fit various models to that data.</p>
<h2 id="the-data">The data</h2>
<p>We are given the data shown below. The data didn’t seem to be available anywhere so I <a href="/data/bda3_chapter_02_exercise_13.csv">created the csv file</a> myself.</p>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
year
</th>
<th style="text-align:right;">
fatal_accidents
</th>
<th style="text-align:right;">
passenger_deaths
</th>
<th style="text-align:right;">
death_rate
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1976
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
734
</td>
<td style="text-align:right;">
0.19
</td>
</tr>
<tr>
<td style="text-align:right;">
1977
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
516
</td>
<td style="text-align:right;">
0.12
</td>
</tr>
<tr>
<td style="text-align:right;">
1978
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
754
</td>
<td style="text-align:right;">
0.15
</td>
</tr>
<tr>
<td style="text-align:right;">
1979
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
877
</td>
<td style="text-align:right;">
0.16
</td>
</tr>
<tr>
<td style="text-align:right;">
1980
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
814
</td>
<td style="text-align:right;">
0.14
</td>
</tr>
<tr>
<td style="text-align:right;">
1981
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
362
</td>
<td style="text-align:right;">
0.06
</td>
</tr>
<tr>
<td style="text-align:right;">
1982
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
764
</td>
<td style="text-align:right;">
0.13
</td>
</tr>
<tr>
<td style="text-align:right;">
1983
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
809
</td>
<td style="text-align:right;">
0.13
</td>
</tr>
<tr>
<td style="text-align:right;">
1984
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
223
</td>
<td style="text-align:right;">
0.03
</td>
</tr>
<tr>
<td style="text-align:right;">
1985
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
1066
</td>
<td style="text-align:right;">
0.15
</td>
</tr>
</tbody>
</table>
<p>Let’s get acquainted with the data by plotting it as a timeseries.</p>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/data_plot-1..svg" />
</figure>
<h2 id="part-a">Part a</h2>
<p>We model the number of fatal accidents as poisson <span class="math inline">\(y \mid \theta \sim \dpois(\theta)\)</span>, where we put a <span class="math inline">\(\theta \sim \dgamma(\alpha, \beta)\)</span> prior on the parameter. I don’t really have any strong prior knowledge about the number of annual fatal flight accidents. I’ll use the gamma approximation to Jeffrey’s prior from the <a href="./chapter_02_exercise_12.html">previous exercise</a>, even though it places probability on very extreme values. We’ll stick with this prior throughout.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shape &lt;-<span class="st"> </span><span class="fl">0.5</span>
rate &lt;-<span class="st"> </span>.Machine<span class="op">$</span>double.xmin</code></pre></div>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/prior_a-1..svg" />
</figure>
<p>The posterior is <span class="math inline">\(\dgamma(0.5 + n\bar y, n) = \dgamma(0.5 + 238, 10)\)</span>.</p>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/posterior_a-1..svg" />
</figure>
<p>To obtain a 95% posterior predictive interval, we draw <span class="math inline">\(\theta\)</span> from its posterior, then draw <span class="math inline">\(y\)</span> from the corresponding Poisson distribution. With these draws, we can obtain the necessary quantiles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n_draws &lt;-<span class="st"> </span><span class="dv">50000</span>

theta_posterior_a &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n_draws, 
                            shape <span class="op">+</span><span class="st"> </span>sum_fatal_accidents, 
                            rate <span class="op">+</span><span class="st"> </span>n_observations
                           ) 
y_pp_a &lt;-<span class="st"> </span><span class="kw">rpois</span>(n_draws, theta_posterior_a) 

mu_a &lt;-<span class="st"> </span><span class="kw">mean</span>(y_pp_a)
ci_a &lt;-<span class="st"> </span><span class="kw">quantile</span>(y_pp_a, <span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>))

ci_a</code></pre></div>
<pre><code> 5% 95% 
 16  32 </code></pre>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/pp_plot_a-1..svg" />
</figure>
<h2 id="part-b">Part b</h2>
<p>In part a, we ignored how many flights there are. We can incorporate this information into our model by using <code>passenger_miles</code> as a measure of exposure. The parameter <span class="math inline">\(\theta\)</span> is now the rate of fatal accidents per year per 100 million passenger miles. Note that this rate is over an order of magnitude smaller than the death rate in the table because the number of fatal accidents is an order of magnitude smaller than the number of passenger deaths. The posterior is <span class="math inline">\(\theta \mid y \sim \dgamma(0.5 + 238, 57158.69)\)</span>.</p>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/posterior_b-1..svg" />
</figure>
<p>The 95% posterior predictive interval seems to be shifted upwards compared to the interval in part a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">theta_posterior_b &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n_draws, 
                            shape <span class="op">+</span><span class="st"> </span>sum_fatal_accidents, 
                            rate <span class="op">+</span><span class="st"> </span>sum_passenger_miles
                           )
y_pp_b &lt;-<span class="st"> </span><span class="kw">rpois</span>(n_draws, theta_posterior_b <span class="op">*</span><span class="st"> </span><span class="dv">8000</span>)

mu_b &lt;-<span class="st"> </span><span class="kw">mean</span>(y_pp_b)

ci_b &lt;-<span class="st"> </span><span class="kw">quantile</span>(y_pp_b, <span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>))

ci_b</code></pre></div>
<pre><code> 5% 95% 
 24  44 </code></pre>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/pp_plot_b-1..svg" />
</figure>
<h2 id="part-c">Part c</h2>
<p>Here we use the same model as in part a but for the number of passenger deaths instead of fatal accidents.</p>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/posterior_c-1..svg" />
</figure>
<p>Only 1 of the 10 observations in the dataset lie within the 95% posterior predictive interval.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">theta_posterior_c &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n_draws, 
                            shape <span class="op">+</span><span class="st"> </span>sum_passenger_deaths, 
                            rate <span class="op">+</span><span class="st"> </span>n_observations
                           )
y_pp_c &lt;-<span class="st"> </span><span class="kw">rpois</span>(n_draws, theta_posterior_c) 

mu_c &lt;-<span class="st"> </span><span class="kw">mean</span>(y_pp_c)
ci_c &lt;-<span class="st"> </span><span class="kw">quantile</span>(y_pp_c, <span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>))

ci_c</code></pre></div>
<pre><code> 5% 95% 
647 738 </code></pre>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/pp_plot_c-1..svg" />
</figure>
<h2 id="part-d">Part d</h2>
<p>Now we use the same model as in part b but for passenger deaths instead of fatal accidents. The posterior is <span class="math inline">\(\dgamma(0.5 + 238, 57158.69)\)</span>.</p>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/posterior_d-1..svg" />
</figure>
<p>None of the observed values falls into the 95% posterior predictive interval.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">theta_posterior_d &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n_draws, 
                            shape <span class="op">+</span><span class="st"> </span>sum_passenger_deaths, 
                            rate <span class="op">+</span><span class="st"> </span>sum_passenger_miles
                           )
y_pp_d &lt;-<span class="st"> </span><span class="kw">rpois</span>(n_draws, theta_posterior_d <span class="op">*</span><span class="st"> </span><span class="dv">8000</span>)

mu_d &lt;-<span class="st"> </span><span class="kw">mean</span>(y_pp_d)

ci_d &lt;-<span class="st"> </span><span class="kw">quantile</span>(y_pp_d, <span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>))

ci_d</code></pre></div>
<pre><code>  5%  95% 
 914 1023 </code></pre>
<figure>
<img src="chapter_02_exercise_13_files/figure-markdown/pp_plot_d-1..svg" />
</figure>
<h2 id="part-e">Part e</h2>
<p>There are a number of issues to consider that are not mentioned in the question or suggested by the data. The number of fatal accidents depends on the number of miles flown by airplanes: if there are more flights, there will likely be more accidents. However, the number of flights isn’t directly accounted for in the number of passenger miles since the number of passengers per flight can vary from year to year. In any case, the number of passenger deaths per year is not independent because passengers on the same flight will have more similar survival chances.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>

</feed>
