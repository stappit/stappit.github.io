---
title: Wasserman's AoS, Chapter 7, Question 5
author: Brian
date: 2017-04-11
tags: wasserman, all of statistics, covariance, empirical distribution function
---

We show that the covariance $C$ of $\hat F_n(x)$ and $\hat F_n(y)$ is
$\frac{1}{n} F(x) \left( 1 + F(y) \right)$, for $x \le y$. For $x \ge y$, we have
$\frac{1}{n} F(y) \left( 1 + F(x) \right)$.

Using $\mathbb E \hat F_n(y) = F(y)$ and linearity of expectation, we obtain

$$
\mathbb E (\hat F_n(x) - F(x)) (\hat F_n(y) - F(y))
=
\mathbb E (\hat F_n(x)\hat F_n(y)) - F(x)F(y)
.
$$

By definition of the empirical cumulative distribution funtion, the first term is equal to

$$
\frac{1}{n^2} \sum_{i, j} \mathbb E (I(X_i \le x)I(X_j \le y))
=
\frac{1}{n^2} \left( 
	\sum_{i = j} \mathbb E (I(X_i \le x)I(X_i \le y))
	+ \sum_{i \ne j} \mathbb E (I(X_i \le x)I(X_j \le y))
\right)
.
$$

We now simplify the two summations.
Note that the Bernoulli variables $I(X_i \le x)$ and $I(X_j \le y)$ are independent for $i \ne j$ since $X_i$ and $X_j$ are independent.
This implies that the expectation of the product is the product of the expectations.

Also, without loss of generality, we may assume that $x \le y$.  With this assumption, $I(X_i \le x)I(X_i \le y) = I(X_i \le x)$.
Thus, we obtain 

$$
\begin{align}
	\frac{1}{n^2} \left( 
			\sum_{i = j} \mathbb E (I(X_i \le x))
			+ \sum_{i \ne j} \mathbb E (I(X_i \le x)) \mathbb E (I(X_j \le y))
			\right)
	&=
	\frac{1}{n^2} \left( 
			\sum_{i = j} F(x)
			+ \sum_{i \ne j} F(x)F(y)
			\right)
	\\
	&=
	\frac{1}{n} F(x) (
			1 + (n-1) F(y)
			)
\end{align}
.
$$

Putting everything together, we see that the covariance $C$ is

$$
\begin{align}
\frac{1}{n} F(x) (1 + (n-1) F(y)) - F(x)F(y)
&=
\frac{1}{n} F(x) (1 + F(y))
\end{align}
$$

for $x \le y$.
