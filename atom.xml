<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Thoughts from the Café</title>
    <link href="http://stappit.github.io/atom.xml" rel="self" />
    <link href="http://stappit.github.io" />
    <id>http://stappit.github.io/atom.xml</id>
    <author>
        <name>Brian</name>
        <email>ha@hahaha.com</email>
    </author>
    <updated>2018-07-02T00:00:00Z</updated>
    <entry>
    <title>Ageing and Marathon Running</title>
    <link href="http://stappit.github.io/posts/berlin_marathon/age.html" />
    <id>http://stappit.github.io/posts/berlin_marathon/age.html</id>
    <published>2018-07-02T00:00:00Z</published>
    <updated>2018-07-02T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Ageing and Marathon Running</h1>
<p class="blog-post-meta">
Posted on July  2, 2018  by Brian </br>
 Tags: <a href="/tags/running.html">running</a>, <a href="/tags/marathon.html">marathon</a>, <a href="/tags/berlin.html">berlin</a>, <a href="/tags/gam.html">gam</a>, <a href="/tags/statistics.html">statistics</a>, <a href="/tags/mgcv.html">mgcv</a>, <a href="/tags/random%20effects.html">random effects</a> </br>
 Category: <a href="/categories/berlin_marathon.html">berlin_marathon</a> 
</p>

<p>Running is great. One of the worst parts, though, is other people telling you how it’s all downhill after 30. But is it? It’s a persistent idea, so I wanted to see if actual marathon results support it. To get an idea of how age affects running performance, we’ll use the data from the <a href="https://www.bmw-berlin-marathon.com/en/race-day-/results-list.html">Berlin Marathon</a>, after some <a href="https://github.com/stappit/berlin-marathon">cleaning up</a>, focussing on the year 2016.</p>
<figure>
<img src="age_files/figure-markdown/bm2016-1.png" alt="Average finishing time in the Berlin marathon 2016" /><figcaption>Average finishing time in the Berlin marathon 2016</figcaption>
</figure>
<p><strong>tl;dr</strong> The performance of the average 20 year old is comparable to that of the average 50 year old. The 34 year old men were the fastest on average for their sex, whereas the 31 year old women were fastest on average for their sex.</p>
<p>Let’s load the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># mapping table from country abbreviations to country names</span>
mapping &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&#39;data/country_continent_mapping.csv&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(
    <span class="dt">country =</span> name,
    <span class="dt">alpha3 =</span> <span class="st">`</span><span class="dt">alpha-3</span><span class="st">`</span>
  )

<span class="co"># read all the data: 2005 to 2016</span>
df0 &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&#39;data/berlin_marathon_times.csv&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(
    year,
    age,
    <span class="dt">sex =</span> <span class="kw">ordered</span>(sex, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&#39;W&#39;</span>, <span class="st">&#39;M&#39;</span>)),
    <span class="dt">usex =</span> <span class="kw">factor</span>(sex, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&#39;W&#39;</span>, <span class="st">&#39;M&#39;</span>), <span class="dt">ordered =</span> <span class="ot">FALSE</span>), <span class="co"># for technical reasons</span>
    <span class="dt">alpha3 =</span> nationality, <span class="co"># for joining with mapping table</span>
    <span class="dt">net_time =</span> <span class="kw">as.duration</span>(<span class="kw">hms</span>(net_time)),
    <span class="dt">hours =</span> <span class="kw">as.numeric</span>(net_time, <span class="st">&#39;hours&#39;</span>)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inner_join</span>(mapping, <span class="dt">by =</span> <span class="st">&#39;alpha3&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">country =</span> <span class="kw">factor</span>(country)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(hours) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>() 

<span class="co"># year of interest</span>
df &lt;-<span class="st"> </span>df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">2016</span>)

<span class="co"># sample of data</span>
df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>usex, <span class="op">-</span>alpha3, <span class="op">-</span>hours) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">kable</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;hover&quot;</span>, <span class="st">&quot;responsive&quot;</span>))</code></pre></div>
<table class="table table-striped table-hover table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
year
</th>
<th style="text-align:right;">
age
</th>
<th style="text-align:left;">
sex
</th>
<th style="text-align:right;">
net_time
</th>
<th style="text-align:left;">
country
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
2016
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
7383s (~2.05 hours)
</td>
<td style="text-align:left;">
Ethiopia
</td>
</tr>
<tr>
<td style="text-align:right;">
2016
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
7393s (~2.05 hours)
</td>
<td style="text-align:left;">
Kenya
</td>
</tr>
<tr>
<td style="text-align:right;">
2016
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
7531s (~2.09 hours)
</td>
<td style="text-align:left;">
Kenya
</td>
</tr>
<tr>
<td style="text-align:right;">
2016
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
7616s (~2.12 hours)
</td>
<td style="text-align:left;">
Ethiopia
</td>
</tr>
<tr>
<td style="text-align:right;">
2016
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
7667s (~2.13 hours)
</td>
<td style="text-align:left;">
Kenya
</td>
</tr>
<tr>
<td style="text-align:right;">
2016
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
7769s (~2.16 hours)
</td>
<td style="text-align:left;">
Kenya
</td>
</tr>
</tbody>
</table>
<p>We have the variables <code>age</code>, <code>sex</code>, <code>nationality</code>, and <code>net_time</code> for a cross section of marathon runners to play with. To measure the effect of age on running performance, we should really be looking at multiple measurements of the same runners at different ages, whilst controlling for features more directly related to running performance (e.g. vO2max, training volume). This would be a fairly expensive experiment and I didn’t find any research in that direction (if you find some, please let me know). We’ll do what we can with the data at hand but the results can only be suggestive of interesting questions to pursue.</p>
<h2 id="a-first-look">A first look</h2>
<p>The average finishing time amongst the runners is about 4 hours 12 minutes, and the average age around 42. These numbers are fairly constant over the years.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">mean_hours =</span> <span class="kw">mean</span>(hours),
    <span class="dt">mean_age =</span> <span class="kw">mean</span>(age)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(metric, value, mean_hours, mean_age) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">limits =</span> <span class="kw">seq</span>(<span class="dv">2005</span>, <span class="dv">2016</span>, <span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>metric, <span class="dt">scales =</span> <span class="st">&#39;free_y&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Year&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Value&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Average age and finishing time per year&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;Berlin Marathon&#39;</span>
  ) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<figure>
<img src="age_files/figure-markdown/unnamed-chunk-2-1.png" />
</figure>
<p>The results are similar when broken down by sex.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(year, sex) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">mean_hours =</span> <span class="kw">mean</span>(hours),
    <span class="dt">mean_age =</span> <span class="kw">mean</span>(age)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(metric, value, mean_hours, mean_age) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> value, <span class="dt">fill =</span> sex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">limits =</span> <span class="kw">seq</span>(<span class="dv">2005</span>, <span class="dv">2016</span>, <span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(metric <span class="op">~</span><span class="st"> </span>sex, <span class="dt">scales =</span> <span class="st">&#39;free_y&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Year&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Value&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Average age and finishing time per year per sex&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;Berlin Marathon&#39;</span>
  ) <span class="op">+</span>
<span class="st">  </span><span class="ot">NULL</span></code></pre></div>
<figure>
<img src="age_files/figure-markdown/unnamed-chunk-3-1.png" />
</figure>
<h3 id="age-and-sex">Age and Sex</h3>
<p>Below is a scatter plot of finishing time against age. The first noticable property is that there is a LOT of variation. Indeed, it would be highly suprising if we could explain running performance with just age, with factors such as <a href="https://en.wikipedia.org/wiki/VVO2max">vvO2max</a> and <a href="https://en.wikipedia.org/wiki/Lactate_threshold">lactate threshold</a> being much more relevant. For some scale of reference, a sub-3h marathon is a challenging goal for many amateur marathon runners - a goal achieved by some in their 60s in this dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> hours)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.03</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">8</span>, <span class="dt">by =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">80</span>, <span class="dt">by =</span> <span class="dv">5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">y =</span> <span class="st">&#39;Net finishing time (hours)&#39;</span>,
    <span class="dt">x =</span> <span class="st">&#39;Age&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Finishing time vs. Age&#39;</span>, 
    <span class="dt">subtitle =</span> <span class="st">&#39;Berlin Marathon 2016&#39;</span>
  ) </code></pre></div>
<figure>
<img src="age_files/figure-markdown/age_vs_hours-1.png" />
</figure>
<p>Next up is the trend line, which shows that the runners in their early 20s were actually a bit slower than those in their late 20s. The trend then stays fairly flat until the early 40s, when the trend starts to slow down.</p>
<p>The above chart lumps men and women together, but the following histogram suggests a difference between the sexes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(hours, <span class="dt">fill =</span> sex)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">8</span>, <span class="dt">by =</span> <span class="fl">0.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.65</span>), <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">0.6</span>, <span class="dt">by =</span> <span class="fl">0.1</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.02</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Net finishing time (hours)&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Frequency&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Histogram of marathon finishing times&#39;</span>, 
    <span class="dt">subtitle =</span> <span class="st">&#39;Berlin Marathon 2016&#39;</span>
  )</code></pre></div>
<figure>
<img src="age_files/figure-markdown/hours_histogram_by_sex-1.png" />
</figure>
<p>Breaking down the hours-age chart by <code>sex</code> tells a similar story. The main difference is that the trend for women flattens out a bit earlier at around age 25 compared to around age 30 for men.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> hours, <span class="dt">colour =</span> sex)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.05</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">8</span>, <span class="dt">by =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">80</span>, <span class="dt">by =</span> <span class="dv">5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">y =</span> <span class="st">&#39;Net finishing time (hours)&#39;</span>,
    <span class="dt">x =</span> <span class="st">&#39;Age&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Finishing time vs. Age&#39;</span>, 
    <span class="dt">subtitle =</span> <span class="st">&#39;Berlin Marathon 2016&#39;</span>
  ) </code></pre></div>
<figure>
<img src="age_files/figure-markdown/age_vs_hours_by_sex-1.png" />
</figure>
<h3 id="nationality">Nationality</h3>
<p>It is also possible that nationality plays some role here. The Berlin marathon is an international event with big prize money at stake and it draws the best of the best from around the world. International travel is also costly and it seems plausible that this could have some influence on the statistical properties of the runners.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ranking_m1 &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(country) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">mean_hours =</span> <span class="kw">mean</span>(hours), 
    <span class="dt">mean_age =</span> <span class="kw">mean</span>(age), 
    <span class="dt">runners =</span> <span class="kw">n</span>()
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(mean_hours) 

<span class="kw">head</span>(ranking_m1) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">kable</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;hover&quot;</span>, <span class="st">&quot;responsive&quot;</span>))</code></pre></div>
<table class="table table-striped table-hover table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
country
</th>
<th style="text-align:right;">
mean_hours
</th>
<th style="text-align:right;">
mean_age
</th>
<th style="text-align:right;">
runners
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Lesotho
</td>
<td style="text-align:right;">
2.451111
</td>
<td style="text-align:right;">
36.00000
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Eritrea
</td>
<td style="text-align:right;">
2.657500
</td>
<td style="text-align:right;">
28.25000
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Ethiopia
</td>
<td style="text-align:right;">
2.749514
</td>
<td style="text-align:right;">
28.33333
</td>
<td style="text-align:right;">
12
</td>
</tr>
<tr>
<td style="text-align:left;">
Kenya
</td>
<td style="text-align:right;">
2.963480
</td>
<td style="text-align:right;">
34.94737
</td>
<td style="text-align:right;">
19
</td>
</tr>
<tr>
<td style="text-align:left;">
Kazakhstan
</td>
<td style="text-align:right;">
3.002222
</td>
<td style="text-align:right;">
27.00000
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Guinea
</td>
<td style="text-align:right;">
3.130556
</td>
<td style="text-align:right;">
26.00000
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table>
<p>However, a breakdown of the 118 countries has the problem that the number of participants for many countries is very small. Small sample sizes lead to high-variance estimates. In other words, we don’t necessarily believe that the average Berlin marathon runner from Lesotho is faster than the average Berlin marathon runner from Kenya on the basis of just one runner. We need some way of using all the information available so that low sample size groups don’t have such extreme estimates. In the next section, we will use random effects to account for this.</p>
<h2 id="models">Models</h2>
<p>This section gets a bit technical; feel free to skip to the end for the pretty charts.</p>
<p>The trend for age doesn’t look linear - it has a U-shape. We could try to model this by adding the quadratic term <code>age^2</code> into our linear models. However, in general we don’t know how many powers we will need to sufficiently model the effect and the effect may not even be polynomial. Instead, we harness the power of general additive models, a.k.a GAMs. Indeed, the trend lines in our plots above actually used GAMs behind the scenes. The advantage of using GAMs is that you don’t have to mess around trying to add the right number of powers into your linear models, or even assume the the trend is polynomial at all.</p>
<p>The <code>s()</code> notation indicates that we want to fit an arbitrary smooth function to the data (not just a linear function). A <strong>smooth</strong> has a number of optional parameters; here <code>bs = re</code> uses random effects as our basis, and <code>by = sex</code> indicates a different age-smooth for each sex.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">gam</span>(
  hours <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(country, <span class="dt">bs =</span> <span class="st">&#39;re&#39;</span>) <span class="op">+</span><span class="st"> </span>usex <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age, <span class="dt">by =</span> sex), 
  <span class="dt">family =</span> <span class="kw">Gamma</span>(),
  <span class="dt">data =</span> df, 
  <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>
)

<span class="kw">summary</span>(m)</code></pre></div>
<pre><code>Family: Gamma 
Link function: inverse 

Formula:
hours ~ 1 + s(country, bs = &quot;re&quot;) + usex + s(age) + s(age, by = sex)

Parametric coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.221962   0.002341   94.81   &lt;2e-16 ***
usexM       0.024254   0.000469   51.72   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Approximate significance of smooth terms:
               edf  Ref.df      F p-value    
s(country)  83.294 117.000 23.306 &lt; 2e-16 ***
s(age)       6.004   6.959 64.706 &lt; 2e-16 ***
s(age):sexM  3.931   4.817  4.439 0.00105 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

R-sq.(adj) =  0.179   Deviance explained = 17.9%
-REML =  37846  Scale est. = 0.028131  n = 35986</code></pre>
<p>This model achieves an explained deviance of 17.9% (analogous to R^2 for Gaußian models). This is low, as expected, but it is unlikely we can get anything much higher from this dataset.</p>
<p>The observations in the dataset are to some degree not independent since many runners run in packs. This is especially the case for those runners following the official pacers. It is not clear how we could account for this or to what extent it affects the estimates. My guess is that it wouldn’t change them too much.</p>
<p>The residual QQ plot seems acceptable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qq.gam</span>(m)</code></pre></div>
<figure>
<img src="age_files/figure-markdown/unnamed-chunk-7-1.png" />
</figure>
<p>The country-level effects are modelled as Gaußian and the QQ plot indicates a decent fit, with the execption of a handful of countries on the extremes. Perhaps a non-normal distribution would model the random effects better, but we’ll roll with this for now.</p>
<p>Note that there are about 83 degrees of freedom although we have included estimates of all 118 countries. This is a direct consequence of using random effects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(m, <span class="dt">select =</span> <span class="dv">1</span>)</code></pre></div>
<figure>
<img src="age_files/figure-markdown/unnamed-chunk-8-1.png" />
</figure>
<p>An interesting byproduct of using random effects to model country level variance is that we can then rank countries by their effect. Since <code>country</code> has an additive effect and the link function is <code>exp</code>, the effect of <code>country</code> on <code>hours</code> is multiplicative. Here we show the multiplicative effect of country on net finishing time. Note that Lesotho is no longer on top despite having the highest raw average time. Indeed, this country effect is higher for those countries with both faster times and more runners.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(country, <span class="dt">.keep_all =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cbind</span>(
    <span class="kw">predict</span>(m, <span class="dt">newdata =</span> ., <span class="dt">type =</span> <span class="st">&#39;terms&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">      </span><span class="kw">transmute</span>(<span class="dt">country_effect =</span> <span class="kw">exp</span>(<span class="st">`</span><span class="dt">s(country)</span><span class="st">`</span>))
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">inner_join</span>(ranking_m1, <span class="dt">by =</span> <span class="st">&#39;country&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(country, country_effect, runners, mean_hours) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(country_effect)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">kable</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&#39;hover&#39;</span>, <span class="st">&#39;striped&#39;</span>, <span class="st">&#39;responsive&#39;</span>))</code></pre></div>
<table class="table table-hover table-striped table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
country
</th>
<th style="text-align:right;">
country_effect
</th>
<th style="text-align:right;">
runners
</th>
<th style="text-align:right;">
mean_hours
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Ethiopia
</td>
<td style="text-align:right;">
1.076819
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
2.749514
</td>
</tr>
<tr>
<td style="text-align:left;">
Kenya
</td>
<td style="text-align:right;">
1.070141
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
2.963480
</td>
</tr>
<tr>
<td style="text-align:left;">
Eritrea
</td>
<td style="text-align:right;">
1.048144
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
2.657500
</td>
</tr>
<tr>
<td style="text-align:left;">
Algeria
</td>
<td style="text-align:right;">
1.036830
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
3.276991
</td>
</tr>
<tr>
<td style="text-align:left;">
Lithuania
</td>
<td style="text-align:right;">
1.033381
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
3.552552
</td>
</tr>
<tr>
<td style="text-align:left;">
Norway
</td>
<td style="text-align:right;">
1.021137
</td>
<td style="text-align:right;">
589
</td>
<td style="text-align:right;">
3.834238
</td>
</tr>
</tbody>
</table>
<p>Feel free to explore more model diagnostics or find a better fitting model.</p>
<h2 id="results">Results</h2>
<p>Let’s create a grid of values of interest and get the fitted estimates from our model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">add_fit &lt;-<span class="st"> </span><span class="cf">function</span>(df, model) {
  <span class="co"># add columns for model&#39;s predicted response and se</span>
  df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">cbind</span>(<span class="kw">predict</span>(model, <span class="dt">newdata =</span> ., <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>))
}

<span class="co"># grid of values of interest</span>
mygrid &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(
    <span class="kw">expand.grid</span>(
      <span class="dt">age =</span> <span class="dv">15</span><span class="op">:</span><span class="dv">80</span>,
      <span class="dt">sex =</span> <span class="kw">c</span>(<span class="st">&#39;W&#39;</span>, <span class="st">&#39;M&#39;</span>),
      <span class="dt">country =</span> <span class="st">&#39;Germany&#39;</span>
    ) 
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">usex =</span> sex) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_fit</span>(m)</code></pre></div>
<p>We have used Germany as our reference country for a couple of reasons:</p>
<ol type="1">
<li>the mgcv package makes it difficult to exclude random effects from response prediction;</li>
<li>every country has the same curves up to a multiplicative constant; and</li>
<li>Germany has the highest number of participants.</li>
</ol>
<p>Ideally we would set the country effect to zero here, but will proceed regardless. Below is the point estimate with 95% confidence intervals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mygrid <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> fit, <span class="dt">colour =</span> sex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> fit <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>se.fit, <span class="dt">ymax =</span> fit <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>se.fit, <span class="dt">fill =</span> sex), <span class="dt">show.legend =</span> <span class="ot">FALSE</span>, <span class="dt">colour =</span> <span class="ot">NA</span>, <span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> mygrid <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(sex) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="kw">which.min</span>(fit))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">80</span>, <span class="dv">5</span>), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">18</span>, <span class="dv">80</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">7</span>, <span class="fl">0.25</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&#39;Average Finish Time by Age and Sex&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;The dots indicate the fastest age</span><span class="ch">\n</span><span class="st">The shaded area is a 95% confidence interval for the estimated net finishing time</span><span class="ch">\n</span><span class="st">Berlin Marathon 2016&#39;</span>,
    <span class="dt">x =</span> <span class="st">&#39;Age&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Finish Time (hours)&#39;</span>,
    <span class="dt">colour =</span> <span class="st">&#39;Sex&#39;</span>
  )</code></pre></div>
<figure>
<img src="age_files/figure-markdown/bm2016-1.png" />
</figure>
<p>The 31 years old women are the fastest age group, whereas for men it’s around 34. Moreover, the performance of the 20 year olds is comparable to that of the ~50 year olds.</p>
<p>So far we have only considered the year 2016. We can apply the same analysis to every year since 2005.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mymodel &lt;-<span class="st"> </span><span class="cf">function</span>(df) {
  <span class="co"># fit the desired model to the data</span>
  <span class="kw">gam</span>(
    hours <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(country, <span class="dt">bs =</span> <span class="st">&#39;re&#39;</span>) <span class="op">+</span><span class="st"> </span>usex <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age, <span class="dt">by =</span> sex), 
    <span class="dt">family =</span> <span class="kw">Gamma</span>(),
    <span class="dt">data =</span> df, 
    <span class="dt">method =</span> <span class="st">&quot;REML&quot;</span>
  )
}

<span class="co"># apply the model to each year separately</span>
all_years_modelled &lt;-<span class="st"> </span>df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">nest</span>(<span class="op">-</span>year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">model =</span> <span class="kw">map</span>(data, mymodel),
    <span class="dt">pred =</span> <span class="kw">map</span>(model, <span class="cf">function</span>(x) {
                        <span class="kw">add_fit</span>(mygrid, x)
                      }
    )
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(pred)</code></pre></div>
<p>This time we drop the confidence intervals and get a feel for the uncertainty by plotting a line for every year.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_years_modelled <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> fit, <span class="dt">colour =</span> year, <span class="dt">group =</span> year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> all_years_modelled <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(year, sex) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="kw">which.min</span>(fit)), <span class="dt">alpha =</span> <span class="fl">0.7</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>sex) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">20</span>, <span class="dv">80</span>, <span class="dv">5</span>), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">18</span>, <span class="dv">80</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">6</span>, <span class="fl">0.25</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&#39;Average Finish Time by Age and Sex&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;Each line is an estimate for different year: 2005 -- 2016</span><span class="ch">\n</span><span class="st">The dots indicate the fastest age&#39;</span>,
    <span class="dt">x =</span> <span class="st">&#39;Age&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Finish Time (hours)&#39;</span>,
    <span class="dt">colour =</span> <span class="st">&#39;Year&#39;</span>
  )</code></pre></div>
<figure>
<img src="age_files/figure-markdown/bm_2005_2016-1.png" />
</figure>
<p>Notice that the fastest ages approximately increase with year, most notably for women. We can display this relationship better by simply plotting estimated fastest age against year.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">all_years_modelled <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(year, sex) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="kw">which.min</span>(fit)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> age, <span class="dt">colour =</span> sex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">2005</span>, <span class="dv">2015</span>, <span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>sex) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> lm) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Year&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Age&#39;</span>,
    <span class="dt">colour =</span> <span class="st">&#39;Sex&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Fastest age per year&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;Berlin Marathon&#39;</span>
  )</code></pre></div>
<figure>
<img src="age_files/figure-markdown/fastest_age_by_year-1.png" />
</figure>
<p>It will be interesting to see if the fastest age for women stays low in future years. It is possible that this change in fastest age for women is due to increasing participation. Indeed, participation is increasing faster for women than for men, although it starts from a much smaller number.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df0 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(year, sex) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">total =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(sex, year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> total, <span class="dt">colour =</span> sex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> lm) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> scales<span class="op">::</span>comma) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">2005</span>, <span class="dv">2015</span>, <span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&#39;Year&#39;</span>,
    <span class="dt">y =</span> <span class="st">&#39;Runners&#39;</span>,
    <span class="dt">colour =</span> <span class="st">&#39;Sex&#39;</span>,
    <span class="dt">title =</span> <span class="st">&#39;Participation per sex per year&#39;</span>,
    <span class="dt">subtitle =</span> <span class="st">&#39;Berlin Marathon&#39;</span>
  )</code></pre></div>
<figure>
<img src="age_files/figure-markdown/finishers_by_year-1.png" />
</figure>
<h2 id="conclusion">Conclusion</h2>
<p>On the basis of our dataset, there is no indication that performance declines at 30. Indeed, those in their early 30s tend to be the fastest age group, both for men and women. Moreover, the performance of the 20 year olds is comparable to that of the ~50 year olds, perhaps suggesting that running performance doesn’t degrade as fast as people often think it does.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Wasserman's AoS, Chapter 8, Question 5</title>
    <link href="http://stappit.github.io/posts/allofstatistics/ch08q04.html" />
    <id>http://stappit.github.io/posts/allofstatistics/ch08q04.html</id>
    <published>2017-05-01T00:00:00Z</published>
    <updated>2017-05-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Wasserman's AoS, Chapter 8, Question 5</h1>
<p class="blog-post-meta">
Posted on May  1, 2017  by Brian </br>
 Tags: <a href="/tags/wasserman.html">wasserman</a>, <a href="/tags/all%20of%20statistics.html">all of statistics</a>, <a href="/tags/bootstrap.html">bootstrap</a>, <a href="/tags/combinatorics.html">combinatorics</a> </br>
 Category: <a href="/categories/allofstatistics.html">allofstatistics</a> 
</p>

<p>We show here that the number of possible bootstrap samples <span class="math inline">\(X_1^*, \dotsc, X_n^*\)</span> is</p>
<p class="mathjaxWide"><span class="math display">\[
{2n - 1 \choose n - 1}.
\]</span></p>
<p>given a sample <span class="math inline">\(X_1, \dotsc, X_n\)</span>.</p>
<p>In fact, we prove the more general result that the number of ways of choosing a sample (with replacement) of size k from n objects is</p>
<p class="mathjaxWide"><span class="math display">\[
{n + k - 1 \choose n - 1}.
\]</span></p>
<h2 id="wrong-solution">Wrong Solution</h2>
<p>It is tempting to answer that there are <span class="math inline">\(n^n\)</span> possibilities with the reasoning that there are n free choices for n balls. However, this overcounts the possibilities, which can be verified by hand in the simple case where <span class="math inline">\(n=k=2\)</span>.</p>
<h2 id="correct-solution">Correct Solution</h2>
<p>The proof actually counts the number of ways to write down a solution using a certain notation called <a href="https://en.wikipedia.org/wiki/Stars_and_bars_(combinatorics)">stars and bars</a>. Consider each of our observations, <span class="math inline">\(X_i\)</span>, as a bucket and each choice as a ball that we put into a bucket. By drawing the k balls in a row, we can show which bucket they fall into by separating the balls with a line. For example, for <span class="math inline">\(n=4\)</span> and <span class="math inline">\(k=3\)</span>, the choice <span class="math inline">\(X_3, X_4, X_4\)</span> would be written</p>
<pre><code>||*|**</code></pre>
<p>Similarly, we can write all solutions for <span class="math inline">\(n=2, k=3\)</span> as</p>
<pre><code>|***
*|**
**|*
***|</code></pre>
<p>The crucial point to note is that we always use <span class="math inline">\(n + k - 1\)</span> symbols for a solution: <span class="math inline">\(n-1\)</span> bars and <span class="math inline">\(k\)</span> balls. Any ordering of these symbols is a solution so we just need to figure out how many orderings there are. The positions of the bars completely determine the positions of the stars. There are <span class="math inline">\(n + k - 1\)</span> positions in total and we choose <span class="math inline">\(n-1\)</span> of these to be bars, so there are</p>
<p class="mathjaxWide"><span class="math display">\[
{n + k - 1 \choose n - 1}
\]</span></p>
<p>possible solutions.</p>
<h2 id="example">Example</h2>
<p>Here are all 10 possibilities for <span class="math inline">\(n=k=3\)</span>.</p>
<pre><code>||***
|*|**
|**|*
|***|
*||**
*|*|*
*|**|
**||*
**|*|
***||</code></pre>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>MIUT Ultra 2017 Race Report</title>
    <link href="http://stappit.github.io/posts/miut_ultra_2017.html" />
    <id>http://stappit.github.io/posts/miut_ultra_2017.html</id>
    <published>2017-04-25T00:00:00Z</published>
    <updated>2017-04-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">MIUT Ultra 2017 Race Report</h1>
<p class="blog-post-meta">
Posted on April 25, 2017  by Brian </br>
 Tags: <a href="/tags/running.html">running</a>, <a href="/tags/trail%20running.html">trail running</a>, <a href="/tags/miut.html">miut</a>, <a href="/tags/ultra.html">ultra</a> </br>
 Category: <a href="/categories/posts.html">posts</a> 
</p>

<p>This is my race report for the <a href="http://www.madeiraultratrail.com/en/the-event/ultra-course">MIUT ultra</a>, 2017.</p>
<h2 id="summary">Summary</h2>
<p>Here is an overview of the course.</p>
<figure>
<img src="../images/miut_ultra_2017_profile.png" alt="Course Profile: The first checkpoint, Rosário, wasn’t there this year." /><figcaption>Course Profile: The first checkpoint, Rosário, wasn’t there this year.</figcaption>
</figure>
<dl>
<dt>Distance</dt>
<dd>83.9km
</dd>
<dt>Elevation Gain</dt>
<dd>4400m
</dd>
<dt>Elevation Loss</dt>
<dd>4400m
</dd>
<dt>Time</dt>
<dd><a href="https://madeiraultratrail.info/#/event/42/96/results/athlete/10226/24697?embed">17:13</a>
</dd>
<dt>Where</dt>
<dd>Madeira, Portugal
</dd>
<dt>When</dt>
<dd>April 22nd, 2017
</dd>
</dl>
<h2 id="goals">Goals</h2>
<p>My main goal was just to finish. I had never run an ultra before and living in Berlin doesn’t offer much by way of preparation for something like MIUT. Finishing in a little over 17h was a pleasant surprise.</p>
<h2 id="training">Training</h2>
<p>I was primarily training for a sub 3h marathon in march with the intention to reverse-taper into the ultra. This would have probably been fine if my motivation hadn’t waned. This was partly due to calf problems but, as it was, I should have trained more. Much more. I hit a max of 90 km/week in training with fairly minimal speed work.</p>
<h2 id="gear">Gear</h2>
<p>I felt fairly well equipped for the run.</p>
<figure>
<img src="../images/miut_ultra_2017_gear.jpg" alt="Gear" /><figcaption>Gear</figcaption>
</figure>
<p>Required:</p>
<ul>
<li>Race vest (Nathan Vapor Air)</li>
<li>Bladder</li>
<li>Water bottle</li>
<li>Bivy</li>
<li>Bandage</li>
<li>Headlamp (Black Diamond Astro) + spare batteries</li>
<li>Torch + spare batteries</li>
<li>Red taillight (Nathan)</li>
<li>Food (gels, Cliff Bars, trail mix)</li>
</ul>
<p>Other:</p>
<ul>
<li>Running shoes (Saucony Kinvara 7)</li>
<li>Poles (Black Diamond FLZ Carbon)</li>
<li>Cap (Salomon)</li>
<li>Sunglasses</li>
<li>Gloves</li>
<li>MP3 player (Scan Disk Clip Sport)</li>
<li>Waste bag + toilet paper</li>
</ul>
<h2 id="pre-race">Pre-Race</h2>
<p>The race start was at 07:00 in São Vicente on the north of the island. The race organisors offered a shuttle service from Machico (east) to the start, leaving at 05:00, which took away much of the stress of using Madeira’s awkward public transport system. Apart from forgetting my pre-race breakfast of oats, everything ran very smoothly. Two Cliff bars and a gel had to suffice for breakfast.</p>
<h2 id="race">Race</h2>
<h3 id="são-vicente-encumeada-12.8km-1100m-390m--146">São Vicente ➡️ Encumeada (12.8km, 1100m+, 390m-, 1:46)</h3>
<p>My average speed of over 7kph felt super easy at the time but was too fast in retrospect. I passed many runners on the uphills throughout the entire race, especially here at the start, which perhaps led to overconfidence. ‘Easy’ in a marathon is different form ‘easy’ in an ultra.</p>
<h3 id="encumeada-curral-das-freiras-15.3km-890m-1060m--319">Encumeada ➡️ Curral das Freiras (15.3km, 890m+, 1060m-, 3:19)</h3>
<p>This is where I made my biggest mistake: starting to jog the downhills. They felt easy and non-technical but after the massive descent into Curral das Freiras I wasn’t able to do any more downhill without pain. I ran out of water (it was HOT) and also thought I had run out gels so I was knackered by the time I got into the checkpoint. After downing a half litre of Pepsi and devouring a Cliff bar amongst other snacks, I sorted out my pack and found my gels. They were mega useful for the next section.</p>
<figure>
<img src="../images/miut_ultra_2017_downhill.jpg" alt="Downhill" /><figcaption>Downhill</figcaption>
</figure>
<h3 id="curral-das-freiras-pico-ruivo-10.8km-1370m-290m--256">Curral das Freiras ➡️ Pico Ruivo (10.8km, 1370m+, 290m-, 2:56)</h3>
<p>This section was by far the most stunning and beautiful. Climb, gel, water, repeat, <a href="https://www.youtube.com/watch?v=wwBhxBBa7tE">Moon Hooch</a>ing all the way to the top. The mountains are epic and it feels almost godlike as you pass through the clouds to the peak. Only occassionally did the dense white fog give way to offer a dizzying glimpse at the sheer cliffs.</p>
<figure>
<img src="../images/miut_ultra_2017_mordor.jpg" alt="Beautiful Mountains" /><figcaption>Beautiful Mountains</figcaption>
</figure>
<p>The checkpoint was out of power and was running on candlelight as I arrived. It was so cramped and I was feeling good so I thought I’d ‘just’ confinue on the next and much larger checkpoint. “Just 5km”, I thought. Haha!</p>
<h3 id="pico-ruivo-pico-do-areeiro-5.5km-460m-420m--125">Pico Ruivo ➡️ Pico do Areeiro (5.5km, 460m+, 420m-, 1:25)</h3>
<p>This section was very technical and the steps were especially steep. Every downhill was agony for my quads and I was grateful for every uphill. I ate lots of trail mix and arrived at the checkpoint utterly exhausted.</p>
<figure>
<img src="../images/miut_ultra_2017_feet.jpg" alt="My Feet" /><figcaption>My Feet</figcaption>
</figure>
<p>Fortunately my dropbag was here and I took the opportunity to rest (~40mins), change my sweat-soaked T-shirt/socks, stock up on calories/water, and take a caffeine pill (200mg). As I lay on the ground waiting for the caffeine to kick in, a guy came sauntering around the corner and, with neither a break in step nor smile, let forth a jet of vomit. A nearby child started to cry as the guy made another projectile offering to the mountain gods. I hope that guy was alright but I can’t deny that this lifted my mood. With a caffeine buzz in my body and the <a href="https://www.youtube.com/watch?v=rwvCEWWWt7Q">Oh Hellos</a> in my ear, I started the next section.</p>
<h3 id="pico-do-areeiro-ribeiro-frio-9.3km-125m-1035m--223">Pico do Areeiro ➡️ Ribeiro Frio (9.3km, 125m+, 1035m-, 2:23)</h3>
<p>The scenery changed drastically here, from single-track mountain paths to open fields, which fitted my now chilled-out mood. The descents still hurt but were manageable.</p>
<figure>
<img src="../images/miut_ultra_2017_happy.jpg" alt="Happy :)" /><figcaption>Happy :)</figcaption>
</figure>
<p>As I neared the checkpoint, I realised something wasn’t right: my stomach was sore, felt blocked up, and I couldn’t eat any more. Drinking was also unpleasant. This remained for the rest of the race and, other than two gels, stopped eating for the day. Too much solid food, too early?</p>
<h3 id="ribeiro-frio-poiso-3.8km-485m-0m--112">Ribeiro Frio ➡️ Poiso (3.8km, 485m+, 0m-, 1:12)</h3>
<p>Ugh, my stomach.</p>
<h3 id="poiso-portela-8.8km-30m-805m--143">Poiso ➡️ Portela (8.8km, 30m+, 805m-, 1:43)</h3>
<p>Eternal downhill of pain. The last of the sunlight disappeared as I arrived at the checkpoint.</p>
<h3 id="portela-larano-5.2km-35m-320m--055">Portela ➡️ Larano (5.2km, 35m+, 320m-, 0:55)</h3>
<p>Three portuguese women were running behind me on the way into Portela and I joined them as they passed. I’m so grateful to them for getting me moving again.</p>
<h3 id="larano-ribeira-seca-7.5km-80m-175m--130">Larano ➡️ Ribeira Seca (7.5km, 80m+, 175m-, 1:30)</h3>
<p>Darkness and the sound of waves. Time seemed to stand still.</p>
<h3 id="ribeira-seca-machico-4.3km-5m-220m--044">Ribeira Seca ➡️ Machico (4.3km, 5m+, 220m-, 0:44)</h3>
<p>Lots of people ran past me here. I didn’t care any more. At some point I was walking behing a portuguese guy called <a href="https://madeiraultratrail.info/#/event/42/95/results/athlete/10053/24024">José</a>, who was finishing the full MIUT course. We walked for an eternity. Thank you, José. The last downhill into the finish was slippery and painful but when we got to the road we jogged it in together.</p>
<h2 id="post-race">Post-Race</h2>
<p>Sleep, breakfast x 3, sleep, lunch, ice-cream, jacuzzi.</p>
<h2 id="learnings">Learnings</h2>
<ul>
<li>Take it really, really easy at the start, especially on the downhills.</li>
<li>I’m good at uphills.</li>
<li>Be careful on the downhills, especially when technical.</li>
<li>I still need to find out why my stomach gave up at ~60km:
<ul>
<li>too much water?</li>
<li>too much fibre/solid food early on?</li>
</ul></li>
<li>Do the proper training!</li>
</ul>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Wasserman's AoS, Chapter 8, Question 5</title>
    <link href="http://stappit.github.io/posts/allofstatistics/ch08q05.html" />
    <id>http://stappit.github.io/posts/allofstatistics/ch08q05.html</id>
    <published>2017-04-16T00:00:00Z</published>
    <updated>2017-04-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Wasserman's AoS, Chapter 8, Question 5</h1>
<p class="blog-post-meta">
Posted on April 16, 2017  by Brian </br>
 Tags: <a href="/tags/wasserman.html">wasserman</a>, <a href="/tags/all%20of%20statistics.html">all of statistics</a>, <a href="/tags/bootstrap.html">bootstrap</a>, <a href="/tags/conditional%20expectation.html">conditional expectation</a>, <a href="/tags/conditional%20variance.html">conditional variance</a> </br>
 Category: <a href="/categories/allofstatistics.html">allofstatistics</a> 
</p>

<p>We solve question 5 from chapter 8 os Wasserman’s “All of Statistics” making the implicit assumption that <span class="math inline">\(X_1, \dotsc, X_n\)</span> are iid. Other computation solutions can be found in the corresponding <a href="https://github.com/stappit/all-of-statistics">GitHub reepo</a>.</p>
<p>Given <span class="math inline">\(X_1, \dotsc, X_n\)</span>, the random variable <span class="math inline">\(X_i^*\)</span> can take any of those <span class="math inline">\(\le n\)</span> values. With the assumption that there are no ties (i.e. there are n distinct values), <span class="math inline">\(X_i^*\)</span> has a discrete uniform distribution over <span class="math inline">\(X_1, \dotsc, X_n\)</span>. (If there are ties, then the distribution is not uniform). We use this fact multiple times to obtain the result.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb E (\bar X_n^* \vert X_1, \dotsc, X_n)
  &amp;=
  \frac{1}{n} \sum_1^n \mathbb E (X_i^* \vert \dotsc)
  \\
  &amp;=
  \frac{1}{n} \sum_1^n \sum_1^n X_j \frac{1}{n}
  \\
  &amp;=
  \frac{1}{n} \sum_1^n \bar X_n
  \\
  &amp;=
  \bar X_n
  ,
\end{align}
\]</span></p>
<p>where we used The Fact for the 2nd equality.</p>
<p>Moreover,</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb E (\bar X_n^*)
  &amp;=
  \mathbb E \mathbb E (\bar X_n^* \vert X_1, \dotsc, X_n)
  \\
  &amp;=
  \mathbb E \bar X_n
  \\
  &amp;=
  \mu
  ,
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\mu := \mathbb E X_1\)</span>, assuming it exists.</p>
<p>For the conditional variance,</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb V (\bar X_n^* \vert X_1, \dotsc, X_n)
  &amp;=
  \frac{1}{n^2} \sum_1^n \mathbb V (X_i^* \vert \dotsc)
  \\
  &amp;=
  \frac{1}{n^2} \sum_1^n \sum_1^n \frac{(X_j - \bar X_n)^2}{n}
  \\
  &amp;=
  \frac{1}{n} \sum_1^n \frac{(X_i - \bar X_n)^2}{n}
  \\
  &amp;=
  \frac{S_n}{n}
  .
\end{align}
\]</span></p>
<p>This has expectation <span class="math inline">\(\frac{\sigma^2}{n}\)</span>, where <span class="math inline">\(\sigma^2 := \mathbb V X_1\)</span>, assuming it exists.</p>
<p>Before calculating the variance, we require one more identity - the variance of the conditional expectation.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb V \mathbb E (\bar X_n^* \vert X_1, \dotsc, X_n)
  &amp;=
  \mathbb V \bar X_n
  \\
  &amp;=
  \frac{\sigma^2}{n}
  .
\end{align}
\]</span></p>
<p>The expression for the variance now follows from Theorem 3.27.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \mathbb V (\bar X_n^*)
  &amp;=
  \mathbb V \mathbb E (\bar X_n^* \vert X_1, \dotsc, X_n)
  +
  \mathbb E \mathbb V (\bar X_n^* \vert X_1, \dotsc, X_n)
  \\
  &amp;=
  \frac{\sigma^2}{n}
  +
  \frac{\sigma^2}{n}
  \\
  &amp;=
  2 \frac{\sigma^2}{n}
  .
\end{align}
\]</span></p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Wasserman's AoS, Chapter 7, Question 5</title>
    <link href="http://stappit.github.io/posts/allofstatistics/ch07q05.html" />
    <id>http://stappit.github.io/posts/allofstatistics/ch07q05.html</id>
    <published>2017-04-11T00:00:00Z</published>
    <updated>2017-04-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Wasserman's AoS, Chapter 7, Question 5</h1>
<p class="blog-post-meta">
Posted on April 11, 2017  by Brian </br>
 Tags: <a href="/tags/wasserman.html">wasserman</a>, <a href="/tags/all%20of%20statistics.html">all of statistics</a>, <a href="/tags/covariance.html">covariance</a>, <a href="/tags/empirical%20distribution%20function.html">empirical distribution function</a> </br>
 Category: <a href="/categories/allofstatistics.html">allofstatistics</a> 
</p>

<p>We show that the covariance <span class="math inline">\(\text{Cov} (\hat F_n(x), \hat F_n(y))\)</span> is <span class="math display">\[
\frac{1}{n} F(x) \left( 1 + F(y) \right)
,
\]</span> for <span class="math inline">\(x \le y\)</span>. For <span class="math inline">\(x \ge y\)</span>, we have <span class="math inline">\(\frac{1}{n} F(y) \left( 1 + F(x) \right)\)</span>.</p>
<p>Using linearity of expectation and the fact that <span class="math inline">\(\mathbb E \hat F_n(y) = F(y)\)</span>, we obtain</p>
<p class="mathjaxWide"><span class="math display">\[
\mathbb E (\hat F_n(x) - F(x)) (\hat F_n(y) - F(y))
=
\mathbb E (\hat F_n(x)\hat F_n(y)) - F(x)F(y)
.
\]</span></p>
<p>By definition of the empirical cumulative distribution function, the first term is equal to</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{1}{n^2} \sum_{i, j} \mathbb E (I(X_i \le x)I(X_j \le y))
=
\frac{1}{n^2} \left( 
	\sum_{i = j} \mathbb E (I(X_i \le x)I(X_i \le y))
	+ \sum_{i \ne j} \mathbb E (I(X_i \le x)I(X_j \le y))
\right)
.
\]</span></p>
<p>We now simplify the two summations:</p>
<ol type="1">
<li><p>Without loss of generality, we may assume that <span class="math inline">\(x \le y\)</span>. With this assumption, <span class="math inline">\(I(X_i \le x)I(X_i \le y) = I(X_i \le x)\)</span>.</p></li>
<li><p>Note that the Bernoulli variables <span class="math inline">\(I(X_i \le x)\)</span> and <span class="math inline">\(I(X_j \le y)\)</span> are independent for <span class="math inline">\(i \ne j\)</span> since <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_j\)</span> are independent. This implies that the expectation of the product is the product of the expectations.</p></li>
</ol>
<p>These two facts allow us to rewrite the first term as</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
	\frac{1}{n^2} \left( 
			\sum_{i = j} \mathbb E (I(X_i \le x))
			+ \sum_{i \ne j} \mathbb E (I(X_i \le x)) \mathbb E (I(X_j \le y))
			\right)
	&amp;=
	\frac{1}{n^2} \left( 
			\sum_{i = j} F(x)
			+ \sum_{i \ne j} F(x)F(y)
			\right)
	\\
	&amp;=
	\frac{1}{n} F(x) (
			1 + (n-1) F(y)
			)
\end{align}
.
\]</span></p>
<p>Putting everything together, we see that the covariance is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
\frac{1}{n} F(x) (1 + (n-1) F(y)) - F(x)F(y)
&amp;=
\frac{1}{n} F(x) (1 + F(y))
\end{align}
\]</span></p>
<p>for <span class="math inline">\(x \le y\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS, Chapter 6</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc06.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc06.html</id>
    <published>2015-12-05T00:00:00Z</published>
    <updated>2015-12-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS, Chapter 6</h1>
<p class="blog-post-meta">
Posted on December  5, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/execution%20trace.html">execution trace</a>, <a href="/tags/queue.html">queue</a>, <a href="/tags/merge%20sort.html">merge sort</a>, <a href="/tags/sortable.html">sortable</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 6 of Okasaki’s “Purely Functional Data Structures”.</p>
<h2 id="exercise-6.1">Exercise 6.1</h2>
<p>Draw the execution trace for the following set of operations.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">a <span class="fu">=</span> snoc empty <span class="dv">0</span>
b <span class="fu">=</span> snoc a <span class="dv">1</span>
c <span class="fu">=</span> tail b
d <span class="fu">=</span> snoc b <span class="dv">2</span>
e <span class="fu">=</span> c <span class="fu">++</span> d
f <span class="fu">=</span> tail c
g <span class="fu">=</span> snoc d <span class="dv">3</span></code></pre></div>
<p>Annotate each node in the trace with the number of logical futures at that node.</p>
<h2 id="solution-6.1">Solution 6.1</h2>
<figure>
<img src="/images/pfds_ex6-1.pdf.png" alt="The execution trace." /><figcaption>The execution trace.</figcaption>
</figure>
<p>There are three terminal nodes (i.e. out-degree = 0): <code>e</code>, <code>f</code>, and <code>g</code>.</p>
<p>Each terminal node has precisely one logical future. The number of logical futures of a non-terminal node is the sum of the number of logical futures of its neighbours.</p>
<h2 id="exercise-6.2">Exercise 6.2</h2>
<p>Change the banker’s queue invariant to <span class="math inline">\(2\left| f \right| \ge \left| r \right|\)</span>.</p>
<ol type="1">
<li>Show that the <span class="math inline">\(\mathcal O (1)\)</span> amortised bounds still hold.</li>
<li>Compare the relative performance of the two implementations on a sequence of one hundred <code>snoc</code>s followed by one hundred <code>tail</code>s.</li>
</ol>
<h2 id="solution-6.2">Solution 6.2</h2>
<p><strong>Item 1.</strong></p>
<p>We assign the debt <span class="math inline">\(D(i) \le \min(3i, 2\left|f\right| - \left|r\right|)\)</span> to the <span class="math inline">\(i\)</span>th element of the front.</p>
<p>Every <code>snoc</code> that doesn’t cause a rotation increases <span class="math inline">\(|r|\)</span> by 1 and decreases <span class="math inline">\(2\left|f\right| - \left|r\right|\)</span> by 1. This violates the debt invariant by 1 whenever we just previously had <span class="math inline">\(D(i) = 2\left|f\right| - \left|r\right|\)</span>. We can restore the invariant by discharging the first debit in the queue, which decreases the rest by 1.</p>
<p>Every <code>tail</code> that doesn’t cause a rotation dereases <span class="math inline">\(\left| f \right|\)</span> by 1, so decreases <span class="math inline">\(2\left|f\right| - \left|r\right|\)</span> by 2. It also decreases the the index of the remaining nodes by 1, so decreases <span class="math inline">\(3i\)</span> by 3. Discharging the first three debits in the queue restores the debt invariant.</p>
<p>Now for a <code>snoc</code> that causes a rotation. Just before the rotation, the invariant guarantees that all debits in the queue have been discharged, so after the rotation the only undischarged debits are those created by the rotation itself. Suppose <span class="math inline">\(\left| f \right|=m\)</span> and <span class="math inline">\(\left| r \right|=2m+1\)</span> at the time of the rotation. Then we create <span class="math inline">\(2m+1\)</span> debits for the reverse and <span class="math inline">\(m\)</span> for the append. The placement of debits is as in the book, which is summarised as follows.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  d (i) 
  &amp;=
  \begin{cases}
    1 &amp; i &lt; m \\
    3m+1 &amp; i = m \\
    0 &amp; i &gt; m
  \end{cases}
  \\
  D (i)
  &amp;=
  \begin{cases}
    i + 1 &amp; i &lt; m \\
    3m+1 &amp; i \ge m 
  \end{cases}
\end{align}
\]</span></p>
<p>The debit invariant is violated at <span class="math inline">\(i=0\)</span> (since <span class="math inline">\(D(0) = 1 &gt; 0\)</span>) and at <span class="math inline">\(i = m\)</span> (since <span class="math inline">\(D (m) = 3m + 1 &gt; 3m\)</span>). Discharging one debit from the zeroth node restores the invariant.</p>
<p>Finally, consider a <code>tail</code> which causes a rotation. There are two cases:</p>
<ol type="1">
<li>Either <span class="math inline">\(\left| f \right| = m\)</span> and <span class="math inline">\(\left| r \right| = 2m + 1\)</span>; or</li>
<li>we have <span class="math inline">\(\left| f \right| = m\)</span> and <span class="math inline">\(\left| r \right| = 2m + 2\)</span>.</li>
</ol>
<p>The first case is analogous to that of <code>snoc</code>; discharging one debit will restore the invariant.</p>
<p>For the second case, we have one more debit than in the first case, which we place on the zeroth node. Now</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  d (i) 
  &amp;=
  \begin{cases}
    2 &amp; i = 0 \\
    1 &amp; 0 &lt; i &lt; m \\
    m+1 &amp; i = m \\
    0 &amp; i &gt; m
  \end{cases}
  \\
  D (i)
  &amp;=
  \begin{cases}
    i + 2 &amp; i &lt; m \\
    3m+2 &amp; i \ge m 
  \end{cases}.
\end{align}
\]</span></p>
<p>We can restore the invariant by discharging two debits from the zeroth node.</p>
<p><strong>Item 2.</strong></p>
<p>Since all suspensions are evaluated, the cost of 100 <code>snocs</code> followed by 100 <code>tails</code> is the complete cost of this sequence of operations. That is, we can pretend that all evaluation is strict.</p>
<p>The only possible difference is in the sum of the lengths of lists that need to be reversed. With the invariant <span class="math inline">\(\left| r \right| \le \left| f \right|\)</span>, this cost amounts to <span class="math inline">\(2^0 + 2^1 + \dots + 2^5 = 2^6 - 1 = 63\)</span>. With the invariant <span class="math inline">\(\left| r \right| \le 2\left| f \right|\)</span>, this cost amounts to <span class="math inline">\(3^0 + 3^1 + 3^2 + 3^3 = 40\)</span>. Thus, we would expect the second invariant to exhibit better performance for the execution trace above.</p>
<h2 id="exercise-6.3">Exercise 6.3</h2>
<p>Prove that <code>findMin</code>, <code>deleteMin</code>, and <code>merge</code> also run in logarithmic amortised time.</p>
<h2 id="solution-6.3">Solution 6.3</h2>
<p>The proofs are essentially dual to those of <a href="/posts/pfds/okasakiPFDSc05.html#exercise-5.3">Exercise 5.3</a>.</p>
<p><strong><code>findMin</code></strong></p>
<p>Let <code>h</code> be a heap of size <span class="math inline">\(n\)</span>. Then <code>findMin h</code> makes a call to <code>removeMinTree</code>, which is linear in the length of the list. Since there are <span class="math inline">\(\log n\)</span> elements in the list, the complete cost of <code>findMin</code> is logarithmic. We must also add the potential, but this is at most <span class="math inline">\(\log n\)</span>, so <code>findMin</code> has indeed <span class="math inline">\(\mathcal O (\log n)\)</span> time.</p>
<p><strong><code>merge</code></strong></p>
<p>The unshared cost is constant. Let <code>h1</code>, <code>h2</code> be binomial heaps of sizes <span class="math inline">\(n_1\)</span>, <span class="math inline">\(n_2\)</span>, respectively. The shared cost is bounded by <span class="math inline">\(\log n_1 + \log n_2 + k\)</span>, where <code>link</code> is called <span class="math inline">\(k\)</span> times. Since <span class="math inline">\(\Phi (m+n) - \Phi (m) - \Phi (n) = -k\)</span>, we have <span class="math inline">\(\Psi (n_1+n_2) - \Psi (n_1) - \Psi (n_2) = k + d (n_1 +n_2) - d(n_1) - d(n_2)\)</span>, where <span class="math inline">\(d (x)\)</span> is the number of bits of <span class="math inline">\(x\)</span>. Thus, the potential increase is greater than <span class="math inline">\(k - \log n_1 - \log n_2\)</span>, giving an amortised cost <span class="math inline">\(\mathcal O (\log n_1 + \log n_2)\)</span>.</p>
<p><strong><code>deleteMin</code></strong></p>
<p>Now we show that <code>deleteMin</code> is also logarithmic. We start with a heap <code>h</code> with <span class="math inline">\(n\)</span> elements. The unshared cost is constant. The shared cost consists of: a call to <code>removeMinTree</code>, which is <span class="math inline">\(\mathcal O (\log n)\)</span>; reversing the list of children, which is <span class="math inline">\(\mathcal O (r)\)</span>; and a call to <code>mrg</code>, which is <span class="math inline">\(k + r + \log n\)</span> where <span class="math inline">\(k\)</span> is the number of calls to <code>link</code>. As with <code>merge</code>, the increase in potential is <span class="math inline">\(k - 2\log n\)</span>, leaving us with an amortised cost of <span class="math inline">\(\mathcal O(r + \log n)\)</span>.</p>
<h2 id="exercise-6.4">Exercise 6.4</h2>
<p>Show that removing the keyword <code>lazy</code> from the definitions of <code>merge</code> and <code>deleteMin</code> doesn’t change the amortised complexity of these funtions.</p>
<h2 id="solution-6.4">Solution 6.4</h2>
<p>For <code>merge</code>, we saw that the complete cost is <span class="math inline">\(\log n_1 + \log n_2 + k\)</span> and the potential increase is <span class="math inline">\(k - \log n_1 - \log n_2\)</span>. Thus, the amortised cost is <span class="math inline">\(\mathcal O (\log n_1 + \log n_2)\)</span> whether <code>merge</code> is lazy or not. A similar argument also works for <code>deleteMin</code>.</p>
<h2 id="exercise-6.5">Exercise 6.5</h2>
<p>Implement a functor <code>SizedHeap</code> that transforms any implementation of heaps into one that explicitly maintains the size.</p>
<h2 id="solution-6.5">Solution 6.5</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/430c770236fd25e29913204fde61128bc89a8f54/src/Chap06/Data/SizedHeap.hs">source</a>.</p>
<h2 id="exercise-6.6">Exercise 6.6</h2>
<p>Show that the following break the <span class="math inline">\(\mathcal O (1)\)</span> amortised time bounds.</p>
<ol type="1">
<li>Never force <code>f</code> until <code>w</code> becomes empty.</li>
<li>During <code>tail</code>, don’t change <code>f</code> but instead just decrease <code>lenf</code> to indicate that the element has been removed.</li>
</ol>
<h2 id="solution-6.6">Solution 6.6</h2>
<p><strong>Item 1</strong></p>
<p>When analysing <code>snoc</code> or <code>tail</code>, part of the shared costs comes from the suspension <code>$(f' @ rev r)</code>. If <code>f' = force f</code>, then evaluating this suspension is linear, as Okasaki shows. If <code>f' = f</code>, then evaluating this suspension is slower than linear. This is due to the fact that we have cascading dependencies of nested suspensions</p>
<p>For <span class="math inline">\(n = 2^k - 1\)</span>, the suspension would contribute to a shared cost of</p>
<p class="mathjaxWide"><span class="math display">\[
  (2^{k-1} + 2^{k-1} - 1) + \dots + (2^0 + 2^0 - 1)
  =
  2n - k - 2
\]</span></p>
<p>Since the increase in potential is <span class="math inline">\(n\)</span>, the amortised cost is <span class="math inline">\(\mathcal O (n)\)</span>, which isn’t constant.</p>
<p><strong>Item 2</strong></p>
<p>This change has two very obvious drawbacks:</p>
<ol type="1">
<li><p>it renders the algorithms incorrect.</p>
<p>For example, <code>head . tail . snoc 1 (empty)</code> should yield an error but instead yields <code>1</code>.</p></li>
<li><p>it is incredibly memory inefficient.</p>
<p>For example, <code>iterate (tail . snoc 1) empty !! k</code> uses at least <span class="math inline">\(\mathcal O (k+1)\)</span> memory instead of constant memory.</p></li>
</ol>
<p>We need to show that it is also inefficient with respect to the time complexity. The <span class="math inline">\(\left| f \right|\)</span> in the potential should be interpreted as <code>lenf</code> instead of <code>length f</code> in order to guarantee that the potential is zero when we force the suspended list. Calling <code>snoc 1</code> on the queue <code>iterate (tail . snoc 1) empty !! k</code> will cause a rotation. However, the shared cost is now <span class="math inline">\(k + m + 1\)</span> instead of <span class="math inline">\(2m+1\)</span>, where <span class="math inline">\(k \ge m\)</span>. For <span class="math inline">\(k = cm\)</span>, <span class="math inline">\(c &gt; 1\)</span>, the new potential is <span class="math inline">\(2m+1\)</span>. Thus, the amortised complexity is <span class="math inline">\(1 + (k+m+1) - (2m+1) \ge (c-1)m\)</span>; that is, <code>snoc</code> is no longer constant time.</p>
<h2 id="exercise-6.7">Exercise 6.7</h2>
<p>Changing the representation from suspended list to a list of streams:</p>
<ol type="1">
<li>Prove the bounds on <code>add</code> and <code>sort</code> using the banker’s method; and</li>
<li>Write a function to extract the <span class="math inline">\(k\)</span> smallest elements from a sortable collection, proving that the funtion runs in <span class="math inline">\(\mathcal O (k \log n)\)</span> time.</li>
</ol>
<h2 id="solution-6.7">Solution 6.7</h2>
<p><strong>Item 1</strong>.</p>
<p>Due to the monolithic nature of the functions, it suffices to assign all debits to the root. This way, we could just maintain the debit invariant that the number of debits in the collection is <span class="math inline">\(D \le \Psi (n)\)</span>, where <span class="math inline">\(n\)</span> is the length of the list. However, for the next part, we will require the list of streams representation and to assign the debits in an incremental fashion.</p>
<p>First, a couple of definitions. Let <span class="math inline">\(s_n (i)\)</span> be the length of the ith stream in a collection of size <span class="math inline">\(n\)</span>. Then define <span class="math inline">\(\sigma_n (i) := \sum_{k=0}^i s_n (i)\)</span>. Note that <span class="math inline">\(n = \sigma_n (B-1)\)</span> where <span class="math inline">\(B\)</span> is the number of one-bits (streams) of <span class="math inline">\(n\)</span>.</p>
<p>Let <span class="math inline">\(d_n (i, j)\)</span> be the number of debits on the jth element of the ith stream in a collection of size <span class="math inline">\(n\)</span>. Then</p>
<p class="mathjaxWide"><span class="math display">\[
D_n (i, j) := \sum_{l=0}^j d_n (i, l) + \sum_{k = 0}^{i-1} \sum_{l = 0}^{s_n (i)} d_n (k, l)
\]</span></p>
<p>is the total number of debits up to the jth element of the ith stream in a collection of size <span class="math inline">\(n\)</span>. For convenience, we also define</p>
<p class="mathjaxWide"><span class="math display">\[
\Delta_n (i, j) := \sum_{k=0}^j d_n (i, k),
\]</span> the total number of debits up to the jth element counting only within the ith stream.</p>
<p>We maintain two debit invariants:</p>
<ol type="1">
<li>each stream has <span class="math inline">\(\Delta_n (i, j) \le 2j\)</span> debits; and</li>
<li>the cummulative total of debits is <span class="math inline">\(D_n (i, j) \le \Psi (\sigma_n (i))\)</span>.</li>
</ol>
<p>We show that the amortised cost of <code>add</code> is logarithmic in the size of the collection. Suppose we have a collection of <span class="math inline">\(n\)</span> elements satisfying both debit invariants. Let <span class="math inline">\(k\)</span> be the largest integer such that the first <span class="math inline">\(k\)</span> bits of <span class="math inline">\(n\)</span> are one-bits. The unshared cost of <code>add</code> is constant, as already shown in the book. The shared cost is <span class="math inline">\(2^{k+1}-2\)</span>, so we create that many debits. We assign two of these debits to each element of the new zeroth stream, except from the zeroth element. More precisely,</p>
<p class="mathjaxWide"><span class="math display">\[
\Delta_{n+1} (0, j) = 2j.
\]</span></p>
<p>Since the size of the zeroth stream is <span class="math inline">\(s_{n+1} (0) = 2^k\)</span>, we have assigned a total of <span class="math inline">\(2(2^k - 1)\)</span> debits as required. There are no more debits to reassign since</p>
<p class="mathjaxWide"><span class="math display">\[
D_n (k-1) \le \Psi (\sigma_n (k-1)) = \Psi (2^k - 1) = 0.
\]</span></p>
<p>We have maintained the first invariant by construction but may have violated the second invariant. There are now a total of</p>
<p class="mathjaxWide"><span class="math display">\[
D_{n+1} (i, j) = D_n (i+k-1, j) + 2^{k+1} - 2
\]</span> debits but are allowed at most <span class="math inline">\(\Psi (\sigma_{n+1} (i))\)</span>. Thus, we should pay off</p>
<p class="mathjaxWide"><span class="math display">\[
D_n (i+k-1, j) + 2^{k+1} - 2 - \Psi (\sigma_{n+1} (i))
\]</span></p>
<p>debits. This is at least <span class="math inline">\(\Psi (\sigma_n (i+k-1)) - \Psi (\sigma_{n+1} (i)) + 2^{k+1} - 2\)</span>. Note that <span class="math inline">\(\sigma_{n+1} (i) = \sigma_n (i+k-1) + 1\)</span>. It follows that we need to pay at least <span class="math inline">\(2B_i&#39;-2\)</span> debits from the first <span class="math inline">\(i\)</span> streams, where <span class="math inline">\(B_i&#39;\)</span> is the number of one-bits of <span class="math inline">\((n+1) \mod 2 s_{n+1} (i)\)</span>; that is, the number of one-bits in the first <span class="math inline">\(i\)</span> bits of <span class="math inline">\(n+1\)</span>. Therefore, we can restore the second invariant by paying off two debits from each stream. The realised shared cost is thus <span class="math inline">\(2B&#39;-2\)</span>.</p>
<p>Showing that <code>sort</code> is linear is much easier. The second invariant guarantees that there are at most <span class="math inline">\(\Psi (n)\)</span> debits. We can just pay them all off, giving basically the same analysis as with the physicist’s method.</p>
<p><strong>Item 2</strong>.</p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/2b33c51b47e266b83f05ce6a7c6fd4063f5dd75f/src/Chap06/Exercise07.hs">source</a>.</p>
<p>Note that the first invariant allows us to access the head of each stream whenever we want. The unshared cost is <span class="math inline">\(2\log n\)</span> since we make one pass over the streams to find the minimum and then one more pass to remove it. In order to be able to access the heads of all remaining streams, we should pay at most two more debits. Thus, <code>extract 1</code> has complexity <span class="math inline">\(\mathcal O (\log n)\)</span>. It follows by induction, that <code>extract k</code> has complexity <span class="math inline">\(\mathcal O (k\log n)\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS, Chapter 5</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc05.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc05.html</id>
    <published>2015-11-25T00:00:00Z</published>
    <updated>2015-11-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS, Chapter 5</h1>
<p class="blog-post-meta">
Posted on November 25, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/deque.html">deque</a>, <a href="/tags/binomial%20heap.html">binomial heap</a>, <a href="/tags/splay%20heap.html">splay heap</a>, <a href="/tags/pairing%20heap.html">pairing heap</a>, <a href="/tags/heap.html">heap</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 5 of Okasaki’s ‘Purely Functional Data Structures’. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="exercise-5.1">Exercise 5.1</h2>
<ol type="1">
<li>Implement deques.</li>
<li>Prove that each deque operation takes <span class="math inline">\(\mathcal O (1)\)</span> amortised time using the potential <span class="math display">\[\Phi (f, r) = \left| \left|f\right| - \left|r\right| \right|.\]</span></li>
</ol>
<h2 id="solution-5.1">Solution 5.1</h2>
<p><strong>Item 1.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap05/Data/BatchedQueue.hs">source</a>.</p>
<p><strong>Item 2.</strong></p>
<p>By symmetry, the costs of <code>cons</code>, <code>head</code>, and <code>tail</code> are (almost) identical to those of <code>snoc</code>, <code>last</code>, and <code>init</code>, respectively.</p>
<p>Consider <code>cons</code>. There is a constant number of actual steps and the potential can change by at most 1. Thus <code>cons</code> runs in constant amortised time.</p>
<p>Consider <code>tail</code>. Any <code>tail</code> which doesn’t empty <code>f</code> requires only one step and changes the potential by one for an amortised cost of <span class="math inline">\(\le 2\)</span>. Any <code>tail</code> which does empty <code>f</code> requires <span class="math inline">\(1 + 2m + \delta\)</span> steps, where <span class="math inline">\(m := \left\lfloor \frac{r}{2} \right\rfloor\)</span>, <span class="math inline">\(\left| r \right| = 2m + \delta\)</span>. The linearity is due to the fact that it takes <span class="math inline">\(m\)</span> steps to split <code>r</code> in half, then <span class="math inline">\(m\)</span> more steps to reverse the other half. The change in potential is given by</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \left|1 - (2m + \delta)\right| - \left|m - (2m + \delta - m)\right| 
  &amp;= 
  2m + 1 + \delta - \delta 
  \\
  &amp;= 
  2m + 1
.
\end{align}
\]</span></p>
<p>Thus, the amortised cost is <span class="math inline">\(1 + 2m + \delta - 2m = 1\)</span>, showing that <code>tail</code> runs in constant amortised time.</p>
<h2 id="exercise-5.2">Exercise 5.2</h2>
<p>Prove that <code>insert</code> on binomial heaps runs in <span class="math inline">\(\mathcal O (1)\)</span> amortised time using the banker’s method.</p>
<h2 id="solution-5.2">Solution 5.2</h2>
<p>The credit invariant associates one credit to every binomial tree in the heap. Let <span class="math inline">\(k\)</span> be the number of calls to <code>link</code> made by a call to <code>insert</code>. A call to <code>insert</code> takes <span class="math inline">\(1 + k\)</span> actual steps. It initially adds a tree to the heap, gaining a credit, and each <code>link</code> removes a tree, spending a credit. Thus, the total amortised cost is <span class="math inline">\((1+k) + 1 - k = 2\)</span>.</p>
<h2 id="exercise-5.3">Exercise 5.3</h2>
<p>Prove that the amortised costs of <code>merge</code> and <code>deleteMin</code> are still <span class="math inline">\(\mathcal O (\log n)\)</span>.</p>
<h2 id="solution-5.3">Solution 5.3</h2>
<p>Let <span class="math inline">\(h_m\)</span>, <span class="math inline">\(h_n\)</span> be binomial heaps with potentials <span class="math inline">\(m\)</span>, <span class="math inline">\(n\)</span>, respectively. We show that the amortised cost of <code>merge</code> is <span class="math inline">\(A(h_m, h_n) \le m+n\)</span>. Let <span class="math inline">\(k\)</span> be the number of calls to <code>link</code>. The actual cost is bounded by <span class="math inline">\(m + n + k\)</span>, since there can be at most <span class="math inline">\(m+n\)</span> recursive calls to <code>merge</code> and any call reaching the third conditional clause of <code>merge</code> will call <code>link</code> several times via <code>insTree</code>. We start with a potential of <span class="math inline">\(m+n\)</span>, and each call to <code>link</code> reduces this by one, for an end potential of <span class="math inline">\(m+n-k\)</span>. The change in potential is <span class="math inline">\(m + n - (m + n - k) = k\)</span>. Thus, the amortised cost of <code>merge</code> is <span class="math inline">\(m+n+k -k = m+n\)</span>.</p>
<p>Now we show that <code>deleteMin</code> is also logarithmic. We start with a heap <span class="math inline">\(h_n\)</span>, which has potential <span class="math inline">\(n\)</span>. There is an actual cost of at most <span class="math inline">\(n\)</span> to find the minimum binary tree, say of rank <span class="math inline">\(r\)</span>. This leaves us with a heap of rank <span class="math inline">\(n-1\)</span>. Then there is an actual cost of at most <span class="math inline">\(r\)</span> to reverse the list of children, making a heap of potential <span class="math inline">\(r\)</span>. Merging these heaps then takes at most <span class="math inline">\(n + r - 1 + k\)</span> steps, where <span class="math inline">\(k\)</span> is the number of calls to <code>link</code>, which leaves us with a heap with potential <span class="math inline">\(n + r - 1 - k\)</span>. This is a total of at most <span class="math inline">\(n + r + (n + r - 1 + k)\)</span> steps. The change in potential is <span class="math inline">\(n - (n + r - 1 - k) = 1 - r + k\)</span>. Thus, the amortised cost of <code>deleteMin</code> is</p>
<p class="mathjaxWide"><span class="math display">\[
2n + 2r + k - 1 - (1 - r + k) = 2n + 3r - 2
.
\]</span></p>
<p>Note that this is indeed logarithmic since, if a heap has a tree of rank <span class="math inline">\(r\)</span>, then it must have at least <span class="math inline">\(2^r\)</span> elements; that is, <span class="math inline">\(r = \mathcal O (\log n)\)</span>.</p>
<h2 id="splay-heaps">Splay Heaps</h2>
<p>A splay heap is a BST that rebalances the tree using a <code>partition</code> function when performing update operations. However, we now allow the insertion of the same element multiple times since we are implementing a heap and not a set.</p>
<figure>
<img src="/images/pfds-splayheap-unbalanced.pdf.png" alt="h = foldr insert empty [1..7]" /><figcaption><code>h = foldr insert empty [1..7]</code></figcaption>
</figure>
<figure>
<img src="/images/pfds-splayheap-unbalanced-insert.pdf.png" alt="insert 8 h" /><figcaption><code>insert 8 h</code></figcaption>
</figure>
<h2 id="exercise-5.4">Exercise 5.4</h2>
<p>Implement <code>smaller</code>.</p>
<h2 id="solution-5.4">Solution 5.4</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap05/Exercise04.hs">source</a>.</p>
<h2 id="exercise-5.5">Exercise 5.5</h2>
<p>Prove that <code>partition</code> is logarithmic (in the zig-zag case).</p>
<h2 id="solution-5.5">Solution 5.5</h2>
<p>First we will need a modification to the lemma proved in the book.</p>
<dl>
<dt>Lemma</dt>
<dd><p>We have the inequality</p>
<p class="mathjaxWide"><span class="math display">\[
1 + \log x + \log y \le 2\log (x + y -1)
.
\]</span></p>
<p>for all <span class="math inline">\(x \in \mathbb N_{\ge 2}\)</span>, <span class="math inline">\(y \in \mathbb N_{\ge 1}\)</span>.</p>
</dd>
</dl>
<p>Using the basic logarithmic identities, the above inequality is equivalent to <span class="math inline">\(2xy \le (x+y-1)^2\)</span>. In other words, we must show that <span class="math inline">\(x^2 -2x + (y-1)^2 \ge 0\)</span> for <span class="math inline">\(x \ge 2\)</span>, <span class="math inline">\(y \ge 1\)</span>. The term with <span class="math inline">\(y\)</span> is non-negative. The remaining term <span class="math inline">\(x^2 -2x\)</span> is non-negative for any <span class="math inline">\(x \ge 2\)</span>.</p>
<p>□</p>
<figure>
<img src="/images/pfds-ex5.5-input.pdf.png" alt="We wish to analyse partition pivot t." /><figcaption>We wish to analyse <code>partition pivot t</code>.</figcaption>
</figure>
<figure>
<img src="/images/pfds-ex5.5-output.pdf.png" alt="Suppose partition pivot t outputs (t_s, t_b)." /><figcaption>Suppose <code>partition pivot t</code> outputs <span class="math inline">\((t_s, t_b)\)</span>.</figcaption>
</figure>
<p>Define <span class="math inline">\((p_s, p_b)\)</span> as the output of <code>partition pivot p</code>. Note that <span class="math inline">\(\#t_s + \#t_b = \#t - 1\)</span>, so that <span class="math inline">\(1 + \phi(t_s) + \phi(t_b) \le 2\phi(t)\)</span> by the lemma.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  A (t) 
  &amp;= 
  T (t) + \Phi (t_s) + \Phi (t_b) - \Phi (t)
  \\
  &amp;=
  1 + T (p) + \Phi (t_s) + \Phi (t_b) - \Phi (t)
  \\
  &amp;=
  1 + A (p) - \Phi (p_s) - \Phi (p_b) + \Phi (p) 
  \\
  &amp;\qquad
            + \Phi (t_s) + \Phi (t_b) - \Phi (t)
  \\
  &amp;=
  1 + A (p) - \Phi (p_s) - \Phi (p_b) + \Phi (p)
  \\
  &amp;\qquad
            + \phi (t_s) + \Phi (a_1) + \Phi (p_s)
  \\
  &amp;\qquad
	    + \phi (t_b) + \Phi (p_b) + \Phi (b)
  \\
  &amp;\qquad
	    - \phi (t)   - \phi (s)   - \Phi (b)  - \Phi (a_1) - \Phi (p)
  \\
  &amp;=
  1 + A (p) + \phi (t_s) + \phi (t_b) - \phi (t) - \phi (s)
  \\
  &amp;\le
  2 + 2\phi (p) + \phi(t_s) + \phi(t_b) - \phi(t) - \phi(s)
  \\
  &amp;\le
  2 + \phi(t) + \phi(s) + \phi(t_s) - \phi(t_b) - \phi(t) - \phi(s)
  \\
  &amp;\le
  2 + \phi(t_s) + \phi(t_b)
  \\
  &amp;\le
  1 + 2\phi(t)
\end{align}
\]</span></p>
<h2 id="exercise-5.6">Exercise 5.6</h2>
<p>Prove that <code>deleteMin</code> also runs in logarithmic time.</p>
<h2 id="solution-5.6">Solution 5.6</h2>
<p>We prove that <code>deleteMin</code> runs in <span class="math inline">\(\mathcal O(3\log n)\)</span> amortised time. Note that <span class="math inline">\(\#a + (\#b + \#c) \le \#s_1\)</span> so that <span class="math inline">\(1 + \phi(a) + \phi(t_2) \le 2\phi(s_1)\)</span>.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  A(s_1)
  &amp;=
  T(s_1) + \Phi(t_1) - \Phi(s_1)
  \\
  &amp;=
  1 + T(a) + \Phi(t_1) - \Phi(s_1)
  \\
  &amp;=
  1 + A(a) - \Phi(a&#39;) + \Phi(a)
  \\
  &amp;\qquad
  	+ \phi(t_1) + \phi(t_2) + \Phi(a&#39;) + \Phi(b) + \Phi(c)
  \\
  &amp;\qquad
  	- \phi(s_1) - \phi(s_2) - \Phi(a) -  \Phi(b) - \Phi(c)
  \\
  &amp;=
  1 + A(a) + \phi(t_1) + \phi(t_2) - \phi(s_1) -\phi(s_2)
  \\
  &amp;\le
  1 + \phi(a) + \phi(t_1) + \phi(t_2)
  \\
  &amp;\le
  \phi(t_1) + 2\phi(s_1)
  \\
  &amp;\le
  3\phi(s_1)
\end{align}
\]</span></p>
<h2 id="exercise-5.7">Exercise 5.7</h2>
<p>Write a sorting function that inserts elements into a splay tree and then performs an in order traversal of the tree dumping the elements into a list. Show that this function takes linear time in a sorted list.</p>
<h2 id="solution-5.7">Solution 5.7</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/5cd2c0ae4641edb65ba88f4c7bf0e0a49a23063a/src/Chap05/Exercise07.hs">source</a>.</p>
<p>Let <code>xs</code> be a list of length <span class="math inline">\(n\)</span> in decreasing order. We can measure the complexity of <code>sort xs</code> by counting the number of calls to <code>partition</code>. Every time we call <code>insert x h</code>, we know that <span class="math inline">\(x &gt; y\)</span> for all <span class="math inline">\(y\)</span> in <code>h</code>, so <code>insert x h</code> calls <code>partition</code> exactly once. The function <code>sort xs</code> makes a total of <span class="math inline">\(n\)</span> calls to <code>insert</code> and thus also <span class="math inline">\(n\)</span> calls to <code>partition</code>, showing that <code>sort</code> runs in <span class="math inline">\(\mathcal O (n)\)</span> time.</p>
<p>The argument for lists in increasing order is completely analogous.</p>
<h2 id="pairing-heaps">Pairing Heaps</h2>
<p>A pairing heap is a heap-ordered multiway tree whose <code>deleteMin</code> operation merges the children in pairs.</p>
<figure>
<img src="/images/pfds-pairingheap-wide.pdf.png" alt="h = foldr insert empty [7, 6..1]" /><figcaption><code>h = foldr insert empty [7, 6..1]</code></figcaption>
</figure>
<figure>
<img src="/images/pfds-pairingheap-wide-deletemin.pdf.png" alt="deleteMin h" /><figcaption><code>deleteMin h</code></figcaption>
</figure>
<h2 id="exercise-5.8">Exercise 5.8</h2>
<ol type="1">
<li><p>Write a function <code>toBinary</code> that converts pairing heaps to binary trees.</p></li>
<li><p>Reimplement pairing heaps using this new representation as binary trees.</p></li>
<li><p>Prove that <code>deleteMin</code> and <code>merge</code> still run in logarithmic amortised time in this new representation.</p></li>
</ol>
<h2 id="solution-5.8">Solution 5.8</h2>
<p><strong>Item 1.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/897522b05776b202e622b55b03cd0438dd581798/src/Chap05/Exercise08.hs">source</a>.</p>
<p>The conversion from a pairing heap to a binary tree is explained in the book.</p>
<figure>
<img src="/images/pfds_ex5-8b_invariant.pdf.png" alt="For any binary tree derived from a pairing heap, x \le y, y_a, y_b for all elements y_a, y_b in the trees a, b, respectively. The right child of the root is empty. The values in b are not related to y." /><figcaption>For any binary tree derived from a pairing heap, <span class="math inline">\(x \le y, y_a, y_b\)</span> for all elements <span class="math inline">\(y_a, y_b\)</span> in the trees <span class="math inline">\(a, b\)</span>, respectively. The right child of the root is empty. The values in <span class="math inline">\(b\)</span> are not related to <span class="math inline">\(y\)</span>.</figcaption>
</figure>
<p>The invariant on a pairing heap <code>T x cs</code> is that <code>x</code> is no greater than any of the elements of its children in <code>cs</code>. This translates into the binary tree invariant that a node is no greater than any of its left descendants. That is, for <code>T' x (T' y a b) c</code> we have that <span class="math inline">\(x \le y, y_a, y_b\)</span> for all elements <span class="math inline">\(y_a, y_b\)</span> in the trees <span class="math inline">\(a, b\)</span>, respectively. The value of <span class="math inline">\(x\)</span> bears no relation to the values in <span class="math inline">\(c\)</span>.</p>
<p>We also maintain a second invariant: the right child of the root is empty.</p>
<p><strong>Item 2.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/897522b05776b202e622b55b03cd0438dd581798/src/Chap05/Data/PairingHeap/Exercise08.hs">source</a>.</p>
<p>Remember that the root of a binary tree representation of a pairing heap has no right child (it is empty). Thus we can forget about the right child without losing desired information.</p>
<p><strong>Item 3.</strong></p>
<p>We start with <code>merge</code>. Note that for any <span class="math inline">\(x, y \ge 2\)</span>, we have <span class="math inline">\(\log (x+y) \le \log x + \log y\)</span>. In particular, <span class="math inline">\(\#s_k \ge 2\)</span>.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  A (s_1, s_2) 
  &amp;= 
  T (s_1, s_2) + \Phi (t_1) - \Phi (s_1) - \Phi (s_2)
  \\
  &amp;=
  1 + \Phi(t_1) - \Phi(s_1) - \Phi(s_2)
  \\
  &amp;=
  1 + \phi(t_1) + \phi(t_2) - \phi(s_1) - \phi(s_2)
  \\
  &amp;\le
  2 + 2\phi(t_1)
  \\
  &amp;\le
  2 + 2\log (\#s_1 + \#s_2)
  \\
  &amp;\le
  2 + 2\log(\#s_1) + 2\log(\#s_2)
  \\
  &amp;\le
  2 + 2\phi(s_1) + 2\phi(s_2)
\end{align}
\]</span></p>
<p>Now consider <code>deleteMin</code>. I was unable to find a nice solution by myself. The following comes from <a href="https://www.cs.cmu.edu/~sleator/papers/pairing-heaps.pdf">The Pairing Heap: A New Form of Self-Adjusting Heap</a>. We reproduce their argument that the asymptotic cost of <code>deleteMin</code> is <span class="math inline">\(A(s_1) \le 2\phi(s_1) + 3\)</span>.</p>
<p>There are at most <span class="math inline">\(2k+1\)</span> calls to <code>merge</code>, where <span class="math inline">\(k\)</span> is the number of children of the root of the pairing heap. The difficult part is calculating the potential increase, which we do in steps.</p>
<dl>
<dt>Lemma 1</dt>
<dd>Let <span class="math inline">\(x, y &gt; 0\)</span> such that <span class="math inline">\(x + y \le 1\)</span>. Then <span class="math inline">\(\log x + \log y \le -2\)</span>.
</dd>
</dl>
<p>Proof. This follows from the fact that <span class="math inline">\(xy \le x(1-x)\)</span>, which has a maximum of <span class="math inline">\(\frac{1}{4}\)</span> at <span class="math inline">\(x = \frac{1}{2}\)</span>.</p>
<p>□</p>
<dl>
<dt>Corollary</dt>
<dd><p>We have</p>
<p class="mathjaxWide"><span class="math display">\[
\log(x + y) - \log(y + z) \le 2 \log (x + y + z) - 2\log z - 2
,
\]</span></p>
<p>for any <span class="math inline">\(x, y, z \ge 0\)</span>.</p>
</dd>
</dl>
<p>Proof. By the lemma we have</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \log(x + y) + \log z - 2\log (x + y + z) 
  &amp;= 
  \log \left(\frac{x + y}{x + y + z}\right) + \log \left(\frac{z}{x + y + z}\right) 
  \\
  &amp;\le 
  -2.
\end{align}
\]</span></p>
<p>Now</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
 \log(x + y) - \log(y + z) 
 &amp;= 
 \log(x + y) + \log z - \log z - \log(y+z)
 \\
 &amp;\le
 2\log (x + y + z) - 2 - \log z -\log(y+z)
 \\
 &amp;\le
 2\log (x + y + z) - 2 - 2\log z.
\end{align}
\]</span></p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd>Define <span class="math inline">\(s_2\)</span> to be the tree <code>T y b c</code> and <span class="math inline">\(s_1\)</span> to be the tree <code>T x a s2</code>.<br />
Then applying <code>merge</code> to <span class="math inline">\(s_1\)</span> results in a potential increase of at most <span class="math inline">\(2\phi(s_1) - 2\phi(c) - 2\)</span>.
</dd>
</dl>
<p>Proof. Without loss of generality, assume <span class="math inline">\(y \le x\)</span>. Define <span class="math inline">\(t_2\)</span> to be the tree <code>T x a b</code> and <span class="math inline">\(t_1\)</span> to be <code>T y t2 c</code>; that is, <span class="math inline">\(t_1\)</span> is the result of applying <code>merge</code> to <span class="math inline">\(s_1\)</span>. The potential increase is <span class="math inline">\(\Phi(t_1) - \Phi(s_1)\)</span>, by definition. This expands to <span class="math inline">\(\phi(t_1) + \phi(t_2) - \phi(s_1) - \phi(s_2)\)</span>, which is equal to <span class="math inline">\(\phi(t_2) - \phi(s_2)\)</span> since <span class="math inline">\(\phi(t_1) = \phi(s_1)\)</span>. Now</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \phi(t_2) - \phi(s_2) 
  &amp;= 
  \log(\#a + \#b) - \phi(\#b + \#c) 
  \\
  &amp;\le 
  2\log(\#a + \#b + \#c) - 2\log (\#c) - 2 
  \\
  &amp;= 
  2\phi(s_1) - 2\phi(c) - 2.
\end{align}
\]</span></p>
<p>□</p>
<dl>
<dt>Corollary</dt>
<dd>Define <span class="math inline">\(s_i\)</span> as the right child of <span class="math inline">\(s_{i-1}\)</span>, where <span class="math inline">\(s_1\)</span> is the root of the binary tree, <span class="math inline">\(i = 1, ..., 2k - 1\)</span>, and <span class="math inline">\(2k + \delta\)</span> is the length of the right spine of <span class="math inline">\(s_1\)</span>. Then the net increase in potential over all calls to <code>merge</code> in the downwards pass of <code>mergePairs</code> is bounded by <span class="math inline">\(2\phi(s_1) - 2(k-1)\)</span>.
</dd>
</dl>
<p>Proof. Applying the previous lemma yields</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  2\phi(s_{2k-1}) + \sum_{i=1}^{k-1} \left( 2\phi(s_{2i - 1}) - 2\phi(s_{2i + 1}) - 2 \right)
  &amp;\le
  2\phi(s_{2k-1}) - 2(k-1) + \sum_{i=1}^{k-1} \left( 2\phi(s_{2i - 1}) - 2\phi(s_{2i + 1}) \right)
  \\
  &amp;\le
  2\phi(s_1) - 2(k-1),
\end{align}
\]</span></p>
<p>where the last line follows by telescoping the sum.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd>The net increase in potential over all calls to merge in the upwards pass of <code>mergePairs</code> is bounded by <span class="math inline">\(\phi(s_1)\)</span>.
</dd>
</dl>
<p>Proof. Let <span class="math inline">\(t\)</span> be the resulting tree after calling <code>merge</code> on two trees <span class="math inline">\(t_1, t_2\)</span>. Furthermore, let <span class="math inline">\(t_1&#39;, t_2&#39;\)</span> be the subtrees whose roots contain the keys of the trees <span class="math inline">\(t_1, t_2\)</span>, respectively. Then <span class="math inline">\(\phi(t_1) \le \phi(t_1&#39;)\)</span> and <span class="math inline">\(\phi(t_2) \ge \phi(t_2&#39;)\)</span>. Thus, the potential increase is bounded by <span class="math inline">\(\phi(t)\)</span>. Since <span class="math inline">\(\#t = \#s_1\)</span>, the potential increase is bounded by <span class="math inline">\(\phi(s_1)\)</span>.</p>
<p>□</p>
<p>There are at most <span class="math inline">\(2k + 1\)</span> actual steps. Removing the root causes a potential increase of <span class="math inline">\(-\phi(s_1)\)</span>. The potential increase in the downwards pass in <code>mergePairs</code> is bounded by <span class="math inline">\(2\phi(s_1) - 2(k-1)\)</span>. The potential increase in the upwards pass in <code>mergePairs</code> is bounded by <span class="math inline">\(\phi(s_1)\)</span>. Therefore, the amortised time is bounded by</p>
<p class="mathjaxWide"><span class="math display">\[
2k + 1 - \phi(s_1) + 2\phi(s_1) - 2(k-1) + \phi(s_1) = 3 + 2\phi(s_1)
.
\]</span></p>
<h2 id="exercise-5.9">Exercise 5.9</h2>
<p>Give examples of sequences of operations for which binomial heaps, splay heaps, and pairing heaps take much longer than indicated by their amortised bounds.</p>
<h2 id="solution-5.9">Solution 5.9</h2>
<p>For any operation with amortised bounds, we can set up the data structure so that the next execution of that operation is expensive, then call that operation many times.</p>
<p><strong>Binomial Heaps</strong></p>
<p>Binomial heaps support an <code>insert</code> operation with a constant amortised cost. The worst case cost of <code>insert</code> is <span class="math inline">\(\mathcal O (\log n)\)</span>, which occurs when inserting into a binomial heap of size <span class="math inline">\(2^m - 1\)</span>. In a persistent setting, we can call <code>insert</code> k times on this heap, executing in <span class="math inline">\(\mathcal O(k\log n)\)</span> time instead of <span class="math inline">\(\mathcal O(k)\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">heap <span class="fu">=</span> foldr insert empty [<span class="dv">1</span><span class="fu">..</span>(<span class="dv">2</span><span class="fu">^</span>m <span class="fu">-</span> <span class="dv">1</span>)]
  <span class="kw">where</span>
    m <span class="fu">=</span> <span class="dv">7</span>
    n <span class="fu">=</span> <span class="dv">2</span><span class="fu">^</span>m <span class="fu">-</span> <span class="dv">1</span>

tooSlow <span class="fu">=</span> map (insert <span class="dv">0</span>) <span class="fu">.</span> replicate k <span class="fu">$</span> heap
  <span class="kw">where</span>
    k <span class="fu">=</span> <span class="dv">100</span></code></pre></div>
<p><strong>Splay Heaps</strong></p>
<p>Splay heaps support a <code>findMin</code> operation with a logarithmic amortised cost. The worst case cost of <code>findMin</code> is linear, which occurs after inserting numbers in increasing order into the empty heap. In a persistent setting, we can call <code>findMin</code> k times on this heap, executing in <span class="math inline">\(\mathcal O(kn)\)</span> time instead of <span class="math inline">\(\mathcal O(k\log n)\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">heap <span class="fu">=</span> foldr insert empty [<span class="dv">1</span><span class="fu">..</span>n]
  <span class="kw">where</span>
    n <span class="fu">=</span> <span class="dv">100</span>

tooSlow <span class="fu">=</span> map findMin <span class="fu">.</span> replicate k <span class="fu">$</span> heap
  <span class="kw">where</span> 
    k <span class="fu">=</span> <span class="dv">100</span></code></pre></div>
<p><strong>Pairing Heaps</strong></p>
<p>Pairing heaps have a <code>deleteMin</code> operation with an amortised cost of <span class="math inline">\(\mathcal O (\log n)\)</span>. The worst case cost of <code>deleteMin</code> is <span class="math inline">\(\mathcal O (n)\)</span>, which occurs after inserting numbers in decreasing order into the empty heap. In a persistent setting, we can call <code>deleteMin</code> k times on this heap, executing in <span class="math inline">\(\mathcal O(kn)\)</span> time instead of <span class="math inline">\(\mathcal O(k\log n)\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">heap <span class="fu">=</span> foldr insert empty [n, (n<span class="fu">-</span><span class="dv">1</span>)<span class="fu">..</span><span class="dv">1</span>]
  <span class="kw">where</span>
    n <span class="fu">=</span> <span class="dv">100</span>

tooSlow <span class="fu">=</span> map deleteMin <span class="fu">.</span> replicate k <span class="fu">$</span> heap
  <span class="kw">where</span> 
    k <span class="fu">=</span> <span class="dv">100</span></code></pre></div>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS, Chapter 4</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc04.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc04.html</id>
    <published>2015-11-08T00:00:00Z</published>
    <updated>2015-11-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS, Chapter 4</h1>
<p class="blog-post-meta">
Posted on November  8, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/lazy.html">lazy</a>, <a href="/tags/strict.html">strict</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 4 of Okasaki’s “Purely Functional Data Structures”. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="notation">Notation</h2>
<p>Okasaki uses <code>$</code> to indicate suspensions. But beware! Haskell also has this symbol but it means something completely different, namely function application. In symbols:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">($) ::</span> (a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> b
(<span class="fu">$</span>) f a <span class="fu">=</span> f a</code></pre></div>
<p>We can use it like any other function in haskell. For example:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">two <span class="fu">=</span> (<span class="dv">1</span> <span class="fu">+</span>) <span class="fu">$</span> <span class="dv">1</span></code></pre></div>
<p>It has nothing to do with suspensions, evaluation, forcing, etc.</p>
<p>It is also important to note that a ‘list’ in haskell is not what Okasaki calls a ‘list’. He would call haskell’s lists ‘streams’. We will stick with haskell’s notation, calling Okasaki’s list a ‘strict list’.</p>
<h2 id="exercise-1">Exercise 1</h2>
<p>Show that both definitions of <code>drop</code> are equivalent.</p>
<h2 id="solution-1">Solution 1</h2>
<p>The code in this solution is NOT Haskell.</p>
<p>For convenience, we give names to the three different functions.</p>
<pre><code>fun drop (0, s)            = s
  | drop (n, $Nil)         = $Nil
  | drop (n, $Cons (x, s)) = drop (n-1, s)</code></pre>
<pre><code>fun lazy dropA (0, s)            = s
       | dropA (n, $Nil)         = $Nil
       | dropA (n, $Cons (x, s)) = dropA (n-1, s)</code></pre>
<pre><code>fun lazy dropB (n, s) = drop (n, s)</code></pre>
<p>The proof proceeds in three steps.</p>
<dl>
<dt>Lemma</dt>
<dd>Let <code>s</code> be a suspension. Then <code>$force s</code> is equivalent to <code>s</code>.
</dd>
</dl>
<p>Proof. Suppose <code>s</code> is <code>$e</code> for some expression <code>e</code>. Then <code>$force s</code> <span class="math inline">\(\cong\)</span> <code>$force $e</code> <span class="math inline">\(\cong\)</span> <code>$e</code> <span class="math inline">\(\cong\)</span> <code>s</code>.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd><code>dropA</code> is equivalent to <code>drop</code>
</dd>
</dl>
<p>Proof. We prove this by induction on <span class="math inline">\(n\)</span>.</p>
<p>For the base step, <code>dropA (0, s)</code> = <code>$force s</code> $<code>`s</code> = <code>drop (0, s)</code>, where the middle equivalence follows by the previous lemma.</p>
<p>Note that <code>dropA (n, $Nil)</code> = <code>$force $Nil</code> = <code>$Nil</code> = <code>drop (n, $Nil)</code> follows by the previous lemma. Now suppose <code>dropA (n, s)</code> <span class="math inline">\(\cong\)</span> <code>drop (n, s)</code> for some <span class="math inline">\(n \in \mathbb N\)</span> and any stream <code>s</code>. We can write <code>s</code> as <code>$Cons (x, s')</code>. Then <code>dropA (n+1, s)</code> = <code>dropA (n+1, $Cons (x, s'))</code> = <code>$force dropA (n, s')</code> <span class="math inline">\(\cong\)</span> <code>dropA (n, s')</code> <span class="math inline">\(\cong\)</span> <code>drop (n, s')</code> = <code>drop (n+1, s)</code>.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd><code>dropA</code> is equivalent to <code>dropB</code>
</dd>
</dl>
<p>Proof. Using the previous two lemmas, we obtain <code>dropB (n, s)</code> = <code>$force drop (n, s)</code> = <code>$force dropA (n, s)</code> = <code>dropA (n, s)</code> for any <span class="math inline">\(n \in \mathbb N\)</span> and any stream <code>s</code>.</p>
<p>□</p>
<h2 id="exercise-2">Exercise 2</h2>
<p>Implement insertion sort on streams and show that extracting the first <span class="math inline">\(k\)</span> elements takes only <span class="math inline">\(\mathcal O (nk)\)</span> time, where <span class="math inline">\(n\)</span> is the length of the input list.</p>
<h2 id="solution-2">Solution 2</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/70501d73d4cf242bfd0128308fa635e7ca95ceef/src/Chap04/Exercise02.hs">source</a>. Note that lists in Haskell are what Okasaki calls streams, so we need no special annotations or data structures.</p>
<p>Let <span class="math inline">\(T (n, k)\)</span> be the asymptotic complexity of computing <code>take k $ sort xs</code>, where <code>xs</code> is a list of length <span class="math inline">\(n\)</span>. By definition of <code>take</code>, <span class="math inline">\(T (n, 0) = \mathcal O (1)\)</span> and <span class="math inline">\(T (0, k) = T (0, 0)\)</span>.</p>
<p>In <code>take k $ sort xs</code> the function <code>take k</code> needs to put <code>sort xs</code> into weak head normal form. Let <span class="math inline">\(S (m)\)</span> be the complexity of puting <code>sort ys</code> into weak head normal form for a list <code>ys</code> of length <span class="math inline">\(m\)</span>. Clearly <span class="math inline">\(S (0) = \mathcal O (1)\)</span>. Since <code>sort (y:ys) = ins y $ sort ys</code>, we have <span class="math inline">\(S (m) = S (m-1) + \mathcal O (1)\)</span>, since <code>ins y</code> only needs to put <code>sort ys</code> into weak head normal form. This is solved by <span class="math inline">\(S (m) = \mathcal O (m)\)</span>.</p>
<p>Now, <code>take k $ sort xs = take k $ y : ys = y : take (k-1) ys</code>, where <code>sort xs = y : ys</code>. Thus <span class="math inline">\(T (n, k) = T (n-1, k-1) + \mathcal O (n)\)</span>. This recurrence is solved by <span class="math inline">\(T (n, k) = \mathcal O (nk)\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS, Chapter 3</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc03.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc03.html</id>
    <published>2015-11-01T00:00:00Z</published>
    <updated>2015-11-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS, Chapter 3</h1>
<p class="blog-post-meta">
Posted on November  1, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/leftist%20tree.html">leftist tree</a>, <a href="/tags/leftist%20heap.html">leftist heap</a>, <a href="/tags/binomial%20tree.html">binomial tree</a>, <a href="/tags/binomial%20heap.html">binomial heap</a>, <a href="/tags/heap.html">heap</a>, <a href="/tags/red%20black%20tree.html">red black tree</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 3 of Okasaki’s ‘Purely Functional Data Structures’. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="leftist-trees">Leftist Trees</h2>
<p>The right spine of a binary tree is the rightmost path from that node to an empty node. For example, the empty tree has a right spine of length 0.</p>
<p>A binary tree is said to satisfy the leftist property if every node has the property that the rank of its left child (= length of its right spine) is greater than or equal to the rank of its right child. A leftist tree is a binary tree with the leftist property.</p>
<p>The following are some examples of (the shape of) leftist trees where the keys have been omitted. The number at each node instead indicates the length of its right spine and any blank nodes are empty nodes.</p>
<figure>
<img src="/images/leftist-tree-1-node.pdf.png" alt="The only leftist tree with 1 node." /><figcaption>The only leftist tree with 1 node.</figcaption>
</figure>
<figure>
<img src="/images/leftist-tree-2-nodes.pdf.png" alt="The only leftist tree with 2 nodes." /><figcaption>The only leftist tree with 2 nodes.</figcaption>
</figure>
<figure>
<img src="/images/leftist-tree-3-nodes-1.pdf.png" alt="A leftist tree with 3 nodes." /><figcaption>A leftist tree with 3 nodes.</figcaption>
</figure>
<figure>
<img src="/images/leftist-tree-3-nodes-2.pdf.png" alt="A leftist tree with 3 nodes." /><figcaption>A leftist tree with 3 nodes.</figcaption>
</figure>
<h2 id="heaps">Heaps</h2>
<p>A tree is said to be heap-ordered if the key of any node is less than or equal to the key of any of its descendants. We capture this structure in the <code>Heap</code> typeclass.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">class</span> <span class="dt">Heap</span> h <span class="kw">where</span>
<span class="ot">  empty     ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a
<span class="ot">  isEmpty   ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> <span class="dt">Bool</span>
<span class="ot">  insert    ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span>   a <span class="ot">-&gt;</span> h a <span class="ot">-&gt;</span> h a
<span class="ot">  merge     ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> h a <span class="ot">-&gt;</span> h a
<span class="ot">  findMin   ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> <span class="dt">Maybe</span> a     <span class="co">-- may be empty</span>
<span class="ot">  deleteMin ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> <span class="dt">Maybe</span> (h a) <span class="co">-- may be empty</span></code></pre></div>
<p>A leftist heap is a heap-ordered leftist tree. We can implement this as a binary tree with a heap instance.</p>
<h2 id="exercise-3.1">Exercise 3.1</h2>
<p>Prove that the right spine of a leftist heap of size <span class="math inline">\(n\)</span> contains at most <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor\)</span> elements.</p>
<h2 id="solution-3.1">Solution 3.1</h2>
<p>We prove the stronger result that a leftist tree of rank <span class="math inline">\(r\)</span> is complete up to depth <span class="math inline">\(r-1\)</span>. The solution then follows from the fact that a tree complete up to depth <span class="math inline">\(r-1\)</span> has at least <span class="math inline">\(2^r - 1\)</span> nodes.</p>
<p>The proof proceeds by induction on the number of nodes.</p>
<p>The statement is true for the empty tree.</p>
<p>Let <span class="math inline">\(T\)</span> be a leftist tree of rank <span class="math inline">\(r\)</span> with <span class="math inline">\(n\)</span> nodes. Then each child is a leftist tree with fewer nodes, so we may apply the induction hypothesis to each child. The right child has rank <span class="math inline">\(r-1\)</span> and, by the leftist property of <span class="math inline">\(T\)</span>, the left child has rank at least <span class="math inline">\(r-1\)</span>. By the induction hypothesis, each child is complete up to depth <span class="math inline">\(r-2\)</span>. Therefore, <span class="math inline">\(T\)</span> is complete up to depth <span class="math inline">\(r-1\)</span>. □</p>
<h2 id="exercise-3.2">Exercise 3.2</h2>
<p>Define <code>insert</code> directly rather than via a call to <code>merge</code>.</p>
<h2 id="solution-3.2">Solution 3.2</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/2ecdad0e72de18d8b250e6cddad011b00debecda/src/Chap03/Exercise02.hs">source</a>.</p>
<h2 id="exercise-3.3">Exercise 3.3</h2>
<p>Implement a function <code>fromList</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">fromList ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> [a] <span class="ot">-&gt;</span> <span class="dt">LeftistHeap</span> a</code></pre></div>
<p>that produces a leftist heap from an unordered list of elements in <span class="math inline">\(\mathcal O (n)\)</span> time by merging in pairs.</p>
<h2 id="solution-3.3">Solution 3.3</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise03.hs">source</a>.</p>
<p>Note that we only use the Heap API, so we are guaranteed both the heap invariants and the leftist invariants. We must only check that the implementation is in fact linear.</p>
<p>Let’s look at the first few cases in detail.</p>
<ul>
<li><p>The first call to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(n/2\)</span> times on two heaps of size <span class="math inline">\(2^0\)</span>. This has a cost of <span class="math inline">\(\frac{n}{2} \log 2 = \frac{n}{2}\)</span>.</p></li>
<li><p>The second call to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(n/4\)</span> times on heaps of size <span class="math inline">\(2^1\)</span>. This has a cost of <span class="math inline">\(\frac{n}{4} \log 4 = \frac{n}{4} \cdot 2\)</span>.</p></li>
<li><p>The third call to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(n/8\)</span> times on heaps of size <span class="math inline">\(2^2\)</span>. This has a cost of <span class="math inline">\(\frac{n}{8} \log 8 = \frac{n}{8} \cdot 3\)</span>.</p></li>
</ul>
<p>Indeed, the <span class="math inline">\(k\)</span>th all to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(\frac{n}{2^k}\)</span> times on two heaps of size <span class="math inline">\(2^{k-1}\)</span>. From this we see that the total cost is of order</p>
<p class="mathjaxWide"><span class="math display">\[
\sum_{k=1}^{\log n} \frac{n}{2^k} k
=
n \sum_{k=1}^{\log n} \frac{k}{2^k}
.
\]</span></p>
<p>Since</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{2i+1}{2^{2i+1}} + \frac{2i+2}{2^{2i+2}} \le \frac{1}{2^i}
,
\]</span></p>
<p>we can pair the terms in the sum to get a total cost of order</p>
<p class="mathjaxWide"><span class="math display">\[
n \sum_{k=0}^{\log n} \frac{1}{2^k}
\le
n \sum_{k=0}^{\infty} \frac{1}{2^k}
\le
2n
.
\]</span></p>
<p>□</p>
<h2 id="exercise-3.4">Exercise 3.4</h2>
<p>A binary tree is said to satisfy the weight-biased leftist property if the size (= number of nodes) of any node’s left child is at least as large as that of its right child.</p>
<ol type="1">
<li>Prove that the right spine of a weight-biased leftist heap contains at most <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor\)</span> elements.</li>
<li>Modify the implementation in figure 3.2 to obtain weight-biased leftist heaps.</li>
<li>Modify <code>merge</code> for weight-biased leftist heaps to operate in a single top-down pass.</li>
<li>What advantages would the top-down version of <code>merge</code> have in a lazy environment? In a concurrent environment?</li>
</ol>
<h2 id="solution-3.4">Solution 3.4</h2>
<p><strong>Item 1.</strong></p>
<p>The proof is almost identical to that for leftist trees in <a href="#exercise-3.1">Exercise 3.1</a>.</p>
<p>The statement is true for the empty tree.</p>
<p>Let <span class="math inline">\(T\)</span> be a weight-biased leftist heap of rank <span class="math inline">\(r\)</span> with <span class="math inline">\(n\)</span> nodes. Then each child is a weight-biased leftist tree with fewer nodes. The right child has rank <span class="math inline">\(r-1\)</span> and by the induction hypothesis must have at least <span class="math inline">\(2^{r-1}-1\)</span> nodes. By the weight-biased property of <span class="math inline">\(T\)</span>, the left child also has at least <span class="math inline">\(2^{r-1}-1\)</span> nodes. Therefore, <span class="math inline">\(T\)</span> has at least <span class="math inline">\(2^r-1\)</span> nodes. In other words, <span class="math inline">\(\log (n+1) \ge r\)</span>. Since <span class="math inline">\(r\)</span> is an integer, <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor \ge r\)</span>. □</p>
<p><strong>Item 2.</strong></p>
<p>The implementation of leftist heaps encompasses both the leftist and weight-biased variants.</p>
<p><strong>Item 3.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise04.hs">source</a>.</p>
<p><strong>Item 4.</strong></p>
<p>In a lazy environment, the top-down version has the advantage that some queries can be made to the merged heap without calculating the entire heap. For example, <code>weight (merge h1 h2)</code> would run in constant time regardless of the sizes of <code>h1</code> and <code>h2</code>.</p>
<h2 id="binomial-heaps">Binomial Heaps</h2>
<p>We define the binomial tree of rank 0 to be the singleton node.</p>
<figure>
<img src="/images/binomial-tree-0.pdf.png" alt="The binomial tree of rank 0" class="nottoobig" /><figcaption>The binomial tree of rank 0</figcaption>
</figure>
<p>The binomial tree of rank r is defined as the tree formed by adding the binomial tree of rank n-1 as a left child of itself.</p>
<figure>
<img src="/images/binomial-tree-1.pdf.png" alt="The binomial tree of rank 1" class="nottoobig" /><figcaption>The binomial tree of rank 1</figcaption>
</figure>
<figure>
<img src="/images/binomial-tree-2.pdf.png" alt="The binomial tree of rank 2" /><figcaption>The binomial tree of rank 2</figcaption>
</figure>
<figure>
<img src="/images/binomial-tree-3.pdf.png" alt="The binomial tree of rank 3" /><figcaption>The binomial tree of rank 3</figcaption>
</figure>
<p>Note that the binomial tree of rank r has exactly <span class="math inline">\(2^r\)</span> nodes. This follows from the fact that we double the number of nodes in the tree each time we increase the rank by 1.</p>
<p>There is an alternative definition of binomial trees. A binomial tree of rank <span class="math inline">\(r\)</span> is a node with <span class="math inline">\(r\)</span> children <span class="math inline">\(t_1, \dotsc, t_r\)</span>, where <span class="math inline">\(t_i\)</span> is a binomial tree of rank <span class="math inline">\(r-i\)</span>.</p>
<p>We represent a node in a binomial tree as a key with a list of children. The extra <code>Int</code> is to keep track of the rank.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">BinomialTree</span> a <span class="fu">=</span> <span class="dt">Node</span> <span class="dt">Int</span> a [<span class="dt">BinTree</span> a]
                    <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</code></pre></div>
<p>We shall maintain two invariants:</p>
<ol type="1">
<li>Each list of children is in decreasing order of rank; and</li>
<li>The elements are stored in heap order.</li>
</ol>
<p>A binomial heap is a forest of heap-ordered binomial trees, where no two trees in the forest have the same rank. Thus, the trees in a binomial heap of size n correspond to the 1s in the binomial representation of n. For example, a binomial heap of size 21 would have one tree of rank 4 (size <span class="math inline">\(2^4 = 16\)</span>), one of rank 2 (size <span class="math inline">\(2^2=4\)</span>), and one of rank 0 (size <span class="math inline">\(2^0=1\)</span>), corresponding to 21’s binomial representation 10101. The binary representation of n contains <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor\)</span> digits, giving a bound for the number of trees in a binomial heap.</p>
<h2 id="exercise-3.5">Exercise 3.5</h2>
<p>Define <code>findMin</code> directly rather than via a call to <code>removeMinTree</code>.</p>
<h2 id="solution-3.5">Solution 3.5</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise05.hs">source</a>.</p>
<h2 id="exercise-3.6">Exercise 3.6</h2>
<p>Given a binomial tree, the rank of the root determines the rank of the children. Reimplement binomial heaps without the redundant rank annotations.</p>
<h2 id="solution-3.6">Solution 3.6</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise06.hs">source</a>.</p>
<h2 id="exercise-3.7">Exercise 3.7</h2>
<p>Make a funtor <code>ExplicitMin</code> that creates a heap with a constant time <code>findMin</code> and logarithmic time <code>deleteMin</code>.</p>
<h2 id="solution-3.7">Solution 3.7</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise07.hs">source</a>.</p>
<h2 id="red-black-trees">Red-Black Trees</h2>
<p>A red-black tree is a type of balanced binary search tree. The balance is achieved by painting the nodes either red or black whilst maintaining the following two invariants:</p>
<dl>
<dt>Red invariant</dt>
<dd>No red node has a red child
</dd>
<dt>Black invariant</dt>
<dd>Every path from the root node to an empty node contains the same number of black nodes.
</dd>
</dl>
<p>By convention, the empty node is defined to be black.</p>
<figure>
<img src="/images/red-black-1-node.pdf.png" alt="The red-black tree of size 1" /><figcaption>The red-black tree of size 1</figcaption>
</figure>
<figure>
<img src="/images/red-black-2-nodes.pdf.png" alt="The red-black tree of size 2" /><figcaption>The red-black tree of size 2</figcaption>
</figure>
<figure>
<img src="/images/red-black-3-nodes.pdf.png" alt="The red-black tree of size 3" /><figcaption>The red-black tree of size 3</figcaption>
</figure>
<figure>
<img src="/images/red-black-nontrivial.pdf.png" alt="A non-trivial red-black tree" /><figcaption>A non-trivial red-black tree</figcaption>
</figure>
<p>Our data type is based on a BST with an extra colour field.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Colour</span> <span class="fu">=</span> <span class="dt">R</span>
            <span class="fu">|</span> <span class="dt">B</span>
            <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)

<span class="kw">data</span> <span class="dt">RBTree</span> a <span class="fu">=</span> <span class="dt">E</span>
              <span class="fu">|</span> <span class="dt">T</span> <span class="dt">Colour</span> (<span class="dt">RBTree</span> a) a (<span class="dt">RBTree</span> a)
              <span class="kw">deriving</span> (<span class="dt">Eq</span>)</code></pre></div>
<h2 id="exercise-3.8">Exercise 3.8</h2>
<p>Prove that the the maximum depth of a node in a red-black tree of size n is at most <span class="math inline">\(2\left\lfloor \log (n+1) \right\rfloor\)</span>.</p>
<h2 id="solution-3.8">Solution 3.8</h2>
<p>We prove this by induction on the number of nodes.</p>
<p>The statement is true for empty trees.</p>
<p>Let <span class="math inline">\(T\)</span> be a red-black tree of depth <span class="math inline">\(d\)</span> with <span class="math inline">\(n\)</span> nodes. Suppose the trees rooted at its children have depths <span class="math inline">\(d_0\)</span> and <span class="math inline">\(d_1\)</span>, with sizes <span class="math inline">\(n_0 \le n_1\)</span>, respectively. In particular, the children are red-black trees with fewer than <span class="math inline">\(n\)</span> nodes. A consequence of the red-black invariant of <span class="math inline">\(T\)</span> is that <span class="math inline">\(d \le 2(d_0 + 1)\)</span>, since <span class="math inline">\(d\)</span> is the length of the longest path and <span class="math inline">\(d_0\)</span> is at least the length of the shortest path. Applying the induction hypothesis to the children yields</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  d 
  &amp;\le 
  2(d_0 +1) 
  \\
  &amp;\le 
  2(\log (n_0 + 1) + 1)
  \\
  &amp;= 
  2\log (2n_0 + 2) 
  \\
  &amp;\le 
  2\log (n_0 + n_1 + 2) 
  \\
  &amp;= 
  2\log (n + 1).
\end{align}
\]</span></p>
<p>□</p>
<h2 id="exercise-3.9">Exercise 3.9</h2>
<p>Write a function <code>fromOrdList</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">fromOrdList ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> [a] <span class="ot">-&gt;</span> <span class="dt">RedBlackTree</span> a</code></pre></div>
<p>that converts a sorted list with no duplicates into a red-black tree in <span class="math inline">\(\mathcal O (n)\)</span> time.</p>
<h2 id="solution-3.9">Solution 3.9</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/5cd2c0ae4641edb65ba88f4c7bf0e0a49a23063a/src/Chap03/Exercise09.hs">source</a>.</p>
<p>We must prove both that this implementation has linear complexity and that the resulting tree is red-black invariant.</p>
<dl>
<dt>Proposition</dt>
<dd>The function <code>fromOrdList</code> has linear complexity.
</dd>
</dl>
<p>The helper <code>go</code> makes at most two recursive calls to a list half the size of the original. More precisely,</p>
<p class="mathjaxWide"><span class="math display">\[
T (2k+1) = 2T (k) + \mathcal O (1)
\]</span></p>
<p>and</p>
<p class="mathjaxWide"><span class="math display">\[
T (2k) = T(k) + T (k-1) + \mathcal O (1).
\]</span></p>
<p>These are solved by <span class="math inline">\(T (n) = \mathcal O (n)\)</span>.</p>
<p>□</p>
<p>For the invariants, note that the shape and colouring of the tree doesn’t depend on the particular elements of the list. With this in mind, we will prove a couple of lemmas.</p>
<dl>
<dt>Lemma</dt>
<dd>The black depth (as measured by the algorithm) of <code>fromOrdList xs</code> is exactly <span class="math inline">\(\left\lfloor \log (n+1) - 1\right\rfloor\)</span>, where <code>xs</code> is a list of length <span class="math inline">\(n\)</span>.
</dd>
</dl>
<p>Proof. We prove this by induction on the length of the list.</p>
<p>For length <span class="math inline">\(0\)</span>, the black depth of the resulting empty tree is <span class="math inline">\(-1 = \log (0 + 1) - 1\)</span>.</p>
<p>By the induction hypothesis, the black depth in the odd length case <span class="math inline">\(n=2k+1\)</span> is <span class="math inline">\(\left\lfloor \log (k+1) \right\rfloor\)</span>. This is equal to</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  &amp;
  \quad \left\lfloor \log (k+1) \right\rfloor +1 -1 
  \\
  &amp;= 
  \left\lfloor \log (k + 1) + \log 2 \right\rfloor - 1 
  \\
  &amp;=
  \left\lfloor \log (2k + 1 + 1) \right\rfloor - 1 
  \\
  &amp;= 
  \left\lfloor \log (n + 1)\right\rfloor - 1.
\end{align}
\]</span></p>
<p>In the even case <span class="math inline">\(n=2k\)</span>, the black depth is <span class="math inline">\(\left\lfloor \log k \right\rfloor\)</span>, again using the induction hypothesis. This simplifies to</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  &amp;
  \quad
  \left\lfloor \log k \right\rfloor +1 -1 
  \\
  &amp;= 
  \left\lfloor \log 2k \right\rfloor - 1 
  \\
  &amp;= 
  \left\lfloor \log (2k+1) \right\rfloor -1 
  \\
  &amp;= 
  \left\lfloor \log (n+1) \right\rfloor - 1.
\end{align}
\]</span></p>
<p>The second line follows from the fact that <span class="math inline">\(\left\lfloor \log a \right\rfloor &lt; \left\lfloor \log (a+1) \right\rfloor\)</span> if and only if <span class="math inline">\(a = 2^i - 1\)</span> for some <span class="math inline">\(i \in \mathbb N_{\ge 1}\)</span>.</p>
<p>□</p>
<dl>
<dt>Proposition</dt>
<dd>The tree <code>fromOrdList xs</code> is black invariant for any list <code>xs</code>.
</dd>
</dl>
<p>Proof. When the two recursive calls in <code>go (length) xs</code> produce trees of differing black depth, their black depths may differ by at most one. This follows from the previous lemma. By painting the tree with the larger black depth red, we maintain the invariant that both black depths are equal. Thus, the tree <code>fromOrdList xs</code> is black invariant.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd>The root of the tree <code>fromOrdList xs</code> has a red left child if and only if the length of <code>xs</code> is <span class="math inline">\(2^i - 2\)</span> for some <span class="math inline">\(i \in \mathbb N_{\ge 2}\)</span>. In any other case, both children are black.
</dd>
</dl>
<p>Proof. Let <span class="math inline">\(n\)</span> be the size of the list <code>xs</code>. The function <code>go (length xs) xs</code> makes two recursive calls to create children of sizes approximately <span class="math inline">\(n/2\)</span>. We paint the root of the left child red when their black depths differ, which can only occur if <span class="math inline">\(n = 2k\)</span> is even. Note that the left child always has the greater size and, by the previous lemma, the greater black depth. In this case the black depth of the left is <span class="math inline">\(\left\lfloor \log (k+1) \right\rfloor - 1\)</span>, and the black depth of the right is <span class="math inline">\(\left\lfloor \log k \right\rfloor - 1\)</span>. These differ precisely when <span class="math inline">\(k = 2^i - 1\)</span> for some <span class="math inline">\(i \in \mathbb N_{\ge 1}\)</span>; that is, when <span class="math inline">\(n = 2 (2^i - 1) = 2^{i+1} - 2\)</span>.</p>
<p>□</p>
<dl>
<dt>Proposition</dt>
<dd>The tree <code>fromOrdList xs</code> is red invariant for any list <code>xs</code>.
</dd>
</dl>
<p>Proof. From the previous lemma, <code>fromOrdList xs</code> has a red left child, then then length of <code>xs</code> is <span class="math inline">\(n = 2^{i+1} - 2\)</span>. But then the size of the left child is <span class="math inline">\(n/2 = 2^i - 1\)</span>, so the left child has no red children. Therefore, no red invariant violation is introduced.</p>
<p>□</p>
<h2 id="exercise-3.10">Exercise 3.10</h2>
<p>Reduce redundancy in the <code>balance</code> function as follows:</p>
<ol type="1">
<li>Split <code>balance</code> into two functions, <code>lbalance</code> and <code>rbalance</code>, that test for colour violations in the left and right child, respectively.</li>
<li>Rewrite <code>ins</code> so that it never tests the colour of nodes not on the search path.</li>
</ol>
<h2 id="solution-3.10">Solution 3.10</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise10.hs">source</a> for both parts.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS, Chapter 2</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc02.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc02.html</id>
    <published>2015-10-26T00:00:00Z</published>
    <updated>2015-10-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS, Chapter 2</h1>
<p class="blog-post-meta">
Posted on October 26, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/binary%20tree.html">binary tree</a>, <a href="/tags/binary%20search%20tree.html">binary search tree</a>, <a href="/tags/set.html">set</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 2 of Okasaki’s ‘Purely Functional Data Structures’. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="exercise-2.1">Exercise 2.1</h2>
<p>Write a function <code>suffixes</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">suffixes ::</span> [a] <span class="ot">-&gt;</span> [[a]]</code></pre></div>
<p>that takes a list <code>xs</code> and returns a list of all the suffixes of <code>xs</code> in decreasing order of length. For example,</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">suffixes [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>] <span class="fu">==</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">4</span>], []]</code></pre></div>
<p>Show that the resulting list of suffixes can be generated in <span class="math inline">\(\mathcal O (n)\)</span> time and represented in <span class="math inline">\(\mathcal O (n)\)</span> space.</p>
<h2 id="solution-2.1">Solution 2.1</h2>
<p>Since there are as many recursive calls to <code>suffixes</code> as there are elements of <code>xs</code>, and both <code>:</code> and <code>tail</code> run in constant time, <code>suffixes</code> must be linear in the length of the list <code>xs</code>. That is, the solution to the recursion <span class="math inline">\(T (n) = T(n-1) + \mathcal O (1)\)</span> is <span class="math inline">\(T (n) = \mathcal O (n)\)</span>.</p>
<p>Moreover, we use the <span class="math inline">\(n\)</span> lists that already exist and also <span class="math inline">\(\mathcal O (n)\)</span> new pointers to each of those lists. Therefore, <code>suffixes xs</code> is represented in <span class="math inline">\(\mathcal O (n)\)</span> space.</p>
<h2 id="binary-search-trees-bsts">Binary Search Trees (BSTs)</h2>
<p>We start with binary trees (not search trees yet!). A binary tree is either empty or has two children, which we call ‘left’ and ‘right’.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Tree</span> a <span class="fu">=</span> <span class="dt">E</span>
            <span class="fu">|</span> <span class="dt">T</span> (<span class="dt">Tree</span> a) a (<span class="dt">Tree</span> a)
            <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</code></pre></div>
<p>In the binary trees below, empty nodes are depicted as squares.</p>
<figure>
<img src="/images/binary-tree-nontrivial.pdf.png" alt="A binary tree (which is NOT a BST)." /><figcaption>A binary tree (which is NOT a BST).</figcaption>
</figure>
<p>A BST is a binary tree with some extra structure. In particular, we require that the key of a node be greater than that of any of its left descendants and smaller than that of any of its right descendants.</p>
<figure>
<img src="/images/bst-nontrivial.pdf.png" alt="A binary tree which IS a BST." /><figcaption>A binary tree which IS a BST.</figcaption>
</figure>
<p>In the following exercises, we implement BSTs in the context of sets.</p>
<h2 id="exercise-2.2">Exercise 2.2</h2>
<p>Rewrite <code>member</code> to take no more than <span class="math inline">\(d+1\)</span> comparisons.</p>
<h2 id="solution-2.2">Solution 2.2</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise02.hs">source</a>.</p>
<h2 id="exercise-2.3">Exercise 2.3</h2>
<p>Rewrite <code>insert</code> using exceptions to avoid copying the entire search path (in the case of inserting an existing element).</p>
<h2 id="solution-2.3">Solution 2.3</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise03.hs">source</a>.</p>
<p>We use the <code>Maybe</code> data structure for our errors, i.e. <code>Nothing</code> indicates an error.</p>
<h2 id="exercise-2.4">Exercise 2.4</h2>
<p>Combine the ideas of <a href="#exercise-2.2">Exercise 2.2</a> and <a href="#exercise-2.3">Exercise 2.3</a> to create an insert function that performs no unnecessary copying and uses no more than <span class="math inline">\(d+1\)</span> comparisons.</p>
<h2 id="solution-2.4">Solution 2.4</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise04.hs">source</a>.</p>
<h2 id="exercise-2.5">Exercise 2.5</h2>
<ol type="1">
<li><p>Write a function <code>complete</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">complete ::</span> a <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">UnbalancedSet</span> a</code></pre></div>
<p>such that <code>complete a d</code> is a complete binary tree of depth d with the key <code>a</code> at every node. This function should run in <span class="math inline">\(\mathcal O (d)\)</span> time.</p></li>
<li><p>Extend <code>complete</code> to create balanced trees of arbitrary size that runs in <span class="math inline">\(\mathcal O (n)\)</span> time, where <span class="math inline">\(n\)</span> is the number of nodes. A tree is said to be balanced if the size of any node’s left child differs by at most one from the size of that node’s right child.</p></li>
</ol>
<h2 id="solution-2.5">Solution 2.5</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise05.hs">source</a>.</p>
<p><strong>Item 1.</strong></p>
<p>The recursion is given by <span class="math inline">\(T(d) = T(d-1) + \mathcal O (1)\)</span>, which is solved by <span class="math inline">\(T (d) = \mathcal O (d)\)</span>.</p>
<p><strong>Item 2.</strong></p>
<p>The complexity of <code>balance</code> is equal to that of <code>create2</code>. The recursion for <code>create2</code> is given by <span class="math inline">\(T (n) = T (n/2) + \mathcal O (1)\)</span>, which is solved by <span class="math inline">\(T (n) = \mathcal O (\log n)\)</span>.</p>
<h2 id="exercise-2.6">Exercise 2.6</h2>
<p>Adapt the <code>UnbalancedSet</code> functor to support finite maps rather than sets. The signature for finite maps is as follows.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">class</span> <span class="dt">FiniteMap</span> m k a <span class="kw">where</span>
<span class="ot">  empty  ::</span> m k a 
<span class="ot">  bind   ::</span> k <span class="ot">-&gt;</span>     a <span class="ot">-&gt;</span> m k a <span class="ot">-&gt;</span> m k a
<span class="ot">  lookup ::</span> k <span class="ot">-&gt;</span> m k a <span class="ot">-&gt;</span> <span class="dt">Maybe</span> a</code></pre></div>
<h2 id="solution-2.6">Solution 2.6</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise06.hs">source</a>.</p>
<p>We reuse the set implementation for <code>UnbalancedSet</code> by creating the <code>Binding</code> data type with the appropriate ordering. Note that this doesn’t allow updating key-value pairs.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>

</feed>
