<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Thoughts from the Café</title>
    <link href="http://stappit.github.io/atom.xml" rel="self" />
    <link href="http://stappit.github.io" />
    <id>http://stappit.github.io/atom.xml</id>
    <author>
        <name>Brian</name>
        <email>ha@hahaha.com</email>
    </author>
    <updated>2015-11-25T00:00:00Z</updated>
    <entry>
    <title>Okasaki's PFDS: Chapter 5</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc05.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc05.html</id>
    <published>2015-11-25T00:00:00Z</published>
    <updated>2015-11-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS: Chapter 5</h1>
<p class="blog-post-meta">
Posted on November 25, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/literate.html">literate</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/deque.html">deque</a>, <a href="/tags/binomial%20heap.html">binomial heap</a>, <a href="/tags/splay%20heap.html">splay heap</a>, <a href="/tags/pairing%20heap.html">pairing heap</a>, <a href="/tags/heap.html">heap</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 5 of Okasaki’s ‘Purely Functional Data Structures’. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="exercise-5.1">Exercise 5.1</h2>
<ol type="1">
<li>Implement deques.</li>
<li>Prove that each deque operation takes <span class="math inline">\(\mathcal O (1)\)</span> amortised time using the potential <span class="math display">\[\Phi (f, r) = \left| \left|f\right| - \left|r\right| \right|.\]</span></li>
</ol>
<h2 id="solution-5.1">Solution 5.1</h2>
<p><strong>Item 1.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap05/Data/BatchedQueue.hs">source</a>.</p>
<p><strong>Item 2.</strong></p>
<p>By symmetry, the costs of <code>cons</code>, <code>head</code>, and <code>tail</code> are (almost) identical to those of <code>snoc</code>, <code>last</code>, and <code>init</code>, respectively.</p>
<p>Consider <code>cons</code>. There is a constant number of actual steps and the potential can change by at most 1. Thus <code>cons</code> runs in constant amortised time.</p>
<p>Consider <code>tail</code>. Any <code>tail</code> which doesn’t empty <code>f</code> requires only one step and changes the potential by one for an amortised cost of <span class="math inline">\(\le 2\)</span>. Any <code>tail</code> which does empty <code>f</code> requires <span class="math inline">\(1 + 2m + \delta\)</span> steps, where <span class="math inline">\(m := \left\lfloor \frac{r}{2} \right\rfloor\)</span>, <span class="math inline">\(\left| r \right| = 2m + \delta\)</span>. The linearity is due to the fact that it takes <span class="math inline">\(m\)</span> steps to split <code>r</code> in half, then <span class="math inline">\(m\)</span> more steps to reverse the other half. The change in potential is given by</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \left|1 - (2m + \delta)\right| - \left|m - (2m + \delta - m)\right| 
  &amp;= 
  2m + 1 + \delta - \delta 
  \\
  &amp;= 
  2m + 1
.
\end{align}
\]</span></p>
<p>Thus, the amortised cost is <span class="math inline">\(1 + 2m + \delta - 2m = 1\)</span>, showing that <code>tail</code> runs in constant amortised time.</p>
<h2 id="exercise-5.2">Exercise 5.2</h2>
<p>Prove that <code>insert</code> on binomial heaps runs in <span class="math inline">\(\mathcal O (1)\)</span> amortised time using the banker’s method.</p>
<h2 id="solution-5.2">Solution 5.2</h2>
<p>The credit invariant associates one credit to every binomial tree in the heap. Let <span class="math inline">\(k\)</span> be the number of calls to <code>link</code> made by a call to <code>insert</code>. A call to <code>insert</code> takes <span class="math inline">\(1 + k\)</span> actual steps. It initially adds a tree to the heap, gaining a credit, and each <code>link</code> removes a tree, spending a credit. Thus, the total amortised cost is <span class="math inline">\((1+k) + 1 - k = 2\)</span>.</p>
<h2 id="exercise-5.3">Exercise 5.3</h2>
<p>Prove that the amortised costs of <code>merge</code> and <code>deleteMin</code> are still <span class="math inline">\(\mathcal O (\log n)\)</span>.</p>
<h2 id="solution-5.3">Solution 5.3</h2>
<p>Let <span class="math inline">\(h_m\)</span>, <span class="math inline">\(h_n\)</span> be binomial heaps with potentials <span class="math inline">\(m\)</span>, <span class="math inline">\(n\)</span>, respectively. We show that the amortised cost of <code>merge</code> is <span class="math inline">\(A(h_m, h_n) \le m+n\)</span>. Let <span class="math inline">\(k\)</span> be the number of calls to <code>link</code>. The actual cost is bounded by <span class="math inline">\(m + n + k\)</span>, since there can be at most <span class="math inline">\(m+n\)</span> recursive calls to <code>merge</code> and any call reaching the third conditional clause of <code>merge</code> will call <code>link</code> several times via <code>insTree</code>. We start with a potential of <span class="math inline">\(m+n\)</span>, and each call to <code>link</code> reduces this by one, for an end potential of <span class="math inline">\(m+n-k\)</span>. The change in potential is <span class="math inline">\(m + n - (m + n - k) = k\)</span>. Thus, the amortised cost of <code>merge</code> is <span class="math inline">\(m+n+k -k = m+n\)</span>.</p>
<p>Now we show that <code>deleteMin</code> is also logarithmic. We start with a heap <span class="math inline">\(h_n\)</span>, which has potential <span class="math inline">\(n\)</span>. There is an actual cost of at most <span class="math inline">\(n\)</span> to find the minimum binary tree, say of rank <span class="math inline">\(r\)</span>. This leaves us with a heap of rank <span class="math inline">\(n-1\)</span>. Then there is an actual cost of at most <span class="math inline">\(r\)</span> to reverse the list of children, making a heap of potential <span class="math inline">\(r\)</span>. Merging these heaps then takes at most <span class="math inline">\(n + r - 1 + k\)</span> steps, where <span class="math inline">\(k\)</span> is the number of calls to <code>link</code>, which leaves us with a heap with potential <span class="math inline">\(n + r - 1 - k\)</span>. This is a total of at most <span class="math inline">\(n + r + (n + r - 1 + k)\)</span> steps. The change in potential is <span class="math inline">\(n - (n + r - 1 - k) = 1 - r + k\)</span>. Thus, the amortised cost of <code>deleteMin</code> is</p>
<p class="mathjaxWide"><span class="math display">\[
2n + 2r + k - 1 - (1 - r + k) = 2n + 3r - 2
.
\]</span></p>
<p>Note that this is indeed logarithmic since, if a heap has a tree of rank <span class="math inline">\(r\)</span>, then it must have at least <span class="math inline">\(2^r\)</span> elements; that is, <span class="math inline">\(r = \mathcal O (n)\)</span>.</p>
<h2 id="splay-heaps">Splay Heaps</h2>
<p>A splay heap is a BST that rebalances the tree using a <code>partition</code> function when performing update operations. However, we now allow the insertion of the same element multiple times since we are implementing a heap and not a set.</p>
<figure>
<img src="/images/pfds-splayheap-unbalanced.pdf.png" alt="h = foldr insert empty [1..7]" /><figcaption><code>h = foldr insert empty [1..7]</code></figcaption>
</figure>
<figure>
<img src="/images/pfds-splayheap-unbalanced-insert.pdf.png" alt="insert 8 h" /><figcaption><code>insert 8 h</code></figcaption>
</figure>
<h2 id="exercise-5.4">Exercise 5.4</h2>
<p>Implement <code>smaller</code>.</p>
<h2 id="solution-5.4">Solution 5.4</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap05/Exercise04.hs">source</a>.</p>
<h2 id="exercise-5.5">Exercise 5.5</h2>
<p>Prove that <code>partition</code> is logarithmic (in the zig-zag case).</p>
<h2 id="solution-5.5">Solution 5.5</h2>
<p>First we will need a modification to the lemma proved in the book.</p>
<dl>
<dt>Lemma</dt>
<dd><p>We have the inequality</p>
<p class="mathjaxWide"><span class="math display">\[
1 + \log x + \log y \le 2\log (x + y -1)
.
\]</span></p>
<p>for all <span class="math inline">\(x \in \mathbb N_{\ge 2}\)</span>, <span class="math inline">\(y \in \mathbb N_{\ge 1}\)</span>.</p>
</dd>
</dl>
<p>Using the basic logarithmic identities, the above inequality is equivalent to <span class="math inline">\(2xy \le (x+y-1)^2\)</span>. In other words, we must show that <span class="math inline">\(x^2 -2x + (y-1)^2 \ge 0\)</span> for <span class="math inline">\(x \ge 2\)</span>, <span class="math inline">\(y \ge 1\)</span>. The term with <span class="math inline">\(y\)</span> is non-negative. The remaining term <span class="math inline">\(x^2 -2x\)</span> is non-negative for any <span class="math inline">\(x \ge 2\)</span>.</p>
<p>□</p>
<figure>
<img src="/images/pfds-ex5.5-input.pdf.png" alt="We wish to analyse partition pivot t." /><figcaption>We wish to analyse <code>partition pivot t</code>.</figcaption>
</figure>
<figure>
<img src="/images/pfds-ex5.5-output.pdf.png" alt="Suppose partition pivot t outputs (t_s, t_b)." /><figcaption>Suppose <code>partition pivot t</code> outputs <span class="math inline">\((t_s, t_b)\)</span>.</figcaption>
</figure>
<p>Define <span class="math inline">\((p_s, p_b)\)</span> as the output of <code>partition pivot p</code>. Note that <span class="math inline">\(\#t_s + \#t_b = \#t - 1\)</span>, so that <span class="math inline">\(1 + \phi(t_s) + \phi(t_b) \le 2\phi(t)\)</span> by the lemma.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  A (t) 
  &amp;= 
  T (t) + \Phi (t_s) + \Phi (t_b) - \Phi (t)
  \\
  &amp;=
  1 + T (p) + \Phi (t_s) + \Phi (t_b) - \Phi (t)
  \\
  &amp;=
  1 + A (p) - \Phi (p_s) - \Phi (p_b) + \Phi (p) 
  \\
  &amp;\qquad
            + \Phi (t_s) + \Phi (t_b) - \Phi (t)
  \\
  &amp;=
  1 + A (p) - \Phi (p_s) - \Phi (p_b) + \Phi (p)
  \\
  &amp;\qquad
            + \phi (t_s) + \Phi (a_1) + \Phi (p_s)
  \\
  &amp;\qquad
	    + \phi (t_b) + \Phi (p_b) + \Phi (b)
  \\
  &amp;\qquad
	    - \phi (t)   - \phi (s)   - \Phi (b)  - \Phi (a_1) - \Phi (p)
  \\
  &amp;=
  1 + A (p) + \phi (t_s) + \phi (t_b) - \phi (t) - \phi (s)
  \\
  &amp;\le
  2 + 2\phi (p) + \phi(t_s) + \phi(t_b) - \phi(t) - \phi(s)
  \\
  &amp;\le
  2 + \phi(t) + \phi(s) + \phi(t_s) - \phi(t_b) - \phi(t) - \phi(s)
  \\
  &amp;\le
  2 + \phi(t_s) + \phi(t_b)
  \\
  &amp;\le
  1 + 2\phi(t)
\end{align}
\]</span></p>
<h2 id="exercise-5.6">Exercise 5.6</h2>
<p>Prove that <code>deleteMin</code> also runs in logarithmic time.</p>
<h2 id="solution-5.6">Solution 5.6</h2>
<p>We prove that <code>deleteMin</code> runs in <span class="math inline">\(\mathcal O(3\log n)\)</span> amortised time. Note that <span class="math inline">\(\#a + (\#b + \#c) \le \#s_1\)</span> so that <span class="math inline">\(1 + \phi(a) + \phi(t_2) \le 2\phi(s_1)\)</span>.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  A(s_1)
  &amp;=
  T(s_1) + \Phi(t_1) - \Phi(s_1)
  \\
  &amp;=
  1 + T(a) + \Phi(t_1) - \Phi(s_1)
  \\
  &amp;=
  1 + A(a) - \Phi(a&#39;) + \Phi(a)
  \\
  &amp;\qquad
  	+ \phi(t_1) + \phi(t_2) + \Phi(a&#39;) + \Phi(b) + \Phi(c)
  \\
  &amp;\qquad
  	- \phi(s_1) - \phi(s_2) - \Phi(a) -  \Phi(b) - \Phi(c)
  \\
  &amp;=
  1 + A(a) + \phi(t_1) + \phi(t_2) - \phi(s_1) -\phi(s_2)
  \\
  &amp;\le
  1 + \phi(a) + \phi(t_1) + \phi(t_2)
  \\
  &amp;\le
  \phi(t_1) + 2\phi(s_1)
  \\
  &amp;\le
  3\phi(s_1)
\end{align}
\]</span></p>
<h2 id="exercise-5.7">Exercise 5.7</h2>
<p>Write a sorting function that inserts elements into a splay tree and then performs an in order traversal of the tree dumping the elements into a list. Show that this function takes linear time in a sorted list.</p>
<h2 id="solution-5.7">Solution 5.7</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/5cd2c0ae4641edb65ba88f4c7bf0e0a49a23063a/src/Chap05/Exercise07.hs">source</a>.</p>
<p>Let <code>xs</code> be a list of length <span class="math inline">\(n\)</span> in decreasing order. We can measure the complexity of <code>sort xs</code> by counting the number of calls to <code>partition</code>. Every time we call <code>insert x h</code>, we know that <span class="math inline">\(x &gt; y\)</span> for all <span class="math inline">\(y\)</span> in <code>h</code>, so <code>insert x h</code> calls <code>partition</code> exactly once. The function <code>sort xs</code> makes a total of <span class="math inline">\(n\)</span> calls to <code>insert</code> and thus also <span class="math inline">\(n\)</span> calls to <code>partition</code>, showing that <code>sort</code> runs in <span class="math inline">\(\mathcal O (n)\)</span> time.</p>
<p>The argument for lists in increasing order is completely analogous.</p>
<h2 id="pairing-heaps">Pairing Heaps</h2>
<p>A pairing heap is a heap-ordered multiway tree whose <code>deleteMin</code> operation merges the children in pairs.</p>
<figure>
<img src="/images/pfds-pairingheap-wide.pdf.png" alt="h = foldr insert empty [7, 6..1]" /><figcaption><code>h = foldr insert empty [7, 6..1]</code></figcaption>
</figure>
<figure>
<img src="/images/pfds-pairingheap-wide-deletemin.pdf.png" alt="deleteMin h" /><figcaption><code>deleteMin h</code></figcaption>
</figure>
<h2 id="exercise-5.8">Exercise 5.8</h2>
<ol type="1">
<li><p>Write a function <code>toBinary</code> that converts pairing heaps to binary trees.</p></li>
<li><p>Reimplement pairing heaps using this new representation as binary trees.</p></li>
<li><p>Prove that <code>deleteMin</code> and <code>merge</code> still run in logarithmic amortised time in this new representation.</p></li>
</ol>
<h2 id="solution-5.8">Solution 5.8</h2>
<p><strong>Item 1.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/897522b05776b202e622b55b03cd0438dd581798/src/Chap05/Exercise08.hs">source</a>.</p>
<p>The conversion from a pairing heap to a binary tree is explained in the book.</p>
<figure>
<img src="/images/pfds_ex5-8b_invariant.pdf.png" alt="For any binary tree derived from a pairing heap, x \le y, y_a, y_b for all elements y_a, y_b in the trees a, b, respectively. The right child of the root is empty. The values in b are not related to y." /><figcaption>For any binary tree derived from a pairing heap, <span class="math inline">\(x \le y, y_a, y_b\)</span> for all elements <span class="math inline">\(y_a, y_b\)</span> in the trees <span class="math inline">\(a, b\)</span>, respectively. The right child of the root is empty. The values in <span class="math inline">\(b\)</span> are not related to <span class="math inline">\(y\)</span>.</figcaption>
</figure>
<p>The invariant on a pairing heap <code>T x cs</code> is that <code>x</code> is no greater than any of the elements of its children in <code>cs</code>. This translates into the binary tree invariant that a node is no greater than any of its left descendants. That is, for <code>T' x (T' y a b) c</code> we have that <span class="math inline">\(x \le y, y_a, y_b\)</span> for all elements <span class="math inline">\(y_a, y_b\)</span> in the trees <span class="math inline">\(a, b\)</span>, respectively. The value of <span class="math inline">\(x\)</span> bears no relation to the values in <span class="math inline">\(c\)</span>.</p>
<p>We also maintain a second invariant: the right child of the root is empty.</p>
<p><strong>Item 2.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/897522b05776b202e622b55b03cd0438dd581798/src/Chap05/Data/PairingHeap/Exercise08.hs">source</a>.</p>
<p>Remember that the root of a binary tree representation of a pairing heap has no right child (it is empty). Thus we can forget about the right child without losing desired information.</p>
<p><strong>Item 3.</strong></p>
<p>We start with <code>merge</code>. Note that for any <span class="math inline">\(x, y \ge 2\)</span>, we have <span class="math inline">\(\log (x+y) \le \log x + \log y\)</span>. In particular, <span class="math inline">\(\#s_k \ge 2\)</span>.</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  A (s_1, s_2) 
  &amp;= 
  T (s_1, s_2) + \Phi (t_1) - \Phi (s_1) - \Phi (s_2)
  \\
  &amp;=
  1 + \Phi(t_1) - \Phi(s_1) - \Phi(s_2)
  \\
  &amp;=
  1 + \phi(t_1) + \phi(t_2) - \phi(s_1) - \phi(s_2)
  \\
  &amp;\le
  2 + 2\phi(t_1)
  \\
  &amp;\le
  2 + 2\log (\#s_1 + \#s_2)
  \\
  &amp;\le
  2 + 2\log(\#s_1) + 2\log(\#s_2)
  \\
  &amp;\le
  2 + 2\phi(s_1) + 2\phi(s_2)
\end{align}
\]</span></p>
<p>Now consider <code>deleteMin</code>. I was unable to find a nice solution by myself. The following comes from <a href="https://www.cs.cmu.edu/~sleator/papers/pairing-heaps.pdf">The Pairing Heap: A New Form of Self-Adjusting Heap</a>. We reproduce their argument that the asymptotic cost of <code>deleteMin</code> is <span class="math inline">\(A(s_1) \le 2\phi(s_1) + 3\)</span>.</p>
<p>There are at most <span class="math inline">\(2k+1\)</span> calls to <code>merge</code>, where <span class="math inline">\(k\)</span> is the number of children of the root of the pairing heap. The difficult part is calculating the potential increase, which we do in steps.</p>
<dl>
<dt>Lemma 1</dt>
<dd>Let <span class="math inline">\(x, y &gt; 0\)</span> such that <span class="math inline">\(x + y \le 1\)</span>. Then <span class="math inline">\(\log x + \log y \le -2\)</span>.
</dd>
</dl>
<p>Proof. This follows from the fact that <span class="math inline">\(xy \le x(1-x)\)</span>, which has a maximum of <span class="math inline">\(\frac{1}{4}\)</span> at <span class="math inline">\(x = \frac{1}{2}\)</span>.</p>
<p>□</p>
<dl>
<dt>Corollary</dt>
<dd><p>We have</p>
<p class="mathjaxWide"><span class="math display">\[
\log(x + y) - \log(y + z) \le 2 \log (x + y + z) - 2\log z - 2
,
\]</span></p>
<p>for any <span class="math inline">\(x, y, z \ge 0\)</span>.</p>
</dd>
</dl>
<p>Proof. By the lemma we have</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \log(x + y) + \log z - 2\log (x + y + z) 
  &amp;= 
  \log \left(\frac{x + y}{x + y + z}\right) + \log \left(\frac{z}{x + y + z}\right) 
  \\
  &amp;\le 
  -2.
\end{align}
\]</span></p>
<p>Now</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
 \log(x + y) - \log(y + z) 
 &amp;= 
 \log(x + y) + \log z - \log z - \log(y+z)
 \\
 &amp;\le
 2\log (x + y + z) - 2 - \log z -\log(y+z)
 \\
 &amp;\le
 2\log (x + y + z) - 2 - 2\log z.
\end{align}
\]</span></p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd>Define <span class="math inline">\(s_2\)</span> to be the tree <code>T y b c</code> and <span class="math inline">\(s_1\)</span> to be the tree <code>T x a s2</code>.<br />
 Then applying <code>merge</code> to <span class="math inline">\(s_1\)</span> results in a potential increase of at most <span class="math inline">\(2\phi(s_1) - 2\phi(c) - 2\)</span>.
</dd>
</dl>
<p>Proof. Without loss of generality, assume <span class="math inline">\(y \le x\)</span>. Define <span class="math inline">\(t_2\)</span> to be the tree <code>T x a b</code> and <span class="math inline">\(t_1\)</span> to be <code>T y t2 c</code>; that is, <span class="math inline">\(t_1\)</span> is the result of applying <code>merge</code> to <span class="math inline">\(s_1\)</span>. The potential increase is <span class="math inline">\(\Phi(t_1) - \Phi(s_1)\)</span>, by definition. This expands to <span class="math inline">\(\phi(t_1) + \phi(t_2) - \phi(s_1) - \phi(s_2)\)</span>, which is equal to <span class="math inline">\(\phi(t_2) - \phi(s_2)\)</span> since <span class="math inline">\(\phi(t_1) = \phi(s_1)\)</span>. Now</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  \phi(t_2) - \phi(s_2) 
  &amp;= 
  \log(\#a + \#b) - \phi(\#b + \#c) 
  \\
  &amp;\le 
  2\log(\#a + \#b + \#c) - 2\log (\#c) - 2 
  \\
  &amp;= 
  2\phi(s_1) - 2\phi(c) - 2.
\end{align}
\]</span></p>
<p>□</p>
<dl>
<dt>Corollary</dt>
<dd>Define <span class="math inline">\(s_i\)</span> as the right child of <span class="math inline">\(s_{i-1}\)</span>, where <span class="math inline">\(s_1\)</span> is the root of the binary tree, <span class="math inline">\(i = 1, ..., 2k - 1\)</span>, and <span class="math inline">\(2k + \delta\)</span> is the length of the right spine of <span class="math inline">\(s_1\)</span>. Then the net increase in potential over all calls to <code>merge</code> in the downwards pass of <code>mergePairs</code> is bounded by <span class="math inline">\(2\phi(s_1) - 2(k-1)\)</span>.
</dd>
</dl>
<p>Proof. Applying the previous lemma yields</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  2\phi(s_{2k-1}) + \sum_{i=1}^{k-1} \left( 2\phi(s_{2i - 1}) - 2\phi(s_{2i + 1}) - 2 \right)
  &amp;\le
  2\phi(s_{2k-1}) - 2(k-1) + \sum_{i=1}^{k-1} \left( 2\phi(s_{2i - 1}) - 2\phi(s_{2i + 1}) \right)
  \\
  &amp;\le
  2\phi(s_1) - 2(k-1),
\end{align}
\]</span></p>
<p>where the last line follows by telescoping the sum.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd>The net increase in potential over all calls to merge in the upwards pass of <code>mergePairs</code> is bounded by <span class="math inline">\(\phi(s_1)\)</span>.
</dd>
</dl>
<p>Proof. Let <span class="math inline">\(t\)</span> be the resulting tree after calling <code>merge</code> on two trees <span class="math inline">\(t_1, t_2\)</span>. Furthermore, let <span class="math inline">\(t_1&#39;, t_2&#39;\)</span> be the subtrees whose roots contain the keys of the trees <span class="math inline">\(t_1, t_2\)</span>, respectively. Then <span class="math inline">\(\phi(t_1) \le \phi(t_1&#39;)\)</span> and <span class="math inline">\(\phi(t_2) \ge \phi(t_2&#39;)\)</span>. Thus, the potential increase is bounded by <span class="math inline">\(\phi(t)\)</span>. Since <span class="math inline">\(\#t = \#s_1\)</span>, the potential increase is bounded by <span class="math inline">\(\phi(s_1)\)</span>.</p>
<p>□</p>
<p>There are at most <span class="math inline">\(2k + 1\)</span> actual steps. Removing the root causes a potential increase of <span class="math inline">\(-\phi(s_1)\)</span>. The potential increase in the downwards pass in <code>mergePairs</code> is bounded by <span class="math inline">\(2\phi(s_1) - 2(k-1)\)</span>. The potential increase in the upwards pass in <code>mergePairs</code> is bounded by <span class="math inline">\(\phi(s_1)\)</span>. Therefore, the amortised time is bounded by</p>
<p class="mathjaxWide"><span class="math display">\[
2k + 1 - \phi(s_1) + 2\phi(s_1) - 2(k-1) + \phi(s_1) = 3 + 2\phi(s_1)
.
\]</span></p>
<h2 id="exercise-5.9">Exercise 5.9</h2>
<p>Give examples of sequences of operations for which binomial heaps, splay heaps, and pairing heaps take much longer than indicated by their amortised bounds.</p>
<h2 id="solution-5.9">Solution 5.9</h2>
<p>For any operation with amortised bounds, we can set up the data structure so that the next execution of that operation is expensive, then call that operation many times.</p>
<p><strong>Binomial Heaps</strong></p>
<p>Binomial heaps support an <code>insert</code> operation with a constant amortised cost. The worst case cost of <code>insert</code> is <span class="math inline">\(\mathcal O (\log n)\)</span>, which occurs when inserting into a binomial heap of size <span class="math inline">\(2^m - 1\)</span>. In a persistent setting, we can call <code>insert</code> k times on this heap, executing in <span class="math inline">\(\mathcal O(k\log n)\)</span> time instead of <span class="math inline">\(\mathcal O(k)\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">heap <span class="fu">=</span> foldr insert empty [<span class="dv">1</span><span class="fu">..</span>(<span class="dv">2</span><span class="fu">^</span>m <span class="fu">-</span> <span class="dv">1</span>)]
  <span class="kw">where</span>
    m <span class="fu">=</span> <span class="dv">7</span>
    n <span class="fu">=</span> <span class="dv">2</span><span class="fu">^</span>m <span class="fu">-</span> <span class="dv">1</span>

tooSlow <span class="fu">=</span> map (insert <span class="dv">0</span>) <span class="fu">.</span> replicate k <span class="fu">$</span> heap
  <span class="kw">where</span>
    k <span class="fu">=</span> <span class="dv">100</span></code></pre></div>
<p><strong>Splay Heaps</strong></p>
<p>Splay heaps support a <code>findMin</code> operation with a logarithmic amortised cost. The worst case cost of <code>findMin</code> is linear, which occurs after inserting numbers in increasing order into the empty heap. In a persistent setting, we can call <code>findMin</code> k times on this heap, executing in <span class="math inline">\(\mathcal O(kn)\)</span> time instead of <span class="math inline">\(\mathcal O(k\log n)\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">heap <span class="fu">=</span> foldr insert empty [<span class="dv">1</span><span class="fu">..</span>n]
  <span class="kw">where</span>
    n <span class="fu">=</span> <span class="dv">100</span>

tooSlow <span class="fu">=</span> map findMin <span class="fu">.</span> replicate k <span class="fu">$</span> heap
  <span class="kw">where</span> 
    k <span class="fu">=</span> <span class="dv">100</span></code></pre></div>
<p><strong>Pairing Heaps</strong></p>
<p>Pairing heaps have a <code>deleteMin</code> operation with an amortised cost of <span class="math inline">\(\mathcal O (\log n)\)</span>. The worst case cost of <code>deleteMin</code> is <span class="math inline">\(\mathcal O (n)\)</span>, which occurs after inserting numbers in decreasing order into the empty heap. In a persistent setting, we can call <code>deleteMin</code> k times on this heap, executing in <span class="math inline">\(\mathcal O(kn)\)</span> time instead of <span class="math inline">\(\mathcal O(k\log n)\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">heap <span class="fu">=</span> foldr insert empty [n, (n<span class="fu">-</span><span class="dv">1</span>)<span class="fu">..</span><span class="dv">1</span>]
  <span class="kw">where</span>
    n <span class="fu">=</span> <span class="dv">100</span>

tooSlow <span class="fu">=</span> map deleteMin <span class="fu">.</span> replicate k <span class="fu">$</span> heap
  <span class="kw">where</span> 
    k <span class="fu">=</span> <span class="dv">100</span></code></pre></div>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS: Chapter 4</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc04.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc04.html</id>
    <published>2015-11-08T00:00:00Z</published>
    <updated>2015-11-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS: Chapter 4</h1>
<p class="blog-post-meta">
Posted on November  8, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/literate.html">literate</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/lazy.html">lazy</a>, <a href="/tags/strict.html">strict</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 4 of Okasaki’s “Purely Functional Data Structures”. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="notation">Notation</h2>
<p>Okasaki uses <code>$</code> to indicate suspensions. But beware! Haskell also has this symbol but it means something completely different, namely function application. In symbols:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">($) ::</span> (a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> b
(<span class="fu">$</span>) f a <span class="fu">=</span> f a</code></pre></div>
<p>We can use it like any other function in haskell. For example:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">two <span class="fu">=</span> (<span class="dv">1</span> <span class="fu">+</span>) <span class="fu">$</span> <span class="dv">1</span></code></pre></div>
<p>It has nothing to do with suspensions, evaluation, forcing, etc.</p>
<p>It is also important to note that a ‘list’ in haskell is not what Okasaki calls a ‘list’. He would call haskell’s lists ‘streams’. We will stick with haskell’s notation, calling Okasaki’s list a ‘strict list’.</p>
<h2 id="exercise-1">Exercise 1</h2>
<p>Show that both definitions of <code>drop</code> are equivalent.</p>
<h2 id="solution-1">Solution 1</h2>
<p>The code in this solution is NOT Haskell.</p>
<p>For convenience, we give names to the three different functions.</p>
<pre><code>fun drop (0, s)            = s
  | drop (n, $Nil)         = $Nil
  | drop (n, $Cons (x, s)) = drop (n-1, s)</code></pre>
<pre><code>fun lazy dropA (0, s)            = s
       | dropA (n, $Nil)         = $Nil
       | dropA (n, $Cons (x, s)) = dropA (n-1, s)</code></pre>
<pre><code>fun lazy dropB (n, s) = drop (n, s)</code></pre>
<p>The proof proceeds in three steps.</p>
<dl>
<dt>Lemma</dt>
<dd>Let <code>s</code> be a suspension. Then <code>$force s</code> is equivalent to <code>s</code>.
</dd>
</dl>
<p>Proof. Suppose <code>s</code> is <code>$e</code> for some expression <code>e</code>. Then <code>$force s</code> <span class="math inline">\(\cong\)</span> <code>$force $e</code> <span class="math inline">\(\cong\)</span> <code>$e</code> <span class="math inline">\(\cong\)</span> <code>s</code>.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd><code>dropA</code> is equivalent to <code>drop</code>
</dd>
</dl>
<p>Proof. We prove this by induction on <span class="math inline">\(n\)</span>.</p>
<p>For the base step, <code>dropA (0, s)</code> = <code>$force s</code> $<code>`s</code> = <code>drop (0, s)</code>, where the middle equivalence follows by the previous lemma.</p>
<p>Note that <code>dropA (n, $Nil)</code> = <code>$force $Nil</code> = <code>$Nil</code> = <code>drop (n, $Nil)</code> follows by the previous lemma. Now suppose <code>dropA (n, s)</code> <span class="math inline">\(\cong\)</span> <code>drop (n, s)</code> for some <span class="math inline">\(n \in \mathbb N\)</span> and any stream <code>s</code>. We can write <code>s</code> as <code>$Cons (x, s')</code>. Then <code>dropA (n+1, s)</code> = <code>dropA (n+1, $Cons (x, s'))</code> = <code>$force dropA (n, s')</code> <span class="math inline">\(\cong\)</span> <code>dropA (n, s')</code> <span class="math inline">\(\cong\)</span> <code>drop (n, s')</code> = <code>drop (n+1, s)</code>.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd><code>dropA</code> is equivalent to <code>dropB</code>
</dd>
</dl>
<p>Proof. Using the previous two lemmas, we obtain <code>dropB (n, s)</code> = <code>$force drop (n, s)</code> = <code>$force dropA (n, s)</code> = <code>dropA (n, s)</code> for any <span class="math inline">\(n \in \mathbb N\)</span> and any stream <code>s</code>.</p>
<p>□</p>
<h2 id="exercise-2">Exercise 2</h2>
<p>Implement insertion sort on streams and show that extracting the first <span class="math inline">\(k\)</span> elements takes only <span class="math inline">\(\mathcal O (nk)\)</span> time, where <span class="math inline">\(n\)</span> is the length of the input list.</p>
<h2 id="solution-2">Solution 2</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/70501d73d4cf242bfd0128308fa635e7ca95ceef/src/Chap04/Exercise02.hs">source</a>. Note that lists in Haskell are what Okasaki calls streams, so we need no special annotations or data structures.</p>
<p>Let <span class="math inline">\(T (n, k)\)</span> be the asymptotic complexity of computing <code>take k $ sort xs</code>, where <code>xs</code> is a list of length <span class="math inline">\(n\)</span>. By definition of <code>take</code>, <span class="math inline">\(T (n, 0) = \mathcal O (1)\)</span> and <span class="math inline">\(T (0, k) = T (0, 0)\)</span>.</p>
<p>In <code>take k $ sort xs</code> the function <code>take k</code> needs to put <code>sort xs</code> into weak head normal form. Let <span class="math inline">\(S (m)\)</span> be the complexity of puting <code>sort ys</code> into weak head normal form for a list <code>ys</code> of length <span class="math inline">\(m\)</span>. Clearly <span class="math inline">\(S (0) = \mathcal O (1)\)</span>. Since <code>sort (y:ys) = ins y $ sort ys</code>, we have <span class="math inline">\(S (m) = S (m-1) + \mathcal O (1)\)</span>, since <code>ins y</code> only needs to put <code>sort ys</code> into weak head normal form. This is solved by <span class="math inline">\(S (m) = \mathcal O (m)\)</span>.</p>
<p>Now, <code>take k $ sort xs = take k $ y : ys = y : take (k-1) ys</code>, where <code>sort xs = y : ys</code>. Thus <span class="math inline">\(T (n, k) = T (n-1, k-1) + \mathcal O (n)\)</span>. This recurrence is solved by <span class="math inline">\(T (n, k) = \mathcal O (nk)\)</span>.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS: Chapter 3</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc03.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc03.html</id>
    <published>2015-11-01T00:00:00Z</published>
    <updated>2015-11-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS: Chapter 3</h1>
<p class="blog-post-meta">
Posted on November  1, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/literate.html">literate</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/leftist%20tree.html">leftist tree</a>, <a href="/tags/leftist%20heap.html">leftist heap</a>, <a href="/tags/binomial%20tree.html">binomial tree</a>, <a href="/tags/binomial%20heap.html">binomial heap</a>, <a href="/tags/heap.html">heap</a>, <a href="/tags/red%20black%20tree.html">red black tree</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 3 of Okasaki’s ‘Purely Functional Data Structures’. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="leftist-trees">Leftist Trees</h2>
<p>The right spine of a binary tree is the rightmost path from that node to an empty node. For example, the empty tree has a right spine of length 0.</p>
<p>A binary tree is said to satisfy the leftist property if every node has the property that the rank of its left child (= length of its right spine) is greater than or equal to the rank of its right child. A leftist tree is a binary tree with the leftist property.</p>
<p>The following are some examples of (the shape of) leftist trees where the keys have been omitted. The number at each node instead indicates the length of its right spine and any blank nodes are empty nodes.</p>
<figure>
<img src="/images/leftist-tree-1-node.pdf.png" alt="The only leftist tree with 1 node." /><figcaption>The only leftist tree with 1 node.</figcaption>
</figure>
<figure>
<img src="/images/leftist-tree-2-nodes.pdf.png" alt="The only leftist tree with 2 nodes." /><figcaption>The only leftist tree with 2 nodes.</figcaption>
</figure>
<figure>
<img src="/images/leftist-tree-3-nodes-1.pdf.png" alt="A leftist tree with 3 nodes." /><figcaption>A leftist tree with 3 nodes.</figcaption>
</figure>
<figure>
<img src="/images/leftist-tree-3-nodes-2.pdf.png" alt="A leftist tree with 3 nodes." /><figcaption>A leftist tree with 3 nodes.</figcaption>
</figure>
<h2 id="heaps">Heaps</h2>
<p>A tree is said to be heap-ordered if the key of any node is less than or equal to the key of any of its descendants. We capture this structure in the <code>Heap</code> typeclass.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">class</span> <span class="dt">Heap</span> h <span class="kw">where</span>
<span class="ot">  empty     ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a
<span class="ot">  isEmpty   ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> <span class="dt">Bool</span>
<span class="ot">  insert    ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span>   a <span class="ot">-&gt;</span> h a <span class="ot">-&gt;</span> h a
<span class="ot">  merge     ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> h a <span class="ot">-&gt;</span> h a
<span class="ot">  findMin   ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> <span class="dt">Maybe</span> a     <span class="co">-- may be empty</span>
<span class="ot">  deleteMin ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> h a <span class="ot">-&gt;</span> <span class="dt">Maybe</span> (h a) <span class="co">-- may be empty</span></code></pre></div>
<p>A leftist heap is a heap-ordered leftist tree. We can implement this as a binary tree with a heap instance.</p>
<h2 id="exercise-3.1">Exercise 3.1</h2>
<p>Prove that the right spine of a leftist heap of size <span class="math inline">\(n\)</span> contains at most <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor\)</span> elements.</p>
<h2 id="solution-3.1">Solution 3.1</h2>
<p>We prove the stronger result that a leftist tree of rank <span class="math inline">\(r\)</span> is complete up to depth <span class="math inline">\(r-1\)</span>. The solution then follows from the fact that a tree complete up to depth <span class="math inline">\(r-1\)</span> has at least <span class="math inline">\(2^r - 1\)</span> nodes.</p>
<p>The proof proceeds by induction on the number of nodes.</p>
<p>The statement is true for the empty tree.</p>
<p>Let <span class="math inline">\(T\)</span> be a leftist tree of rank <span class="math inline">\(r\)</span> with <span class="math inline">\(n\)</span> nodes. Then each child is a leftist tree with fewer nodes, so we may apply the induction hypothesis to each child. The right child has rank <span class="math inline">\(r-1\)</span> and, by the leftist property of <span class="math inline">\(T\)</span>, the left child has rank at least <span class="math inline">\(r-1\)</span>. By the induction hypothesis, each child is complete up to depth <span class="math inline">\(r-2\)</span>. Therefore, <span class="math inline">\(T\)</span> is complete up to depth <span class="math inline">\(r-1\)</span>. □</p>
<h2 id="exercise-3.2">Exercise 3.2</h2>
<p>Define <code>insert</code> directly rather than via a call to <code>merge</code>.</p>
<h2 id="solution-3.2">Solution 3.2</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/2ecdad0e72de18d8b250e6cddad011b00debecda/src/Chap03/Exercise02.hs">source</a>.</p>
<h2 id="exercise-3.3">Exercise 3.3</h2>
<p>Implement a function <code>fromList</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">fromList ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> [a] <span class="ot">-&gt;</span> <span class="dt">LeftistHeap</span> a</code></pre></div>
<p>that produces a leftist heap from an unordered list of elements in <span class="math inline">\(\mathcal O (n)\)</span> time by merging in pairs.</p>
<h2 id="solution-3.3">Solution 3.3</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise03.hs">source</a>.</p>
<p>Note that we only use the Heap API, so we are guaranteed both the heap invariants and the leftist invariants. We must only check that the implementation is in fact linear.</p>
<p>Let’s look at the first few cases in detail.</p>
<ul>
<li><p>The first call to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(n/2\)</span> times on two heaps of size <span class="math inline">\(2^0\)</span>. This has a cost of <span class="math inline">\(\frac{n}{2} \log 2 = \frac{n}{2}\)</span>.</p></li>
<li><p>The second call to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(n/4\)</span> times on heaps of size <span class="math inline">\(2^1\)</span>. This has a cost of <span class="math inline">\(\frac{n}{4} \log 4 = \frac{n}{4} \cdot 2\)</span>.</p></li>
<li><p>The third call to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(n/8\)</span> times on heaps of size <span class="math inline">\(2^2\)</span>. This has a cost of <span class="math inline">\(\frac{n}{8} \log 8 = \frac{n}{8} \cdot 3\)</span>.</p></li>
</ul>
<p>Indeed, the <span class="math inline">\(k\)</span>th all to <code>mergePairs</code> calls <code>merge</code> a total of <span class="math inline">\(\frac{n}{2^k}\)</span> times on two heaps of size <span class="math inline">\(2^{k-1}\)</span>. From this we see that the total cost is of order</p>
<p class="mathjaxWide"><span class="math display">\[
\sum_{k=1}^{\log n} \frac{n}{2^k} k
=
n \sum_{k=1}^{\log n} \frac{k}{2^k}
.
\]</span></p>
<p>Since</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{2i+1}{2^{2i+1}} + \frac{2i+2}{2^{2i+2}} \le \frac{1}{2^i}
,
\]</span></p>
<p>we can pair the terms in the sum to get a total cost of order</p>
<p class="mathjaxWide"><span class="math display">\[
n \sum_{k=0}^{\log n} \frac{1}{2^k}
\le
n \sum_{k=0}^{\infty} \frac{1}{2^k}
\le
2n
.
\]</span></p>
<p>□</p>
<h2 id="exercise-3.4">Exercise 3.4</h2>
<p>A binary tree is said to satisfy the weight-biased leftist property if the size (= number of nodes) of any node’s left child is at least as large as that of its right child.</p>
<ol type="1">
<li>Prove that the right spine of a weight-biased leftist heap contains at most <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor\)</span> elements.</li>
<li>Modify the implementation in figure 3.2 to obtain weight-biased leftist heaps.</li>
<li>Modify <code>merge</code> for weight-biased leftist heaps to operate in a single top-down pass.</li>
<li>What advantages would the top-down version of <code>merge</code> have in a lazy environment? In a concurrent environment?</li>
</ol>
<h2 id="solution-3.4">Solution 3.4</h2>
<p><strong>Item 1.</strong></p>
<p>The proof is almost identical to that for leftist trees in <a href="#exercise-3.1">Exercise 3.1</a>.</p>
<p>The statement is true for the empty tree.</p>
<p>Let <span class="math inline">\(T\)</span> be a weight-biased leftist heap of rank <span class="math inline">\(r\)</span> with <span class="math inline">\(n\)</span> nodes. Then each child is a weight-biased leftist tree with fewer nodes. The right child has rank <span class="math inline">\(r-1\)</span> and by the induction hypothesis must have at least <span class="math inline">\(2^{r-1}-1\)</span> nodes. By the weight-biased property of <span class="math inline">\(T\)</span>, the left child also has at least <span class="math inline">\(2^{r-1}-1\)</span> nodes. Therefore, <span class="math inline">\(T\)</span> has at least <span class="math inline">\(2^r-1\)</span> nodes. In other words, <span class="math inline">\(\log (n+1) \ge r\)</span>. Since <span class="math inline">\(r\)</span> is an integer, <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor \ge r\)</span>. □</p>
<p><strong>Item 2.</strong></p>
<p>The implementation of leftist heaps encompasses both the leftist and weight-biased variants.</p>
<p><strong>Item 3.</strong></p>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise04.hs">source</a>.</p>
<p><strong>Item 4.</strong></p>
<p>In a lazy environment, the top-down version has the advantage that some queries can be made to the merged heap without calculating the entire heap. For example, <code>weight (merge h1 h2)</code> would run in constant time regardless of the sizes of <code>h1</code> and <code>h2</code>.</p>
<h2 id="binomial-heaps">Binomial Heaps</h2>
<p>We define the binomial tree of rank 0 to be the singleton node.</p>
<figure>
<img src="/images/binomial-tree-0.pdf.png" alt="The binomial tree of rank 0" /><figcaption>The binomial tree of rank 0</figcaption>
</figure>
<p>The binomial tree of rank r is defined as the tree formed by adding the binomial tree of rank n-1 as a left child of itself.</p>
<figure>
<img src="/images/binomial-tree-1.pdf.png" alt="The binomial tree of rank 1" /><figcaption>The binomial tree of rank 1</figcaption>
</figure>
<figure>
<img src="/images/binomial-tree-2.pdf.png" alt="The binomial tree of rank 2" /><figcaption>The binomial tree of rank 2</figcaption>
</figure>
<figure>
<img src="/images/binomial-tree-3.pdf.png" alt="The binomial tree of rank 3" /><figcaption>The binomial tree of rank 3</figcaption>
</figure>
<p>Note that the binomial tree of rank r has exactly <span class="math inline">\(2^r\)</span> nodes. This follows from the fact that we double the number of nodes in the tree each time we increase the rank by 1.</p>
<p>There is an alternative definition of binomial trees. A binomial tree of rank <span class="math inline">\(r\)</span> is a node with <span class="math inline">\(r\)</span> children <span class="math inline">\(t_1, \dotsc, t_r\)</span>, where <span class="math inline">\(t_i\)</span> is a binomial tree of rank <span class="math inline">\(r-i\)</span>.</p>
<p>We represent a node in a binomial tree as a key with a list of children. The extra <code>Int</code> is to keep track of the rank.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">BinomialTree</span> a <span class="fu">=</span> <span class="dt">Node</span> <span class="dt">Int</span> a [<span class="dt">BinTree</span> a]
                    <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</code></pre></div>
<p>We shall maintain two invariants:</p>
<ol type="1">
<li>Each list of children is in decreasing order of rank; and</li>
<li>The elements are stored in heap order.</li>
</ol>
<p>A binomial heap is a forest of heap-ordered binomial trees, where no two trees in the forest have the same rank. Thus, the trees in a binomial heap of size n correspond to the 1s in the binomial representation of n. For example, a binomial heap of size 21 would have one tree of rank 4 (size <span class="math inline">\(2^4 = 16\)</span>), one of rank 2 (size <span class="math inline">\(2^2=4\)</span>), and one of rank 0 (size <span class="math inline">\(2^0=1\)</span>), corresponding to 21’s binomial representation 10101. The binary representation of n contains <span class="math inline">\(\left\lfloor \log (n+1) \right\rfloor\)</span> digits, giving a bound for the number of trees in a binomial heap.</p>
<h2 id="exercise-3.5">Exercise 3.5</h2>
<p>Define <code>findMin</code> directly rather than via a call to <code>removeMinTree</code>.</p>
<h2 id="solution-3.5">Solution 3.5</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise05.hs">source</a>.</p>
<h2 id="exercise-3.6">Exercise 3.6</h2>
<p>Given a binomial tree, the rank of the root determines the rank of the children. Reimplement binomial heaps without the redundant rank annotations.</p>
<h2 id="solution-3.6">Solution 3.6</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise06.hs">source</a>.</p>
<h2 id="exercise-3.7">Exercise 3.7</h2>
<p>Make a funtor <code>ExplicitMin</code> that creates a heap with a constant time <code>findMin</code> and logarithmic time <code>deleteMin</code>.</p>
<h2 id="solution-3.7">Solution 3.7</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise07.hs">source</a>.</p>
<h2 id="red-black-trees">Red-Black Trees</h2>
<p>A red-black tree is a type of balanced binary search tree. The balance is achieved by painting the nodes either red or black whilst maintaining the following two invariants:</p>
<dl>
<dt>Red invariant</dt>
<dd>No red node has a red child
</dd>
<dt>Black invariant</dt>
<dd>Every path from the root node to an empty node contains the same number of black nodes.
</dd>
</dl>
<p>By convention, the empty node is defined to be black.</p>
<figure>
<img src="/images/red-black-1-node.pdf.png" alt="The red-black tree of size 1" /><figcaption>The red-black tree of size 1</figcaption>
</figure>
<figure>
<img src="/images/red-black-2-nodes.pdf.png" alt="The red-black tree of size 2" /><figcaption>The red-black tree of size 2</figcaption>
</figure>
<figure>
<img src="/images/red-black-3-nodes.pdf.png" alt="The red-black tree of size 3" /><figcaption>The red-black tree of size 3</figcaption>
</figure>
<figure>
<img src="/images/red-black-nontrivial.pdf.png" alt="A non-trivial red-black tree" /><figcaption>A non-trivial red-black tree</figcaption>
</figure>
<p>Our data type is based on a BST with an extra colour field.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Colour</span> <span class="fu">=</span> <span class="dt">R</span>
            <span class="fu">|</span> <span class="dt">B</span>
            <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)

<span class="kw">data</span> <span class="dt">RBTree</span> a <span class="fu">=</span> <span class="dt">E</span>
              <span class="fu">|</span> <span class="dt">T</span> <span class="dt">Colour</span> (<span class="dt">RBTree</span> a) a (<span class="dt">RBTree</span> a)
              <span class="kw">deriving</span> (<span class="dt">Eq</span>)</code></pre></div>
<h2 id="exercise-3.8">Exercise 3.8</h2>
<p>Prove that the the maximum depth of a node in a red-black tree of size n is at most <span class="math inline">\(2\left\lfloor \log (n+1) \right\rfloor\)</span>.</p>
<h2 id="solution-3.8">Solution 3.8</h2>
<p>We prove this by induction on the number of nodes.</p>
<p>The statement is true for empty trees.</p>
<p>Let <span class="math inline">\(T\)</span> be a red-black tree of depth <span class="math inline">\(d\)</span> with <span class="math inline">\(n\)</span> nodes. Suppose the trees rooted at its children have depths <span class="math inline">\(d_0\)</span> and <span class="math inline">\(d_1\)</span>, with sizes <span class="math inline">\(n_0 \le n_1\)</span>, respectively. In particular, the children are red-black trees with fewer than <span class="math inline">\(n\)</span> nodes. A consequence of the red-black invariant of <span class="math inline">\(T\)</span> is that <span class="math inline">\(d \le 2(d_0 + 1)\)</span>, since <span class="math inline">\(d\)</span> is the length of the longest path and <span class="math inline">\(d_0\)</span> is at least the length of the shortest path. Applying the induction hypothesis to the children yields</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  d 
  &amp;\le 
  2(d_0 +1) 
  \\
  &amp;\le 
  2(\log (n_0 + 1) + 1)
  \\
  &amp;= 
  2\log (2n_0 + 2) 
  \\
  &amp;\le 
  2\log (n_0 + n_1 + 2) 
  \\
  &amp;= 
  2\log (n + 1).
\end{align}
\]</span></p>
<p>□</p>
<h2 id="exercise-3.9">Exercise 3.9</h2>
<p>Write a function <code>fromOrdList</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">fromOrdList ::</span> <span class="dt">Ord</span> a <span class="ot">=&gt;</span> [a] <span class="ot">-&gt;</span> <span class="dt">RedBlackTree</span> a</code></pre></div>
<p>that converts a sorted list with no duplicates into a red-black tree in <span class="math inline">\(\mathcal O (n)\)</span> time.</p>
<h2 id="solution-3.9">Solution 3.9</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/5cd2c0ae4641edb65ba88f4c7bf0e0a49a23063a/src/Chap03/Exercise09.hs">source</a>.</p>
<p>We must prove both that this implementation has linear complexity and that the resulting tree is red-black invariant.</p>
<dl>
<dt>Proposition</dt>
<dd>The function <code>fromOrdList</code> has linear complexity.
</dd>
</dl>
<p>The helper <code>go</code> makes at most two recursive calls to a list half the size of the original. More precisely,</p>
<p class="mathjaxWide"><span class="math display">\[
T (2k+1) = 2T (k) + \mathcal O (1)
\]</span></p>
<p>and</p>
<p class="mathjaxWide"><span class="math display">\[
T (2k) = T(k) + T (k-1) + \mathcal O (1).
\]</span></p>
<p>These are solved by <span class="math inline">\(T (n) = \mathcal O (n)\)</span>.</p>
<p>□</p>
<p>For the invariants, note that the shape and colouring of the tree doesn’t depend on the particular elements of the list. With this in mind, we will prove a couple of lemmas.</p>
<dl>
<dt>Lemma</dt>
<dd>The black depth (as measured by the algorithm) of <code>fromOrdList xs</code> is exactly <span class="math inline">\(\left\lfloor \log (n+1) - 1\right\rfloor\)</span>, where <code>xs</code> is a list of length <span class="math inline">\(n\)</span>.
</dd>
</dl>
<p>Proof. We prove this by induction on the length of the list.</p>
<p>For length <span class="math inline">\(0\)</span>, the black depth of the resulting empty tree is <span class="math inline">\(-1 = \log (0 + 1) - 1\)</span>.</p>
<p>By the induction hypothesis, the black depth in the odd length case <span class="math inline">\(n=2k+1\)</span> is <span class="math inline">\(\left\lfloor \log (k+1) \right\rfloor\)</span>. This is equal to</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  &amp;
  \quad \left\lfloor \log (k+1) \right\rfloor +1 -1 
  \\
  &amp;= 
  \left\lfloor \log (k + 1) + \log 2 \right\rfloor - 1 
  \\
  &amp;=
  \left\lfloor \log (2k + 1 + 1) \right\rfloor - 1 
  \\
  &amp;= 
  \left\lfloor \log (n + 1)\right\rfloor - 1.
\end{align}
\]</span></p>
<p>In the even case <span class="math inline">\(n=2k\)</span>, the black depth is <span class="math inline">\(\left\lfloor \log k \right\rfloor\)</span>, again using the induction hypothesis. This simplifies to</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
  &amp;
  \quad
  \left\lfloor \log k \right\rfloor +1 -1 
  \\
  &amp;= 
  \left\lfloor \log 2k \right\rfloor - 1 
  \\
  &amp;= 
  \left\lfloor \log (2k+1) \right\rfloor -1 
  \\
  &amp;= 
  \left\lfloor \log (n+1) \right\rfloor - 1.
\end{align}
\]</span></p>
<p>The second line follows from the fact that <span class="math inline">\(\left\lfloor \log a \right\rfloor &lt; \left\lfloor \log (a+1) \right\rfloor\)</span> if and only if <span class="math inline">\(a = 2^i - 1\)</span> for some <span class="math inline">\(i \in \mathbb N_{\ge 1}\)</span>.</p>
<p>□</p>
<dl>
<dt>Proposition</dt>
<dd>The tree <code>fromOrdList xs</code> is black invariant for any list <code>xs</code>.
</dd>
</dl>
<p>Proof. When the two recursive calls in <code>go (length) xs</code> produce trees of differing black depth, their black depths may differ by at most one. This follows from the previous lemma. By painting the tree with the larger black depth red, we maintain the invariant that both black depths are equal. Thus, the tree <code>fromOrdList xs</code> is black invariant.</p>
<p>□</p>
<dl>
<dt>Lemma</dt>
<dd>The root of the tree <code>fromOrdList xs</code> has a red left child if and only if the length of <code>xs</code> is <span class="math inline">\(2^i - 2\)</span> for some <span class="math inline">\(i \in \mathbb N_{\ge 2}\)</span>. In any other case, both children are black.
</dd>
</dl>
<p>Proof. Let <span class="math inline">\(n\)</span> be the size of the list <code>xs</code>. The function <code>go (length xs) xs</code> makes two recursive calls to create children of sizes approximately <span class="math inline">\(n/2\)</span>. We paint the root of the left child red when their black depths differ, which can only occur if <span class="math inline">\(n = 2k\)</span> is even. Note that the left child always has the greater size and, by the previous lemma, the greater black depth. In this case the black depth of the left is <span class="math inline">\(\left\lfloor \log (k+1) \right\rfloor - 1\)</span>, and the black depth of the right is <span class="math inline">\(\left\lfloor \log k \right\rfloor - 1\)</span>. These differ precisely when <span class="math inline">\(k = 2^i - 1\)</span> for some <span class="math inline">\(i \in \mathbb N_{\ge 1}\)</span>; that is, when <span class="math inline">\(n = 2 (2^i - 1) = 2^{i+1} - 2\)</span>.</p>
<p>□</p>
<dl>
<dt>Proposition</dt>
<dd>The tree <code>fromOrdList xs</code> is red invariant for any list <code>xs</code>.
</dd>
</dl>
<p>Proof. From the previous lemma, <code>fromOrdList xs</code> has a red left child, then then length of <code>xs</code> is <span class="math inline">\(n = 2^{i+1} - 2\)</span>. But then the size of the left child is <span class="math inline">\(n/2 = 2^i - 1\)</span>, so the left child has no red children. Therefore, no red invariant violation is introduced.</p>
<p>□</p>
<h2 id="exercise-3.10">Exercise 3.10</h2>
<p>Reduce redundancy in the <code>balance</code> function as follows:</p>
<ol type="1">
<li>Split <code>balance</code> into two functions, <code>lbalance</code> and <code>rbalance</code>, that test for colour violations in the left and right child, respectively.</li>
<li>Rewrite <code>ins</code> so that it never tests the colour of nodes not on the search path.</li>
</ol>
<h2 id="solution-3.10">Solution 3.10</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/ca52a0986bb5baab4bb36266d39235f035378f80/src/Chap03/Exercise10.hs">source</a> for both parts.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>
<entry>
    <title>Okasaki's PFDS: Chapter 2</title>
    <link href="http://stappit.github.io/posts/pfds/okasakiPFDSc02.html" />
    <id>http://stappit.github.io/posts/pfds/okasakiPFDSc02.html</id>
    <published>2015-10-26T00:00:00Z</published>
    <updated>2015-10-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[


<h1 class="blog-post-title">Okasaki's PFDS: Chapter 2</h1>
<p class="blog-post-meta">
Posted on October 26, 2015  by Brian </br>
 Tags: <a href="/tags/fp.html">fp</a>, <a href="/tags/haskell.html">haskell</a>, <a href="/tags/literate.html">literate</a>, <a href="/tags/okasaki.html">okasaki</a>, <a href="/tags/binary%20tree.html">binary tree</a>, <a href="/tags/binary%20search%20tree.html">binary search tree</a>, <a href="/tags/set.html">set</a> </br>
 Category: <a href="/categories/pfds.html">pfds</a> 
</p>

<p>This post contains my solutions to the exercises in chapter 2 of Okasaki’s ‘Purely Functional Data Structures’. The latest source code can be found in <a href="https://github.com/stappit/okasaki-pfds">my GitHub repo</a>.</p>
<h2 id="exercise-2.1">Exercise 2.1</h2>
<p>Write a function <code>suffixes</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">suffixes ::</span> [a] <span class="ot">-&gt;</span> [[a]]</code></pre></div>
<p>that takes a list <code>xs</code> and returns a list of all the suffixes of <code>xs</code> in decreasing order of length. For example,</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">suffixes [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>] <span class="fu">==</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">4</span>], []]</code></pre></div>
<p>Show that the resulting list of suffixes can be generated in <span class="math inline">\(\mathcal O (n)\)</span> time and represented in <span class="math inline">\(\mathcal O (n)\)</span> space.</p>
<h2 id="solution-2.1">Solution 2.1</h2>
<p>Since there are as many recursive calls to <code>suffixes</code> as there are elements of <code>xs</code>, and both <code>:</code> and <code>tail</code> run in constant time, <code>suffixes</code> must be linear in the length of the list <code>xs</code>. That is, the solution to the recursion <span class="math inline">\(T (n) = T(n-1) + \mathcal O (1)\)</span> is <span class="math inline">\(T (n) = \mathcal O (n)\)</span>.</p>
<p>Moreover, we use the <span class="math inline">\(n\)</span> lists that already exist and also <span class="math inline">\(\mathcal O (n)\)</span> new pointers to each of those lists. Therefore, <code>suffixes xs</code> is represented in <span class="math inline">\(\mathcal O (n)\)</span> space.</p>
<h2 id="binary-search-trees-bsts">Binary Search Trees (BSTs)</h2>
<p>We start with binary trees (not search trees yet!). A binary tree is either empty or has two children, which we call ‘left’ and ‘right’.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Tree</span> a <span class="fu">=</span> <span class="dt">E</span>
            <span class="fu">|</span> <span class="dt">T</span> (<span class="dt">Tree</span> a) a (<span class="dt">Tree</span> a)
            <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</code></pre></div>
<p>In the binary trees below, empty nodes are depicted as squares.</p>
<figure>
<img src="/images/binary-tree-nontrivial.pdf.png" alt="A binary tree (which is NOT a BST)." /><figcaption>A binary tree (which is NOT a BST).</figcaption>
</figure>
<p>A BST is a binary tree with some extra structure. In particular, we require that the key of a node be greater than that of any of its left descendants and smaller than that of any of its right descendants.</p>
<figure>
<img src="/images/bst-nontrivial.pdf.png" alt="A binary tree which IS a BST." /><figcaption>A binary tree which IS a BST.</figcaption>
</figure>
<p>In the following exercises, we implement BSTs in the context of sets.</p>
<h2 id="exercise-2.2">Exercise 2.2</h2>
<p>Rewrite <code>member</code> to take no more than <span class="math inline">\(d+1\)</span> comparisons.</p>
<h2 id="solution-2.2">Solution 2.2</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise02.hs">source</a>.</p>
<h2 id="exercise-2.3">Exercise 2.3</h2>
<p>Rewrite <code>insert</code> using exceptions to avoid copying the entire search path (in the case of inserting an existing element).</p>
<h2 id="solution-2.3">Solution 2.3</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise03.hs">source</a>.</p>
<p>We use the <code>Maybe</code> data structure for our errors, i.e. <code>Nothing</code> indicates an error.</p>
<h2 id="exercise-2.4">Exercise 2.4</h2>
<p>Combine the ideas of <a href="#exercise-2.2">Exercise 2.2</a> and <a href="#exercise-2.3">Exercise 2.3</a> to create an insert function that performs no unnecessary copying and uses no more than <span class="math inline">\(d+1\)</span> comparisons.</p>
<h2 id="solution-2.4">Solution 2.4</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise04.hs">source</a>.</p>
<h2 id="exercise-2.5">Exercise 2.5</h2>
<ol type="1">
<li><p>Write a function <code>complete</code> of type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">complete ::</span> a <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">UnbalancedSet</span> a</code></pre></div>
<p>such that <code>complete a d</code> is a complete binary tree of depth d with the key <code>a</code> at every node. This function should run in <span class="math inline">\(\mathcal O (d)\)</span> time.</p></li>
<li><p>Extend <code>complete</code> to create balanced trees of arbitrary size that runs in <span class="math inline">\(\mathcal O (n)\)</span> time, where <span class="math inline">\(n\)</span> is the number of nodes. A tree is said to be balanced if the size of any node’s left child differs by at most one from the size of that node’s right child.</p></li>
</ol>
<h2 id="solution-2.5">Solution 2.5</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise05.hs">source</a>.</p>
<p><strong>Item 1.</strong></p>
<p>The recursion is given by <span class="math inline">\(T(d) = T(d-1) + \mathcal O (1)\)</span>, which is solved by <span class="math inline">\(T (d) = \mathcal O (d)\)</span>.</p>
<p><strong>Item 2.</strong></p>
<p>The complexity of <code>balance</code> is equal to that of <code>create2</code>. The recursion for <code>create2</code> is given by <span class="math inline">\(T (n) = T (n/2) + \mathcal O (1)\)</span>, which is solved by <span class="math inline">\(T (n) = \mathcal O (\log n)\)</span>.</p>
<h2 id="exercise-2.6">Exercise 2.6</h2>
<p>Adapt the <code>UnbalancedSet</code> functor to support finite maps rather than sets. The signature for finite maps is as follows.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">class</span> <span class="dt">FiniteMap</span> m k a <span class="kw">where</span>
<span class="ot">  empty  ::</span> m k a 
<span class="ot">  bind   ::</span> k <span class="ot">-&gt;</span>     a <span class="ot">-&gt;</span> m k a <span class="ot">-&gt;</span> m k a
<span class="ot">  lookup ::</span> k <span class="ot">-&gt;</span> m k a <span class="ot">-&gt;</span> <span class="dt">Maybe</span> a</code></pre></div>
<h2 id="solution-2.6">Solution 2.6</h2>
<p>See <a href="https://github.com/stappit/okasaki-pfds/blob/master/src/Chap02/Exercise06.hs">source</a>.</p>
<p>We reuse the set implementation for <code>UnbalancedSet</code> by creating the <code>Binding</code> data type with the appropriate ordering. Note that this doesn’t allow updating key-value pairs.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>
]]></summary>
</entry>

</feed>
