<!DOCTYPE html>

<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css" integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">

    <link rel="stylesheet" href="../../css/default.css">

    <link rel="alternate" type="application/atom+xml" title="Brian's feed" href="atom.xml" />

    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">

    <title>Brian - BDA3 Chapter 4 Exercise 1</title>
  </head>

  <body>
    <nav id="navbar-container" class="navbar navbar-expand-lg navbar-light bg-light">
      <div class="container">
        <a class="navbar-brand mr-5" href="https://www.briancallander.com">Brian</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div id="navbar" class="collapse navbar-collapse justify-content-end">
          <ul class="nav navbar-nav">
            <li class="nav-item"><a class="nav-link" href="https://www.briancallander.com"><i class="fas fa-home"></i> Recent</a></li>
            <li class="nav-item"><a class="nav-link" href="https://www.briancallander.com"><i class="fas fa-archive"></i> Archive</a></li>
            <li class="nav-item"><a class="nav-link" href="https://twitter.com/mcbricall"><i class="fab fa-twitter"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://github.com/stappit"><i class="fab fa-github"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://www.linkedin.com/in/brian-callander-ba4117140/"><i class="fab fa-linkedin-in"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://www.strava.com/athletes/6396953"><i class="fab fa-strava"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://www.instagram.com/macbricall/"><i class="fab fa-instagram"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://www.briancallander.com"><i class="far fa-envelope"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://www.briancallander.com"><i class="fas fa-rss"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://www.briancallander.com"><i class="fas fa-info-circle"></i> About</a></li>
          </ul>
        </div>
      </div>
    </nav>

    <section>
      <article>
        <div id="content" class="container">
          <h1 class="post-title">BDA3 Chapter 4 Exercise 1</h1>

<div class="card post-meta border-0">
  <div class="card-body post-meta">
    <p class="card-text text-muted text-left">
    Posted on November  3, 2018  by Brian </br>
     Tags: <a href="../../tags/bda%20chapter%204.html">bda chapter 4</a>, <a href="../../tags/solutions.html">solutions</a>, <a href="../../tags/bayes.html">bayes</a>, <a href="../../tags/cauchy.html">cauchy</a>, <a href="../../tags/normal%20approximation.html">normal approximation</a> </br>
     Category: <a href="../../categories/bda3.html">bda3</a> 
    </p>
  </div>
</div>

<p>Here’s my solution to exercise 1, chapter 4, of <a href="https://andrewgelman.com/">Gelman’s</a> <em>Bayesian Data Analysis</em> (BDA), 3rd edition. There are <a href="http://www.stat.columbia.edu/~gelman/book/solutions.pdf">solutions</a> to some of the exercises on the <a href="http://www.stat.columbia.edu/~gelman/book/">book’s webpage</a>.</p>
<!--more-->
<div style="display:none">
<p class="mathjaxWide"><span class="math inline">\(\DeclareMathOperator{\dbinomial}{Binomial} \DeclareMathOperator{\dbern}{Bernoulli} \DeclareMathOperator{\dpois}{Poisson} \DeclareMathOperator{\dnorm}{Normal} \DeclareMathOperator{\dt}{t} \DeclareMathOperator{\dcauchy}{Cauchy} \DeclareMathOperator{\dexponential}{Exp} \DeclareMathOperator{\duniform}{Uniform} \DeclareMathOperator{\dgamma}{Gamma} \DeclareMathOperator{\dinvgamma}{InvGamma} \DeclareMathOperator{\invlogit}{InvLogit} \DeclareMathOperator{\dinvchi}{InvChi2} \DeclareMathOperator{\dnorminvchi}{NormInvChi2} \DeclareMathOperator{\logit}{Logit} \DeclareMathOperator{\ddirichlet}{Dirichlet} \DeclareMathOperator{\dbeta}{Beta}\)</span></p>
</div>
<p>Suppose the likelihood is Cauchy, <span class="math inline">\(p(y_i \mid \theta) \propto (1 + (y_i - \theta)^2)^{-1}\)</span>, with a prior uniform on <span class="math inline">\([0, 1]\)</span>. Then the posterior has the same equation as the likelihood on the support of <span class="math inline">\(\theta\)</span>. Part of the exercise is to find the posterior mode but the hint is more confusing than helpful. Solving for the mode algebraically involves solving a polynomial of degree <span class="math inline">\(2n + 1\)</span>, where <span class="math inline">\(n\)</span> is the number of observations. We’ll use some numerical approximations to find the mode.</p>
<h2 id="posterior-mode">Posterior mode</h2>
<p>The observed data are as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">1.5</span>, <span class="fl">2.5</span>)</code></pre></div>
<p>We could make draws from the posterior by coding this up in stan. However, an estimation of the mode from such values is difficult. An alternative is to use numerical optimisation. For that we’ll use the posterior on the log scale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">log_likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(y, theta)
  (<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(y <span class="op">-</span><span class="st"> </span>theta)<span class="op">^</span><span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">log</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">sum</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">map_dbl</span>(<span class="st">`</span><span class="dt">*</span><span class="st">`</span>, <span class="op">-</span><span class="dv">1</span>)

log_posterior_given &lt;-<span class="st"> </span><span class="cf">function</span>(y) {
  <span class="cf">function</span>(theta) {
    <span class="cf">if</span> (theta <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">|</span><span class="st"> </span><span class="dv">1</span> <span class="op">&lt;</span><span class="st"> </span>theta) {
      <span class="kw">return</span>(<span class="op">-</span><span class="ot">Inf</span>)
    } <span class="cf">else</span> {
      <span class="kw">return</span>(<span class="kw">log_likelihood</span>(y, theta))
    }
  }
}

log_posterior &lt;-<span class="st"> </span><span class="kw">log_posterior_given</span>(y)</code></pre></div>
<p>Numerical maximisation gives us a value near, but not quite, zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mode_numerical &lt;-<span class="st"> </span><span class="kw">optimise</span>(log_posterior, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">maximum =</span> <span class="ot">TRUE</span>)<span class="op">$</span>maximum
mode_numerical</code></pre></div>
<pre><code>[1] 6.610696e-05</code></pre>
<p>Let’s plot the posterior.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">granularity &lt;-<span class="st"> </span><span class="fl">1e5</span>
grid &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> granularity)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">id =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>(),
    <span class="dt">log_unnormalised_density =</span> <span class="kw">map_dbl</span>(theta, log_posterior),
    <span class="dt">unnormalised_density =</span> <span class="kw">exp</span>(log_unnormalised_density),
    <span class="dt">density =</span> granularity <span class="op">*</span><span class="st"> </span>unnormalised_density <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unnormalised_density),
    <span class="dt">is_mode =</span> <span class="kw">abs</span>(theta <span class="op">-</span><span class="st"> </span><span class="kw">signif</span>(mode_numerical, <span class="dt">digits =</span> <span class="dv">1</span>)) <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">/</span><span class="st"> </span>granularity
  ) </code></pre></div>
<figure>
<img src="chapter_04_exercise_01_files/figure-markdown/grid_plot-1..svg" />
</figure>
<p>Indeed, it looks like the mode could be 0. Zooming in we see that it is very likely to be zero.</p>
<figure>
<img src="chapter_04_exercise_01_files/figure-markdown/closeup-1..svg" />
</figure>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mode &lt;-<span class="st"> </span><span class="dv">0</span></code></pre></div>
<h2 id="normal-approximation">Normal approximation</h2>
<p>Now let’s calculate the derivatives in order to find the normal approximation. The derivative of the log posterior is</p>
<p class="mathjaxWide"><span class="math display">\[
\frac{d}{d\theta} \log p(y \mid \theta)
=
2 \sum_1^5 \frac{y_i - \theta}{1 + (y_i - \theta)^2}
.
\]</span></p>
<p>The second derivative of the log posterior is</p>
<p class="mathjaxWide"><span class="math display">\[
\begin{align}
\frac{d^2}{d\theta^2} \log p(y \mid \theta)
&amp;=
\sum_1^5
\frac{
  \frac{-2}{1 + (y_i - \theta)^2} - \frac{2(y_i - \theta)}{(1 + (y_i - \theta)^2)^2}\cdot 2(y_i - \theta)
}{
  \left( 1 + (y_i - \theta)^2 \right)^2
}
\\
&amp;=
\sum_1^5
\frac{-2\left( 1 + (y_i - \theta)^2 \right)^2 - 4 (y_i - \theta)^2}{\left( 1 + (y_i - \theta)^2 \right)^4}
\\
&amp;=
-2
\sum_1^5
\frac{3(y_i - \theta)^2 + 2(y_i - \theta) + 1}{\left( 1 + (y_i - \theta)^2 \right)^4}
.
\end{align}
\]</span></p>
<p>Evaluating this at the mode gives</p>
<p class="mathjaxWide"><span class="math display">\[
-2 \sum_1^5 \frac{3y_i^2 + 2y_i + 1}{\left( 1 + y_i^2 \right)^4}
.
\]</span></p>
<p>The means that the observed information is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">I &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>((<span class="dv">3</span> <span class="op">*</span><span class="st"> </span>y<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>y <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>y<span class="op">^</span><span class="dv">2</span>)<span class="op">^</span><span class="dv">4</span>)
I</code></pre></div>
<pre><code>[1] 2.489427</code></pre>
<p>This gives us the normal approximation with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span>mode
variance &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>I
std &lt;-<span class="st"> </span><span class="kw">sqrt</span>(variance)

<span class="kw">c</span>(mu, std)</code></pre></div>
<pre><code>[1] 0.0000000 0.6337972</code></pre>
<p>which gives us the normal approximation <span class="math inline">\(p(\theta \mid y) \approx \dnorm(0, 0.634)\)</span> on <span class="math inline">\([0, 1]\)</span>.</p>
<figure>
<img src="chapter_04_exercise_01_files/figure-markdown/approx_plot-1..svg" />
</figure>
<p>The approximation isn’t very good.</p>

<div id="disqus_thread"></div>
<script>
/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
 */
/*
   var disqus_config = function () {
   this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
   this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
   };
 */
(function() {  // DON'T EDIT BELOW THIS LINE
 var d = document, s = d.createElement('script');

 s.src = '//stappit-github-io.disqus.com/embed.js';

 s.setAttribute('data-timestamp', +new Date());
 (d.head || d.body).appendChild(s);
 })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

<script id="dsq-count-scr" src="//stappit-github-io.disqus.com/count.js" async></script>

        </div>
      </article>
    </section>

    <footer class="footer">
      <div class="container text-center">
        Site proudly generated by
        <a href="http://jaspervdj.be/hakyll">Hakyll</a>
      </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </body>
</html>
